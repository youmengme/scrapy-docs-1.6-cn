

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Scrapy教程 &mdash; Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="示例" href="examples.html" />
    <link rel="prev" title="安装指南" href="install.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
              <div class="version">
                1.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Scrapy 一目了然</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">安装指南</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Scrapy教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">创建项目</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">我们的第一个爬虫</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">如何运行我们的爬虫</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">到底发生了什么事？</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#start-requests">start_requests方法的快捷方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">提取数据</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#xpath">Xpath 简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">提取名言和作者</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id9">在爬虫中提取数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#storing-data">存储爬虫数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id13">跟进链接</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#request">创建Request的快捷方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">更多示例和模式</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id15">使用爬虫参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id16">下一步</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">示例</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html">命令行工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html">爬虫（Spiders）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html">选择器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html">Item 装载器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html">Item Pipeline（项目管道）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html">Feed 导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html">请求与响应</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html">链接提取器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html">设置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html">例外</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html">统计收集</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html">发送电子邮件</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html">Telnet 控制台</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html">Web 服务</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/media-pipeline.html">下载和处理文件与图像</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html">AutoThrottle 扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html">架构概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html">扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html">信号(Signals)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Scrapy教程</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/intro/tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="scrapy">
<span id="intro-tutorial"></span><h1>Scrapy教程<a class="headerlink" href="#scrapy" title="Permalink to this headline">¶</a></h1>
<p>在本教程中，我们假设您的系统上已经安装了Scrapy。如果不是这种情况，请参阅 <a class="reference internal" href="install.html#intro-install"><span class="std std-ref">安装指南</span></a>.</p>
<p>我们将要爬取 <a class="reference external" href="http://quotes.toscrape.com/">quotes.toscrape.com</a>, 一个包含众多著名作家名言的网站。</p>
<p>本教程将引导您完成以下任务:</p>
<ol class="arabic simple">
<li><p>创建一个新的 Scrapy 项目</p></li>
<li><p>编写 <a class="reference internal" href="../topics/spiders.html#topics-spiders"><span class="std std-ref">spider</span></a> 以抓取网站并提取数据</p></li>
<li><p>使用命令行导出已爬取的数据</p></li>
<li><p>将爬虫更改为递归跟进链接</p></li>
<li><p>使用爬虫参数</p></li>
</ol>
<p>Scrapy是用 <a class="reference external" href="https://www.python.org/">Python</a>. 编写的。如果您不熟悉该语言，您可能需要先了解语言是什么样的，以便充分利用Scrapy。</p>
<p>If如果您已经熟悉其他语言，并希望快速学习Python，那么 <a class="reference external" href="https://docs.python.org/3/tutorial">Python Tutorial</a> 是一个很好的资源。</p>
<p>如果您不熟悉编程并希望从Python开始，以下书籍可能对您有用:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://automatetheboringstuff.com/">Automate the Boring Stuff With Python</a></p></li>
<li><p><a class="reference external" href="http://openbookproject.net/thinkcs/python/english3e/">How To Think Like a Computer Scientist</a></p></li>
<li><p><a class="reference external" href="https://learnpythonthehardway.org/python3/">Learn Python 3 The Hard Way</a></p></li>
</ul>
<p>您还可以查看 <a class="reference external" href="https://wiki.python.org/moin/BeginnersGuide/NonProgrammers">this list of Python resources for non-programmers</a>,
以及 <a class="reference external" href="https://www.reddit.com/r/learnpython/wiki/index#wiki_new_to_python.3F">suggested resources in the learnpython-subreddit</a>.</p>
<div class="section" id="id1">
<h2>创建项目<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>在开始抓取之前，您必须设置一个新的Scrapy项目。输入您要存储代码的目录并运行:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">tutorial</span>
</pre></div>
</div>
<p>T这将创建一个具有以下内容的 <code class="docutils literal notranslate"><span class="pre">tutorial</span></code> 目录:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tutorial</span><span class="o">/</span>
    <span class="n">scrapy</span><span class="o">.</span><span class="n">cfg</span>            <span class="c1"># deploy configuration file</span>

    <span class="n">tutorial</span><span class="o">/</span>             <span class="c1"># project&#39;s Python module, you&#39;ll import your code from here</span>
        <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>

        <span class="n">items</span><span class="o">.</span><span class="n">py</span>          <span class="c1"># project items definition file</span>

        <span class="n">middlewares</span><span class="o">.</span><span class="n">py</span>    <span class="c1"># project middlewares file</span>

        <span class="n">pipelines</span><span class="o">.</span><span class="n">py</span>      <span class="c1"># project pipelines file</span>

        <span class="n">settings</span><span class="o">.</span><span class="n">py</span>       <span class="c1"># project settings file</span>

        <span class="n">spiders</span><span class="o">/</span>          <span class="c1"># a directory where you&#39;ll later put your spiders</span>
            <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>我们的第一个爬虫<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>爬虫是您定义的类，Scrapy用它从网站（或一组网站）中抓取信息。它们必须子类化
<code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Spider</span></code> 并定义初始请求，可选地如何跟踪页面中的链接，以及如何解析下载的页面内容以提取数据。</p>
<p>这是我们第一个爬虫的代码。将其保存在项目中的
<code class="docutils literal notranslate"><span class="pre">tutorial/spiders</span></code> 目录下名为 <code class="docutils literal notranslate"><span class="pre">quotes_spider.py</span></code> 的文件中:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
            <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;quotes-</span><span class="si">%s</span><span class="s1">.html&#39;</span> <span class="o">%</span> <span class="n">page</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;Saved file </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>如你所见，我们的 Spider 继承了 <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Spider</span></code></a>
并定义了一些属性和方法:</p>
<ul>
<li><p><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.name" title="scrapy.spiders.Spider.name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code></a>: 标识爬虫。它在项目中必须是唯一的，也就是说，您不能为不同的 Spider 设置相同的名称。</p></li>
<li><p><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a>: 必须返回一个可迭代的 Requests（您可以返回一个 request 列表或写一个生成器函数），Spider将开始抓取。后续请求将从这些初始请求中连续生成。</p></li>
<li><p><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a>: 被调用来处理 response 的方法， response 由每个 request 下载生成。 response 参数是一个 <a class="reference internal" href="../topics/request-response.html#scrapy.http.TextResponse" title="scrapy.http.TextResponse"><code class="xref py py-class docutils literal notranslate"><span class="pre">TextResponse</span></code></a> 的实例，它保存页面内容，并具有更多有用的方法来处理它。</p>
<p>The <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> 方法通常解析 response ，将抓取的数据提取为 dicts，并查找要跟进的新 URL 并从中创建新请求 (<a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>) 。</p>
</li>
</ul>
<div class="section" id="id3">
<h3>如何运行我们的爬虫<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>要让我们的蜘蛛工作，进入项目的根目录并运行:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span>
</pre></div>
</div>
<p>T此命令运行将我们刚才添加名为 <code class="docutils literal notranslate"><span class="pre">quotes</span></code> 的爬虫，并发送一些请到 <code class="docutils literal notranslate"><span class="pre">quotes.toscrape.com</span></code> 域。您将得到类似于以下的输出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span> <span class="p">(</span><span class="n">omitted</span> <span class="k">for</span> <span class="n">brevity</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Spider</span> <span class="n">opened</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">extensions</span><span class="o">.</span><span class="n">logstats</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Crawled</span> <span class="mi">0</span> <span class="n">pages</span> <span class="p">(</span><span class="n">at</span> <span class="mi">0</span> <span class="n">pages</span><span class="o">/</span><span class="nb">min</span><span class="p">),</span> <span class="n">scraped</span> <span class="mi">0</span> <span class="n">items</span> <span class="p">(</span><span class="n">at</span> <span class="mi">0</span> <span class="n">items</span><span class="o">/</span><span class="nb">min</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">extensions</span><span class="o">.</span><span class="n">telnet</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Telnet</span> <span class="n">console</span> <span class="n">listening</span> <span class="n">on</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="p">:</span><span class="mi">6023</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">404</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">robots</span><span class="o">.</span><span class="n">txt</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">2</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">quotes</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Saved</span> <span class="n">file</span> <span class="n">quotes</span><span class="o">-</span><span class="mf">1.</span><span class="n">html</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">quotes</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Saved</span> <span class="n">file</span> <span class="n">quotes</span><span class="o">-</span><span class="mf">2.</span><span class="n">html</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Closing</span> <span class="n">spider</span> <span class="p">(</span><span class="n">finished</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>现在，检查当前目录中的文件。您应该注意到，已经创建了两个新文件: <em>quotes-1.html</em> 和 <em>quotes-2.html</em>, 内容分别对应各自的 URL ，作为我们的 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法指示.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果您想知道为什么我们还没有解析HTML，请继续，我们将很快介绍。</p>
</div>
<div class="section" id="id4">
<h4>到底发生了什么事？<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>Scrapy 调度由 Spider 的 <code class="docutils literal notranslate"><span class="pre">start_requests</span></code> 方法返回的:class:<cite>scrapy.Request &lt;scrapy.http.Request&gt;</cite> 对象。在接收到每个 response 时，它实例化 <a class="reference internal" href="../topics/request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code></a> 对象并调用与 request 相关联的回调方法（在这儿是
<code class="docutils literal notranslate"><span class="pre">parse</span></code> 方法）将 response 作为参数传递。</p>
</div>
</div>
<div class="section" id="start-requests">
<h3>start_requests方法的快捷方式<a class="headerlink" href="#start-requests" title="Permalink to this headline">¶</a></h3>
<p>您可以使用一个 URL 列表定义一个 <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_urls" title="scrapy.spiders.Spider.start_urls"><code class="xref py py-attr docutils literal notranslate"><span class="pre">start_urls</span></code></a>  类属性，来代替实现一个从 URLs 生成 <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 对象的 <a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Request</span></code></a>  方法， 此列表将由默认实现的  <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> 用于为您的爬虫创建初始请求:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;quotes-</span><span class="si">%s</span><span class="s1">.html&#39;</span> <span class="o">%</span> <span class="n">page</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>
</div>
<p><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> 法来处理对这些 URL 的每个请求，即使我们没有明确告诉 Scrapy 这样做。发生这种情况是因为  <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> 是 Scrapy 的默认回调方法，它为没有显式分配的回调的请求调用。</p>
</div>
<div class="section" id="id5">
<h3>提取数据<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>学习如何使用Scrapy提取数据的最佳方法是使用 <a class="reference internal" href="../topics/shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a> 的选择器(selectors)。:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>当您在终端运行 Scrapy 时，请一定记得给 url 地址加上引号，否则包含参数的 url (例如 <code class="docutils literal notranslate"><span class="pre">&amp;</span></code> 号)会导致 Scrapy 运行失败。</p>
<p>在Windows上，请使用双引号:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="s2">&quot;http://quotes.toscrape.com/page/1/&quot;</span>
</pre></div>
</div>
</div>
<p>你会看到类似的东西:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="o">...</span> <span class="n">Scrapy</span> <span class="n">log</span> <span class="n">here</span> <span class="o">...</span> <span class="p">]</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">12</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">27</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="n">Available</span> <span class="n">Scrapy</span> <span class="n">objects</span><span class="p">:</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">scrapy</span>     <span class="n">scrapy</span> <span class="n">module</span> <span class="p">(</span><span class="n">contains</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">,</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">,</span> <span class="n">etc</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">crawler</span>    <span class="o">&lt;</span><span class="n">scrapy</span><span class="o">.</span><span class="n">crawler</span><span class="o">.</span><span class="n">Crawler</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fa91d888c90</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">item</span>       <span class="p">{}</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">request</span>    <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">response</span>   <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">settings</span>   <span class="o">&lt;</span><span class="n">scrapy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">Settings</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fa91d888c10</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">spider</span>     <span class="o">&lt;</span><span class="n">DefaultSpider</span> <span class="s1">&#39;default&#39;</span> <span class="n">at</span> <span class="mh">0x7fa91c8af990</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="n">Useful</span> <span class="n">shortcuts</span><span class="p">:</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">shelp</span><span class="p">()</span>           <span class="n">Shell</span> <span class="n">help</span> <span class="p">(</span><span class="nb">print</span> <span class="n">this</span> <span class="n">help</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">fetch</span><span class="p">(</span><span class="n">req_or_url</span><span class="p">)</span> <span class="n">Fetch</span> <span class="n">request</span> <span class="p">(</span><span class="ow">or</span> <span class="n">URL</span><span class="p">)</span> <span class="ow">and</span> <span class="n">update</span> <span class="n">local</span> <span class="n">objects</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">view</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>    <span class="n">View</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">browser</span>
<span class="o">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>使用 shell，您可以尝试使用带有 response 对象的 <a class="reference external" href="https://www.w3.org/TR/selectors">CSS</a> 选择元素:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">)</span>
<span class="go">[&lt;Selector xpath=&#39;descendant-or-self::title&#39; data=&#39;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&#39;&gt;]</span>
</pre></div>
</div>
<p>运行 <code class="docutils literal notranslate"><span class="pre">response.css('title')</span></code> 的结果是一个名为
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList" title="scrapy.selector.SelectorList"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectorList</span></code></a>,的类似列表的对象，它表示包含 XML / HTML 元素的
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><code class="xref py py-class docutils literal notranslate"><span class="pre">Selector</span></code></a> 对象列表，允许您运行进一步的查询以精细选择或提取数据。</p>
<p>要从上面的标题中提取文本，您可以执行以下操作:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="go">[&#39;Quotes to Scrape&#39;]</span>
</pre></div>
</div>
<p>这里有两个要注意的事情：一个是我们在CSS查询中添加了 <code class="docutils literal notranslate"><span class="pre">::text</span></code> ，这意味着我们只想直接在
<code class="docutils literal notranslate"><span class="pre">&lt;title&gt;</span></code> 元素中选择文本元素。如果我们不指定 <code class="docutils literal notranslate"><span class="pre">::text</span></code>, 我们将获得完整的 title 元素，包括其标签:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="go">[&#39;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&#39;]</span>
</pre></div>
</div>
<p>另一件事是调用 <code class="docutils literal notranslate"><span class="pre">.getall()</span></code> 的结果是一个列表: 选择器可能返回多个结果，因此我们将它们全部提取出来。当你知道你只想要第一个结果时，就像在这种情况下，你可以这样做:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">&#39;Quotes to Scrape&#39;</span>
</pre></div>
</div>
<p>此外，您还可以这样做:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">&#39;Quotes to Scrape&#39;</span>
</pre></div>
</div>
<p>但是，<code class="docutils literal notranslate"><span class="pre">.get()</span></code> 直接在 <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList" title="scrapy.selector.SelectorList"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectorList</span></code></a>
实例上使用会避免 <code class="docutils literal notranslate"><span class="pre">IndexError</span></code> 并且在找不到与选择匹配的元素时返回 None <code class="docutils literal notranslate"><span class="pre">None</span></code> 。</p>
<p>这里有一个教训：对于大多数抓取代码，您希望它能够对由于在页面上找不到的东西而导致的错误后恢复运行，这样即使某些部分无法被抓取，您至少也可以获得一些数据。</p>
<p>除了 <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.getall" title="scrapy.selector.SelectorList.getall"><code class="xref py py-meth docutils literal notranslate"><span class="pre">getall()</span></code></a> 和
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.get" title="scrapy.selector.SelectorList.get"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get()</span></code></a> 方法之外，您还可以使用 <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.re" title="scrapy.selector.SelectorList.re"><code class="xref py py-meth docutils literal notranslate"><span class="pre">re()</span></code></a> 方法使用 <a class="reference external" href="https://docs.python.org/3/library/re.html">regular
expressions</a>  进行提取:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Quotes.*&#39;</span><span class="p">)</span>
<span class="go">[&#39;Quotes to Scrape&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Q\w+&#39;</span><span class="p">)</span>
<span class="go">[&#39;Quotes&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\w+) to (\w+)&#39;</span><span class="p">)</span>
<span class="go">[&#39;Quotes&#39;, &#39;Scrape&#39;]</span>
</pre></div>
</div>
<p>为了找到正确的CSS选择器使用，您可能会发现有用的打开响应页面从您的Web浏览器中使用  <code class="docutils literal notranslate"><span class="pre">view(response)</span></code>.
您可以使用浏览器开发人员工具或扩展（如 Firebug）（有关 <a class="reference internal" href="../topics/developer-tools.html#topics-developer-tools"><span class="std std-ref">Using your browser’s Developer Tools for scraping</span></a>).</p>
<p><a class="reference external" href="http://selectorgadget.com/">Selector Gadget</a> 也是一个很好的工具，可以快速找到CSS选择器的视觉选择的元素，这在许多浏览器。</p>
<div class="section" id="xpath">
<h4>Xpath 简介<a class="headerlink" href="#xpath" title="Permalink to this headline">¶</a></h4>
<p>除了 <a class="reference external" href="https://www.w3.org/TR/selectors">CSS</a>, Scrapy选择器还支持使用 <a class="reference external" href="https://www.w3.org/TR/xpath">XPath</a> 表达式:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//title&#39;</span><span class="p">)</span>
<span class="go">[&lt;Selector xpath=&#39;//title&#39; data=&#39;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&#39;&gt;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">&#39;Quotes to Scrape&#39;</span>
</pre></div>
</div>
<p>XPath 表达式非常强大，是 Scrapy 选择器的基础。事实上，CSS 选择器转换为 XPath 。如果您仔细阅读在 shell 中的选择器对象的文本表示您将会看到它。</p>
<p>虽然可能不像CSS选择器那样流行，XPath 表达式提供了更多的功能，因为除了导航结构之外，它还可以查看内容。使用 XPath，您可以选择以下内容：选择包含文本“下一页”的链接。这使得 XPath 非常适合于抓取的任务，我们鼓励您学习 XPath ，即使您已经知道如何构造CSS选择器，它将使抓取更容易。</p>
<p>我们不会在这里介绍 XPath 的很多，但是你可以阅读更多关于 <a class="reference internal" href="../topics/selectors.html#topics-selectors"><span class="std std-ref">使用 XPath
与 Scrapy 选择器</span></a>. 要了解有关 XPath 的更多信息，我们建议 <a class="reference external" href="http://zvon.org/comp/r/tut-XPath_1.html">通过本教程示例学习XPath</a>, 以及 ` 学习本教程“如何在XPath中思考”  &lt;<a class="reference external" href="http://plasmasturm.org/log/xpath101/">http://plasmasturm.org/log/xpath101/</a>&gt;`_.</p>
</div>
<div class="section" id="id8">
<h4>提取名言和作者<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>现在您已经对选择（select）和提取（extract）有一定的了解，让我们通过编写代码从网页提取名言来完成我们的爬虫.</p>
<p><a class="reference external" href="http://quotes.toscrape.com">http://quotes.toscrape.com</a> 每个引用都由HTML元素表示，如下所示:</p>
<div class="highlight-html notranslate"><div class="highlight"><pre><span></span><span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;quote&quot;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;text&quot;</span><span class="p">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span><span class="p">&gt;</span>
        by <span class="p">&lt;</span><span class="nt">small</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;author&quot;</span><span class="p">&gt;</span>Albert Einstein<span class="p">&lt;/</span><span class="nt">small</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/author/Albert-Einstein&quot;</span><span class="p">&gt;</span>(about)<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;tags&quot;</span><span class="p">&gt;</span>
        Tags:
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;tag&quot;</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/tag/change/page/1/&quot;</span><span class="p">&gt;</span>change<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;tag&quot;</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/tag/deep-thoughts/page/1/&quot;</span><span class="p">&gt;</span>deep-thoughts<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;tag&quot;</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/tag/thinking/page/1/&quot;</span><span class="p">&gt;</span>thinking<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;tag&quot;</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/tag/world/page/1/&quot;</span><span class="p">&gt;</span>world<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>让我们打开scrapy shell并尝试一下以了解如何提取我们想要的数据:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy shell &#39;http://quotes.toscrape.com&#39;
</pre></div>
</div>
<p>我们得到一个带有 HTML 元素的 quote 列表:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;div.quote&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>通过上面的查询返回的每个选择器允许我们对它们的子元素进行进一步的查询。让我们将第一个选择器分配给一个变量，以便我们可以直接对特定的引用运行我们的CSS选择器:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">quote</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;div.quote&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>现在，让我们使用刚刚创建的 <code class="docutils literal notranslate"><span class="pre">quote</span></code> 对象从该报价中提取 <code class="docutils literal notranslate"><span class="pre">title</span></code>, <code class="docutils literal notranslate"><span class="pre">author</span></code> 和 <code class="docutils literal notranslate"><span class="pre">tags</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">title</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;span.text::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">title</span>
<span class="go">&#39;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;small.author::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">author</span>
<span class="go">&#39;Albert Einstein&#39;</span>
</pre></div>
</div>
<p>鉴于标签是字符串列表，我们可以使用 <code class="docutils literal notranslate"><span class="pre">.getall()</span></code> 方法来获取所有内容:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;div.tags a.tag::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tags</span>
<span class="go">[&#39;change&#39;, &#39;deep-thoughts&#39;, &#39;thinking&#39;, &#39;world&#39;]</span>
</pre></div>
</div>
<p>在弄清楚如何提取每个内容之后，我们现在可以遍历所有的引号元素，并将它们放在一起成为一个Python字典:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;div.quote&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">text</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;span.text::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;small.author::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&quot;div.tags a.tag::text&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">author</span><span class="o">=</span><span class="n">author</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">))</span>
<span class="go">{&#39;tags&#39;: [&#39;change&#39;, &#39;deep-thoughts&#39;, &#39;thinking&#39;, &#39;world&#39;], &#39;author&#39;: &#39;Albert Einstein&#39;, &#39;text&#39;: &#39;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&#39;}</span>
<span class="go">{&#39;tags&#39;: [&#39;abilities&#39;, &#39;choices&#39;], &#39;author&#39;: &#39;J.K. Rowling&#39;, &#39;text&#39;: &#39;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&#39;}</span>
<span class="go">    ... a few more of these, omitted for brevity</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id9">
<h3>在爬虫中提取数据<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>让我们回到我们的爬虫。直到现在，它不会提取任何特别的数据，只是将整个HTML页面保存到本地文件。让我们将上面的提取逻辑集成到我们的爬虫中。</p>
<p>Scrapy 爬虫通常会生成许多包含从页面中提取的数据的字典。为此，我们在回调中使用 Python 的 <code class="docutils literal notranslate"><span class="pre">yield</span></code> 关键字，如下所示:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>
</pre></div>
</div>
<p>如果你运行这个爬虫，它将在日志输出提取的数据:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">18</span><span class="p">:</span><span class="mi">57</span><span class="p">:</span><span class="mi">19</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scraper</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Scraped</span> <span class="kn">from</span> <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">{</span><span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;life&#39;</span><span class="p">,</span> <span class="s1">&#39;love&#39;</span><span class="p">],</span> <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="s1">&#39;André Gide&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s1">&#39;“It is better to be hated for what you are than to be loved for what you are not.”&#39;</span><span class="p">}</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">18</span><span class="p">:</span><span class="mi">57</span><span class="p">:</span><span class="mi">19</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scraper</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Scraped</span> <span class="kn">from</span> <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">{</span><span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;edison&#39;</span><span class="p">,</span> <span class="s1">&#39;failure&#39;</span><span class="p">,</span> <span class="s1">&#39;inspirational&#39;</span><span class="p">,</span> <span class="s1">&#39;paraphrased&#39;</span><span class="p">],</span> <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="s1">&#39;Thomas A. Edison&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s2">&quot;“I have not failed. I&#39;ve just found 10,000 ways that won&#39;t work.”&quot;</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="storing-data">
<span id="id10"></span><h2>存储爬虫数据<a class="headerlink" href="#storing-data" title="Permalink to this headline">¶</a></h2>
<p>存储抓取数据的最简单方法是使用 <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">Feed 导出(Feed exports)</span></a>, 使用以下命令:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>这将生成一个  <code class="docutils literal notranslate"><span class="pre">quotes.json</span></code> 文件，其中包含所有被抓取的项目，以 <a class="reference external" href="https://en.wikipedia.org/wiki/JSON">JSON</a> 序列化.</p>
<p>由于历史原因，Scrapy会附加到给定文件而不是覆盖其内容。如果在第二次之前没有删除文件的情况下运行此命令两次，则最终会出现损坏的JSON文件。</p>
<p>您还可以使用其他格式，例如 <a class="reference external" href="http://jsonlines.org">JSON Lines</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">jl</span>
</pre></div>
</div>
<p><a class="reference external" href="http://jsonlines.org">JSON Lines</a> 格式很有用，因为它是流式的，你可以轻松地添加新的记录到它。当你运行两次它没有相同的 JSON 问题。此外，由于每条记录都是单独的行，因此您可以处理大文件，而无需将所有内容都放在内存中，有像 <a class="reference external" href="https://stedolan.github.io/jq">JQ</a> 这样的工具可以帮助在命令行执行。</p>
<p>在小项目（如本教程中的一个）中，这应该足够了。但是，如果要对已抓取的 Item 执行更复杂的操作，则可以编写 <a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">Item Pipeline</span></a>. 在创建项目时，已经在
<a href="#id11"><span class="problematic" id="id12">``</span></a>tutorial/pipelines.py``中为您创建了 Item Pipeline 的占位符文件。如果您只想存储被抓取的 Item ，您不需要实现任何 Item Pipeline。</p>
</div>
<div class="section" id="id13">
<h2>跟进链接<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>如果我们不只是从 <a class="reference external" href="http://quotes.toscrape">http://quotes.toscrape</a>.com的前两页中提取内容，而是想从网站的所有页面提取名言.</p>
<p>现在您已经知道如何从网页中提取数据，让我们看看如何跟进他们的链接。</p>
<p>首先是提取我们要关注的网页的链接。检查我们的页面，我们可以看到有一个链接到下一页与下面的标记:</p>
<div class="highlight-html notranslate"><div class="highlight"><pre><span></span><span class="p">&lt;</span><span class="nt">ul</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;pager&quot;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">li</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;next&quot;</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;/page/2/&quot;</span><span class="p">&gt;</span>Next <span class="p">&lt;</span><span class="nt">span</span> <span class="na">aria-hidden</span><span class="o">=</span><span class="s">&quot;true&quot;</span><span class="p">&gt;</span><span class="ni">&amp;rarr;</span><span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">li</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">ul</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>我们可以尝试在shell中提取它:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">&#39;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;→&lt;/span&gt;&lt;/a&gt;&#39;</span>
</pre></div>
</div>
<p>这得到锚（anchor）元素，但我们想要属性 <code class="docutils literal notranslate"><span class="pre">href</span></code> 。为此，Scrapy 支持一个 CSS 扩展，让您选择属性内容，如下所示:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">&#39;/page/2/&#39;</span>
</pre></div>
</div>
<p>还有一个 <code class="docutils literal notranslate"><span class="pre">attrib</span></code> 属性可用(请参阅 <a class="reference internal" href="../topics/selectors.html#selecting-attributes"><span class="std std-ref">选择元素属性</span></a> 以获取更多信息):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">attrib</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
<span class="go">&#39;/page/2&#39;</span>
</pre></div>
</div>
<p>让我们看看现在我们的爬虫被修改为递归地跟进到下一页的链接，并从中提取数据:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>现在，在提取数据之后， <code class="docutils literal notranslate"><span class="pre">parse()</span></code> 方法寻找到下一页的链接，使用
<a class="reference internal" href="../topics/request-response.html#scrapy.http.Response.urljoin" title="scrapy.http.Response.urljoin"><code class="xref py py-meth docutils literal notranslate"><span class="pre">urljoin()</span></code></a> 方法构建一个完整的绝对 URL（因为链接可能是相对的），并产生一个新的请求到下一页，将其自身注册为回调，以处理下一页的数据提取，并保持抓取通过所有页面。</p>
<p>这里您可以看到 Scrapy 的跟进链接机制：当您在回调方法中产生一个请求时，当当前请求完成时 Scrapy 会调度要发送的请求，并注册一个回调方法。</p>
<p>使用它，您可以构建复杂的抓取工具，根据您定义的规则跟进链接，并根据访问的网页提取不同类型的数据。</p>
<p>在我们的示例中，它创建一个循环，所有的链接到下一页，直到它找不到一个可以抓取的博客，论坛和其他网站分页。</p>
<div class="section" id="request">
<span id="response-follow-example"></span><h3>创建Request的快捷方式<a class="headerlink" href="#request" title="Permalink to this headline">¶</a></h3>
<p>作为创建Request对象的快捷方式，您可以使用
<a class="reference internal" href="../topics/request-response.html#scrapy.http.TextResponse.follow" title="scrapy.http.TextResponse.follow"><code class="xref py py-meth docutils literal notranslate"><span class="pre">response.follow</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span small::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>与scrapy.Request不同, <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> 直接支持相对URL - 无需调用urljoin。注意. <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> 只返回一个Request实例; 你仍然需要提出这个请求.</p>
<p>您也可以传递选择器到 <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> 而不是字符串; 此选择器应提取必要的属性:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>对于 <code class="docutils literal notranslate"><span class="pre">&lt;a&gt;</span></code> 元素，有一个快捷方式: <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> 自动使用其href属性。所以代码可以进一步缩短:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a&#39;</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">response.follow(response.css('li.next</span> <span class="pre">a'))</span></code> 无效是因为
<code class="docutils literal notranslate"><span class="pre">response.css</span></code> 返回一个类似于列表的对象，其中包含所有结果的选择器，而不是单个选择器。. 上面例子中的 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环或
<code class="docutils literal notranslate"><span class="pre">response.follow(response.css('li.next</span> <span class="pre">a')[0])</span></code> 是个不错的选择.</p>
</div>
</div>
<div class="section" id="id14">
<h3>更多示例和模式<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>这是另一个爬虫，它说明了回调和以下链接，这次是为了抓取作者信息:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">AuthorSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;author&#39;</span>

    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://quotes.toscrape.com/&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># follow links to author pages</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.author + a::attr(href)&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_author</span><span class="p">)</span>

        <span class="c1"># follow pagination links</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">extract_with_css</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;h3.author-title::text&#39;</span><span class="p">),</span>
            <span class="s1">&#39;birthdate&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;.author-born-date::text&#39;</span><span class="p">),</span>
            <span class="s1">&#39;bio&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;.author-description::text&#39;</span><span class="p">),</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>这个爬虫将从主页开始，它将跟进所有到作者页面的链接，并为每个链接调用 <code class="docutils literal notranslate"><span class="pre">parse_author</span></code>  回调方法，以及我们之前看到的 <code class="docutils literal notranslate"><span class="pre">parse</span></code> 回调的分页链接。</p>
<p>在这里，我们将回调传递给 <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> 位置参数，以使代码更短; 它也适用于 <code class="docutils literal notranslate"><span class="pre">scrapy.Request</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">parse_author</span></code> 回调定义了一个辅助函数从CSS查询提取和清理数据，并产生了Python字典与作者的数据。</p>
<p>另一个有趣的事情，这个爬虫演示的是，即使有很多来自同一作者的quote，我们不需要担心访问同一作者页面多次。默认情况下，Scrapy 会过滤掉已访问过的网址的重复请求，从而避免由于编程错误而导致服务器过多的问题。这可以通过设置
<a class="reference internal" href="../topics/settings.html#std:setting-DUPEFILTER_CLASS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_CLASS</span></code></a> 进行配置.</p>
<p>希望到现在为止，您已经很好地理解了如何使用Scrapy跟踪链接和回调的机制。</p>
<p>作为利用跟进链接的机制另一个示例爬虫，请查看一个通用爬虫 <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.CrawlSpider" title="scrapy.spiders.CrawlSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrawlSpider</span></code></a> 类，它实现了一个小规则引擎（small rules engine），您可以用它写你的爬虫。</p>
<p>此外，一个常见的模式是使用一个 <a class="reference internal" href="../topics/request-response.html#topics-request-response-ref-request-callback-arguments"><span class="std std-ref">把额外的数据传递给回调函数的技巧</span></a> 来构建一个包含多个页面的数据的 Item.</p>
</div>
</div>
<div class="section" id="id15">
<h2>使用爬虫参数<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<p>在运行爬虫时，可以使用 <code class="docutils literal notranslate"><span class="pre">-a</span></code> 选项为您的爬虫提供命令行参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">-</span><span class="n">humor</span><span class="o">.</span><span class="n">json</span> <span class="o">-</span><span class="n">a</span> <span class="n">tag</span><span class="o">=</span><span class="n">humor</span>
</pre></div>
</div>
<p>这些参数传递给 Spider 的 <code class="docutils literal notranslate"><span class="pre">__init__</span></code> 方法，默认成为spider属性.</p>
<p>在此示例中，为 <code class="docutils literal notranslate"><span class="pre">tag</span></code> 参数提供的值将通过 <code class="docutils literal notranslate"><span class="pre">self.tag</span></code>. 提供。您可以使用此方法使您的爬虫根据参数构建 URL来实现仅抓取带有特定tag的数据:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://quotes.toscrape.com/&#39;</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;tag&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">url</span> <span class="o">+</span> <span class="s1">&#39;tag/&#39;</span> <span class="o">+</span> <span class="n">tag</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>如果您向此爬虫传递 <code class="docutils literal notranslate"><span class="pre">tag=humor</span></code> 参数，您会注意到它只会访问 <code class="docutils literal notranslate"><span class="pre">humor</span></code> 标记中的网址，例如 <code class="docutils literal notranslate"><span class="pre">http://quotes.toscrape.com/tag/humor</span></code>.</p>
<p>您可以 :ref:` 在此处了解有关处理spider参数的更多信息 &lt;spiderargs&gt;`.</p>
</div>
<div class="section" id="id16">
<h2>下一步<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<p>T本教程仅介绍了Scrapy的基础知识，但这里没有提到很多其他功能。查看 <a class="reference internal" href="overview.html#intro-overview"><span class="std std-ref">Scrapy 一目了然</span></a>  中的
<a class="reference internal" href="overview.html#topics-whatelse"><span class="std std-ref">还有什么？</span></a> 部分，以便快速了解最重要的部分。</p>
<p>您可以继续阅读 <a class="reference internal" href="../index.html#section-basics"><span class="std std-ref">基本概念</span></a> 分，以了解有关命令行工具，蜘蛛，选择器以及教程未涵盖的其他内容的更多信息，例如对已删除数据进行建模。如果您更喜欢使用示例项目，请查看 <a class="reference internal" href="examples.html#intro-examples"><span class="std std-ref">示例</span></a> 部分.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="examples.html" class="btn btn-neutral float-right" title="示例" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral float-left" title="安装指南" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008–2018, Scrapy developers
      <span class="lastupdated">
        Last updated on Feb 27, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>


</body>
</html>