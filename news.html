

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Release notes &mdash; Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Contributing to Scrapy" href="contributing.html" />
    <link rel="prev" title="Item Exporters" href="topics/exporters.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
              <div class="version">
                1.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro/overview.html">Scrapy 一目了然</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/install.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/tutorial.html">Scrapy教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/examples.html">示例</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/commands.html">命令行工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spiders.html">爬虫（Spiders）</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/selectors.html">选择器</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/loaders.html">Item 装载器</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/item-pipeline.html">Item Pipeline（项目管道）</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/feed-exports.html">Feed 导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/request-response.html">请求与响应</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/link-extractors.html">链接提取器</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/settings.html">设置</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exceptions.html">例外</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/stats.html">统计收集</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/email.html">发送电子邮件</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/telnetconsole.html">Telnet 控制台</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/webservice.html">Web 服务</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/media-pipeline.html">下载和处理文件与图像</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/autothrottle.html">AutoThrottle 扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/architecture.html">架构概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/extensions.html">扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/signals.html">信号(Signals)</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-6-0-2019-01-30">Scrapy 1.6.0 (2019-01-30)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#selector-api-changes">Selector API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnet-console">Telnet console</a></li>
<li class="toctree-l3"><a class="reference internal" href="#new-extensibility-features">New extensibility features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#new-filepipeline-and-mediapipeline-features">New FilePipeline and MediaPipeline features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scrapy-contracts-improvements"><code class="docutils literal notranslate"><span class="pre">scrapy.contracts</span></code> improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usability-improvements">Usability improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bug-fixes">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#documentation-improvements">Documentation improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecation-removals">Deprecation removals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-improvements-cleanups">Other improvements, cleanups</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-5-2-2019-01-22">Scrapy 1.5.2 (2019-01-22)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-5-1-2018-07-12">Scrapy 1.5.1 (2018-07-12)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-5-0-2017-12-29">Scrapy 1.5.0 (2017-12-29)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#backwards-incompatible-changes">Backwards Incompatible Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#new-features">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#docs">Docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-4-0-2017-05-18">Scrapy 1.4.0 (2017-05-18)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deprecations-and-backwards-incompatible-changes">Deprecations and Backwards Incompatible Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cleanups-refactoring">Cleanups &amp; Refactoring</a></li>
<li class="toctree-l3"><a class="reference internal" href="#documentation">Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-3-3-2017-03-10">Scrapy 1.3.3 (2017-03-10)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-3-2-2017-02-13">Scrapy 1.3.2 (2017-02-13)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-3-1-2017-02-08">Scrapy 1.3.1 (2017-02-08)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cleanups">Cleanups</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-3-0-2016-12-21">Scrapy 1.3.0 (2016-12-21)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dependencies-cleanups">Dependencies &amp; Cleanups</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-3-2017-03-03">Scrapy 1.2.3 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-2-2016-12-06">Scrapy 1.2.2 (2016-12-06)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id10">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-changes">Other changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-1-2016-10-21">Scrapy 1.2.1 (2016-10-21)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id12">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">Other changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-0-2016-10-03">Scrapy 1.2.0 (2016-10-03)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id15">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#refactoring">Refactoring</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tests-requirements">Tests &amp; Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id17">Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-4-2017-03-03">Scrapy 1.1.4 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-3-2016-09-22">Scrapy 1.1.3 (2016-09-22)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id18">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-2-2016-08-18">Scrapy 1.1.2 (2016-08-18)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id20">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-1-2016-07-13">Scrapy 1.1.1 (2016-07-13)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id21">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id22">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id23">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-0-2016-05-11">Scrapy 1.1.0 (2016-05-11)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#beta-python-3-support">Beta Python 3 Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="#additional-new-features-and-enhancements">Additional New Features and Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecations-and-removals">Deprecations and Removals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#relocations">Relocations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bugfixes">Bugfixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-7-2017-03-03">Scrapy 1.0.7 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-6-2016-05-04">Scrapy 1.0.6 (2016-05-04)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-5-2016-02-04">Scrapy 1.0.5 (2016-02-04)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-4-2015-12-30">Scrapy 1.0.4 (2015-12-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-3-2015-08-11">Scrapy 1.0.3 (2015-08-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-2-2015-08-06">Scrapy 1.0.2 (2015-08-06)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-1-2015-07-01">Scrapy 1.0.1 (2015-07-01)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-0-2015-06-19">Scrapy 1.0.0 (2015-06-19)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#support-for-returning-dictionaries-in-spiders">Support for returning dictionaries in spiders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#per-spider-settings-gsoc-2014">Per-spider settings (GSoC 2014)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#python-logging">Python Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#crawler-api-refactoring-gsoc-2014">Crawler API refactoring (GSoC 2014)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-relocations">Module Relocations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#full-list-of-relocations">Full list of relocations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#changelog">Changelog</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-6-2015-04-20">Scrapy 0.24.6 (2015-04-20)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-5-2015-02-25">Scrapy 0.24.5 (2015-02-25)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-4-2014-08-09">Scrapy 0.24.4 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-3-2014-08-09">Scrapy 0.24.3 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-2-2014-07-08">Scrapy 0.24.2 (2014-07-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-1-2014-06-27">Scrapy 0.24.1 (2014-06-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-0-2014-06-26">Scrapy 0.24.0 (2014-06-26)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#enhancements">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id25">Bugfixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-2-released-2014-02-14">Scrapy 0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-1-released-2014-02-08">Scrapy 0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-0-released-2014-01-17">Scrapy 0.22.0 (released 2014-01-17)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id26">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fixes">Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-2-released-2013-12-09">Scrapy 0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-1-released-2013-11-28">Scrapy 0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-0-released-2013-11-08">Scrapy 0.20.0 (released 2013-11-08)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id27">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id28">Bugfixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other">Other</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thanks">Thanks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-4-released-2013-10-10">Scrapy 0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-3-released-2013-10-03">Scrapy 0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-2-released-2013-09-03">Scrapy 0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-1-released-2013-08-27">Scrapy 0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-0-released-2013-08-09">Scrapy 0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-5-released-2013-05-30">Scrapy 0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-4-released-2013-01-23">Scrapy 0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-3-released-2012-12-07">Scrapy 0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-2-released-2012-11-09">Scrapy 0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-1-released-2012-10-26">Scrapy 0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-0-released-2012-10-18">Scrapy 0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-4">Scrapy 0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-3">Scrapy 0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-2">Scrapy 0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-1">Scrapy 0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14">Scrapy 0.14</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-settings">New features and settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-rearranged-and-removed">Code rearranged and removed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-12">Scrapy 0.12</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-improvements">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scrapyd-changes">Scrapyd changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-settings">Changes to settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecated-obsoleted-functionality">Deprecated/obsoleted functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-10">Scrapy 0.10</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id29">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-tool-changes">Command-line tool changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#api-changes">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id30">Changes to settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-9">Scrapy 0.9</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id31">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id32">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-default-settings">Changes to default settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-8">Scrapy 0.8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id33">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id34">Backwards-incompatible changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-7">Scrapy 0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Release notes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/news.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="release-notes">
<span id="news"></span><h1>Release notes<a class="headerlink" href="#release-notes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="scrapy-1-6-0-2019-01-30">
<span id="release-1-6-0"></span><h2>Scrapy 1.6.0 (2019-01-30)<a class="headerlink" href="#scrapy-1-6-0-2019-01-30" title="Permalink to this headline">¶</a></h2>
<p>Highlights:</p>
<ul class="simple">
<li><p>better Windows support;</p></li>
<li><p>Python 3.7 compatibility;</p></li>
<li><p>big documentation improvements, including a switch
from <code class="docutils literal notranslate"><span class="pre">.extract_first()</span></code> + <code class="docutils literal notranslate"><span class="pre">.extract()</span></code> API to <code class="docutils literal notranslate"><span class="pre">.get()</span></code> + <code class="docutils literal notranslate"><span class="pre">.getall()</span></code>
API;</p></li>
<li><p>feed exports, FilePipeline and MediaPipeline improvements;</p></li>
<li><p>better extensibility: <a class="reference internal" href="topics/signals.html#std:signal-item_error"><code class="xref std std-signal docutils literal notranslate"><span class="pre">item_error</span></code></a> and
<a class="reference internal" href="topics/signals.html#std:signal-request_reached_downloader"><code class="xref std std-signal docutils literal notranslate"><span class="pre">request_reached_downloader</span></code></a> signals; <code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> support
for feed exporters, feed storages and dupefilters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.contracts</span></code> fixes and new features;</p></li>
<li><p>telnet console security improvements, first released as a
backport in <a class="reference internal" href="#release-1-5-2"><span class="std std-ref">Scrapy 1.5.2 (2019-01-22)</span></a>;</p></li>
<li><p>clean-up of the deprecated code;</p></li>
<li><p>various bug fixes, small new features and usability improvements across
the codebase.</p></li>
</ul>
<div class="section" id="selector-api-changes">
<h3>Selector API changes<a class="headerlink" href="#selector-api-changes" title="Permalink to this headline">¶</a></h3>
<p>While these are not changes in Scrapy itself, but rather in the <a class="reference external" href="https://github.com/scrapy/parsel">parsel</a>
library which Scrapy uses for xpath/css selectors, these changes are
worth mentioning here. Scrapy now depends on parsel &gt;= 1.5, and
Scrapy documentation is updated to follow recent <code class="docutils literal notranslate"><span class="pre">parsel</span></code> API conventions.</p>
<p>Most visible change is that <code class="docutils literal notranslate"><span class="pre">.get()</span></code> and <code class="docutils literal notranslate"><span class="pre">.getall()</span></code> selector
methods are now preferred over <code class="docutils literal notranslate"><span class="pre">.extract_first()</span></code> and <code class="docutils literal notranslate"><span class="pre">.extract()</span></code>.
We feel that these new methods result in a more concise and readable code.
See <a class="reference internal" href="topics/selectors.html#old-extraction-api"><span class="std std-ref">extract() 和 extract_first()</span></a> for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are currently <strong>no plans</strong> to deprecate <code class="docutils literal notranslate"><span class="pre">.extract()</span></code>
and <code class="docutils literal notranslate"><span class="pre">.extract_first()</span></code> methods.</p>
</div>
<p>Another useful new feature is the introduction of <code class="docutils literal notranslate"><span class="pre">Selector.attrib</span></code> and
<code class="docutils literal notranslate"><span class="pre">SelectorList.attrib</span></code> properties, which make it easier to get
attributes of HTML elements. See <a class="reference internal" href="topics/selectors.html#selecting-attributes"><span class="std std-ref">选择元素属性</span></a>.</p>
<p>CSS selectors are cached in parsel &gt;= 1.5, which makes them faster
when the same CSS path is used many times. This is very common in
case of Scrapy spiders: callbacks are usually called several times,
on different pages.</p>
<p>If you’re using custom <code class="docutils literal notranslate"><span class="pre">Selector</span></code> or <code class="docutils literal notranslate"><span class="pre">SelectorList</span></code> subclasses,
a <strong>backwards incompatible</strong> change in parsel may affect your code.
See <a class="reference external" href="https://parsel.readthedocs.io/en/latest/history.html">parsel changelog</a> for a detailed description, as well as for the
full list of improvements.</p>
</div>
<div class="section" id="telnet-console">
<h3>Telnet console<a class="headerlink" href="#telnet-console" title="Permalink to this headline">¶</a></h3>
<p><strong>Backwards incompatible</strong>: Scrapy’s telnet console now requires username
and password. See <a class="reference internal" href="topics/telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet 控制台</span></a> for more details. This change
fixes a <strong>security issue</strong>; see <a class="reference internal" href="#release-1-5-2"><span class="std std-ref">Scrapy 1.5.2 (2019-01-22)</span></a> release notes for details.</p>
</div>
<div class="section" id="new-extensibility-features">
<h3>New extensibility features<a class="headerlink" href="#new-extensibility-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> support is added to feed exporters and feed storages. This,
among other things, allows to access Scrapy settings from custom feed
storages and exporters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1605">issue 1605</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3348">issue 3348</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> support is added to dupefilters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2956">issue 2956</a>); this allows
to access e.g. settings or a spider from a dupefilter.</p></li>
<li><p><a class="reference internal" href="topics/signals.html#std:signal-item_error"><code class="xref std std-signal docutils literal notranslate"><span class="pre">item_error</span></code></a> is fired when an error happens in a pipeline
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3256">issue 3256</a>);</p></li>
<li><p><a class="reference internal" href="topics/signals.html#std:signal-request_reached_downloader"><code class="xref std std-signal docutils literal notranslate"><span class="pre">request_reached_downloader</span></code></a> is fired when Downloader gets
a new Request; this signal can be useful e.g. for custom Schedulers
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3393">issue 3393</a>).</p></li>
<li><p>new SitemapSpider <code class="xref py py-meth docutils literal notranslate"><span class="pre">sitemap_filter()</span></code> method which allows
to select sitemap entries based on their attributes in SitemapSpider
subclasses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3512">issue 3512</a>).</p></li>
<li><p>Lazy loading of Downloader Handlers is now optional; this enables better
initialization error handling in custom Downloader Handlers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3394">issue 3394</a>).</p></li>
</ul>
</div>
<div class="section" id="new-filepipeline-and-mediapipeline-features">
<h3>New FilePipeline and MediaPipeline features<a class="headerlink" href="#new-filepipeline-and-mediapipeline-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Expose more options for S3FilesStore: <a class="reference internal" href="topics/settings.html#std:setting-AWS_ENDPOINT_URL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AWS_ENDPOINT_URL</span></code></a>,
<a class="reference internal" href="topics/settings.html#std:setting-AWS_USE_SSL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AWS_USE_SSL</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-AWS_VERIFY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AWS_VERIFY</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-AWS_REGION_NAME"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AWS_REGION_NAME</span></code></a>.
For example, this allows to use alternative or self-hosted
AWS-compatible providers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2609">issue 2609</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3548">issue 3548</a>).</p></li>
<li><p>ACL support for Google Cloud Storage: <a class="reference internal" href="topics/media-pipeline.html#std:setting-FILES_STORE_GCS_ACL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FILES_STORE_GCS_ACL</span></code></a> and
<a class="reference internal" href="topics/media-pipeline.html#std:setting-IMAGES_STORE_GCS_ACL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">IMAGES_STORE_GCS_ACL</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3199">issue 3199</a>).</p></li>
</ul>
</div>
<div class="section" id="scrapy-contracts-improvements">
<h3><code class="docutils literal notranslate"><span class="pre">scrapy.contracts</span></code> improvements<a class="headerlink" href="#scrapy-contracts-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Exceptions in contracts code are handled better (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3377">issue 3377</a>);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dont_filter=True</span></code> is used for contract requests, which allows to test
different callbacks with the same URL (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3381">issue 3381</a>);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">request_cls</span></code> attribute in Contract subclasses allow to use different
Request classes in contracts, for example FormRequest (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3383">issue 3383</a>).</p></li>
<li><p>Fixed errback handling in contracts, e.g. for cases where a contract
is executed for URL which returns non-200 response (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3371">issue 3371</a>).</p></li>
</ul>
</div>
<div class="section" id="usability-improvements">
<h3>Usability improvements<a class="headerlink" href="#usability-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>more stats for RobotsTxtMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3100">issue 3100</a>)</p></li>
<li><p>INFO log level is used to show telnet host/port (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3115">issue 3115</a>)</p></li>
<li><p>a message is added to IgnoreRequest in RobotsTxtMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3113">issue 3113</a>)</p></li>
<li><p>better validation of <code class="docutils literal notranslate"><span class="pre">url</span></code> argument in <code class="docutils literal notranslate"><span class="pre">Response.follow</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3131">issue 3131</a>)</p></li>
<li><p>non-zero exit code is returned from Scrapy commands when error happens
on spider inititalization (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3226">issue 3226</a>)</p></li>
<li><p>Link extraction improvements: “ftp” is added to scheme list (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3152">issue 3152</a>);
“flv” is added to common video extensions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3165">issue 3165</a>)</p></li>
<li><p>better error message when an exporter is disabled (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3358">issue 3358</a>);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">--help</span></code> mentions syntax required for local files
(<code class="docutils literal notranslate"><span class="pre">./file.html</span></code>) - <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3496">issue 3496</a>.</p></li>
<li><p>Referer header value is added to RFPDupeFilter log messages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3588">issue 3588</a>)</p></li>
</ul>
</div>
<div class="section" id="bug-fixes">
<h3>Bug fixes<a class="headerlink" href="#bug-fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>fixed issue with extra blank lines in .csv exports under Windows
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3039">issue 3039</a>);</p></li>
<li><p>proper handling of pickling errors in Python 3 when serializing objects
for disk queues (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3082">issue 3082</a>)</p></li>
<li><p>flags are now preserved when copying Requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3342">issue 3342</a>);</p></li>
<li><p>FormRequest.from_response clickdata shouldn’t ignore elements with
<code class="docutils literal notranslate"><span class="pre">input[type=image]</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3153">issue 3153</a>).</p></li>
<li><p>FormRequest.from_response should preserve duplicate keys (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3247">issue 3247</a>)</p></li>
</ul>
</div>
<div class="section" id="documentation-improvements">
<h3>Documentation improvements<a class="headerlink" href="#documentation-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Docs are re-written to suggest .get/.getall API instead of
.extract/.extract_first. Also, <a class="reference internal" href="topics/selectors.html#topics-selectors"><span class="std std-ref">选择器</span></a> docs are updated
and re-structured to match latest parsel docs; they now contain more topics,
such as <a class="reference internal" href="topics/selectors.html#selecting-attributes"><span class="std std-ref">选择元素属性</span></a> or <a class="reference internal" href="topics/selectors.html#topics-selectors-css-extensions"><span class="std std-ref">CSS选择器扩展</span></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3390">issue 3390</a>).</p></li>
<li><p><a class="reference internal" href="topics/developer-tools.html#topics-developer-tools"><span class="std std-ref">Using your browser’s Developer Tools for scraping</span></a> is a new tutorial which replaces
old Firefox and Firebug tutorials (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3400">issue 3400</a>).</p></li>
<li><p>SCRAPY_PROJECT environment variable is documented (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3518">issue 3518</a>);</p></li>
<li><p>troubleshooting section is added to install instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3517">issue 3517</a>);</p></li>
<li><p>improved links to beginner resources in the tutorial
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3367">issue 3367</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3468">issue 3468</a>);</p></li>
<li><p>fixed <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_HTTP_CODES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_HTTP_CODES</span></code></a> default values in docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3335">issue 3335</a>);</p></li>
<li><p>remove unused <cite>DEPTH_STATS</cite> option from docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3245">issue 3245</a>);</p></li>
<li><p>other cleanups (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3347">issue 3347</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3350">issue 3350</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3445">issue 3445</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3544">issue 3544</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3605">issue 3605</a>).</p></li>
</ul>
</div>
<div class="section" id="deprecation-removals">
<h3>Deprecation removals<a class="headerlink" href="#deprecation-removals" title="Permalink to this headline">¶</a></h3>
<p>Compatibility shims for pre-1.0 Scrapy module names are removed
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3318">issue 3318</a>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.command</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.contrib</span></code> (with all submodules)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.contrib_exp</span></code> (with all submodules)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.dupefilter</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.linkextractor</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.project</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.spider</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.spidermanager</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.squeue</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.stats</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.statscol</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.utils.decorator</span></code></p></li>
</ul>
<p>See <a class="reference internal" href="#module-relocations"><span class="std std-ref">Module Relocations</span></a> for more information, or use suggestions
from Scrapy 1.5.x deprecation warnings to update your code.</p>
<p>Other deprecation removals:</p>
<ul class="simple">
<li><p>Deprecated scrapy.interfaces.ISpiderManager is removed; please use
scrapy.interfaces.ISpiderLoader.</p></li>
<li><p>Deprecated <code class="docutils literal notranslate"><span class="pre">CrawlerSettings</span></code> class is removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3327">issue 3327</a>).</p></li>
<li><p>Deprecated <code class="docutils literal notranslate"><span class="pre">Settings.overrides</span></code> and <code class="docutils literal notranslate"><span class="pre">Settings.defaults</span></code> attributes
are removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3327">issue 3327</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3359">issue 3359</a>).</p></li>
</ul>
</div>
<div class="section" id="other-improvements-cleanups">
<h3>Other improvements, cleanups<a class="headerlink" href="#other-improvements-cleanups" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>All Scrapy tests now pass on Windows; Scrapy testing suite is executed
in a Windows environment on CI (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3315">issue 3315</a>).</p></li>
<li><p>Python 3.7 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3326">issue 3326</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3150">issue 3150</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3547">issue 3547</a>).</p></li>
<li><p>Testing and CI fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3526">issue 3526</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3538">issue 3538</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3308">issue 3308</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3311">issue 3311</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3309">issue 3309</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3305">issue 3305</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3210">issue 3210</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3299">issue 3299</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.http.cookies.CookieJar.clear</span></code> accepts “domain”, “path” and “name”
optional arguments (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3231">issue 3231</a>).</p></li>
<li><p>additional files are included to sdist (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3495">issue 3495</a>);</p></li>
<li><p>code style fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3405">issue 3405</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3304">issue 3304</a>);</p></li>
<li><p>unneeded .strip() call is removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3519">issue 3519</a>);</p></li>
<li><p>collections.deque is used to store MiddlewareManager methods instead
of a list (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3476">issue 3476</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-5-2-2019-01-22">
<span id="release-1-5-2"></span><h2>Scrapy 1.5.2 (2019-01-22)<a class="headerlink" href="#scrapy-1-5-2-2019-01-22" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p><em>Security bugfix</em>: Telnet console extension can be easily exploited by rogue
websites POSTing content to <a class="reference external" href="http://localhost:6023">http://localhost:6023</a>, we haven’t found a way to
exploit it from Scrapy, but it is very easy to trick a browser to do so and
elevates the risk for local development environment.</p>
<p><em>The fix is backwards incompatible</em>, it enables telnet user-password
authentication by default with a random generated password. If you can’t
upgrade right away, please consider setting <code class="xref std std-setting docutils literal notranslate"><span class="pre">TELNET_CONSOLE_PORT</span></code>
out of its default value.</p>
<p>See <a class="reference internal" href="topics/telnetconsole.html#topics-telnetconsole"><span class="std std-ref">telnet console</span></a> documentation for more info</p>
</li>
<li><p>Backport CI build failure under GCE environemnt due to boto import error.</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-5-1-2018-07-12">
<span id="release-1-5-1"></span><h2>Scrapy 1.5.1 (2018-07-12)<a class="headerlink" href="#scrapy-1-5-1-2018-07-12" title="Permalink to this headline">¶</a></h2>
<p>This is a maintenance release with important bug fixes, but no new features:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">O(N^2)</span></code> gzip decompression issue which affected Python 3 and PyPy
is fixed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3281">issue 3281</a>);</p></li>
<li><p>skipping of TLS validation errors is improved (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3166">issue 3166</a>);</p></li>
<li><p>Ctrl-C handling is fixed in Python 3.5+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3096">issue 3096</a>);</p></li>
<li><p>testing fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3092">issue 3092</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3263">issue 3263</a>);</p></li>
<li><p>documentation improvements (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3058">issue 3058</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3059">issue 3059</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3089">issue 3089</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3123">issue 3123</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3127">issue 3127</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3189">issue 3189</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3224">issue 3224</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3280">issue 3280</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3279">issue 3279</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3201">issue 3201</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3260">issue 3260</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3284">issue 3284</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3298">issue 3298</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3294">issue 3294</a>).</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-5-0-2017-12-29">
<span id="release-1-5-0"></span><h2>Scrapy 1.5.0 (2017-12-29)<a class="headerlink" href="#scrapy-1-5-0-2017-12-29" title="Permalink to this headline">¶</a></h2>
<p>This release brings small new features and improvements across the codebase.
Some highlights:</p>
<ul class="simple">
<li><p>Google Cloud Storage is supported in FilesPipeline and ImagesPipeline.</p></li>
<li><p>Crawling with proxy servers becomes more efficient, as connections
to proxies can be reused now.</p></li>
<li><p>Warnings, exception and logging messages are improved to make debugging
easier.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span></code> command now allows to set custom request meta via
<code class="docutils literal notranslate"><span class="pre">--meta</span></code> argument.</p></li>
<li><p>Compatibility with Python 3.6, PyPy and PyPy3 is improved;
PyPy and PyPy3 are now supported officially, by running tests on CI.</p></li>
<li><p>Better default handling of HTTP 308, 522 and 524 status codes.</p></li>
<li><p>Documentation is improved, as usual.</p></li>
</ul>
<div class="section" id="backwards-incompatible-changes">
<h3>Backwards Incompatible Changes<a class="headerlink" href="#backwards-incompatible-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scrapy 1.5 drops support for Python 3.3.</p></li>
<li><p>Default Scrapy User-Agent now uses https link to scrapy.org (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2983">issue 2983</a>).
<strong>This is technically backwards-incompatible</strong>; override
<a class="reference internal" href="topics/settings.html#std:setting-USER_AGENT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">USER_AGENT</span></code></a> if you relied on old value.</p></li>
<li><p>Logging of settings overridden by <code class="docutils literal notranslate"><span class="pre">custom_settings</span></code> is fixed;
<strong>this is technically backwards-incompatible</strong> because the logger
changes from <code class="docutils literal notranslate"><span class="pre">[scrapy.utils.log]</span></code> to <code class="docutils literal notranslate"><span class="pre">[scrapy.crawler]</span></code>. If you’re
parsing Scrapy logs, please update your log parsers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1343">issue 1343</a>).</p></li>
<li><p>LinkExtractor now ignores <code class="docutils literal notranslate"><span class="pre">m4v</span></code> extension by default, this is change
in behavior.</p></li>
<li><p>522 and 524 status codes are added to <code class="docutils literal notranslate"><span class="pre">RETRY_HTTP_CODES</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2851">issue 2851</a>)</p></li>
</ul>
</div>
<div class="section" id="new-features">
<h3>New features<a class="headerlink" href="#new-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Support <code class="docutils literal notranslate"><span class="pre">&lt;link&gt;</span></code> tags in <code class="docutils literal notranslate"><span class="pre">Response.follow</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2785">issue 2785</a>)</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">ptpython</span></code> REPL (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2654">issue 2654</a>)</p></li>
<li><p>Google Cloud Storage support for FilesPipeline and ImagesPipeline
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2923">issue 2923</a>).</p></li>
<li><p>New <code class="docutils literal notranslate"><span class="pre">--meta</span></code> option of the “scrapy parse” command allows to pass additional
request.meta (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2883">issue 2883</a>)</p></li>
<li><p>Populate spider variable when using <code class="docutils literal notranslate"><span class="pre">shell.inspect_response</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2812">issue 2812</a>)</p></li>
<li><p>Handle HTTP 308 Permanent Redirect (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2844">issue 2844</a>)</p></li>
<li><p>Add 522 and 524 to <code class="docutils literal notranslate"><span class="pre">RETRY_HTTP_CODES</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2851">issue 2851</a>)</p></li>
<li><p>Log versions information at startup (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2857">issue 2857</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.mail.MailSender</span></code> now works in Python 3 (it requires Twisted 17.9.0)</p></li>
<li><p>Connections to proxy servers are reused (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2743">issue 2743</a>)</p></li>
<li><p>Add template for a downloader middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2755">issue 2755</a>)</p></li>
<li><p>Explicit message for NotImplementedError when parse callback not defined
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2831">issue 2831</a>)</p></li>
<li><p>CrawlerProcess got an option to disable installation of root log handler
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2921">issue 2921</a>)</p></li>
<li><p>LinkExtractor now ignores <code class="docutils literal notranslate"><span class="pre">m4v</span></code> extension by default</p></li>
<li><p>Better log messages for responses over <a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_WARNSIZE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_WARNSIZE</span></code></a> and
<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_MAXSIZE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_MAXSIZE</span></code></a> limits (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2927">issue 2927</a>)</p></li>
<li><p>Show warning when a URL is put to <code class="docutils literal notranslate"><span class="pre">Spider.allowed_domains</span></code> instead of
a domain (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2250">issue 2250</a>).</p></li>
</ul>
</div>
<div class="section" id="id1">
<h3>Bug fixes<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Fix logging of settings overridden by <code class="docutils literal notranslate"><span class="pre">custom_settings</span></code>;
<strong>this is technically backwards-incompatible</strong> because the logger
changes from <code class="docutils literal notranslate"><span class="pre">[scrapy.utils.log]</span></code> to <code class="docutils literal notranslate"><span class="pre">[scrapy.crawler]</span></code>, so please
update your log parsers if needed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1343">issue 1343</a>)</p></li>
<li><p>Default Scrapy User-Agent now uses https link to scrapy.org (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2983">issue 2983</a>).
<strong>This is technically backwards-incompatible</strong>; override
<a class="reference internal" href="topics/settings.html#std:setting-USER_AGENT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">USER_AGENT</span></code></a> if you relied on old value.</p></li>
<li><p>Fix PyPy and PyPy3 test failures, support them officially
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2793">issue 2793</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2935">issue 2935</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2990">issue 2990</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3050">issue 3050</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2213">issue 2213</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3048">issue 3048</a>)</p></li>
<li><p>Fix DNS resolver when <code class="docutils literal notranslate"><span class="pre">DNSCACHE_ENABLED=False</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2811">issue 2811</a>)</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">cryptography</span></code> for Debian Jessie tox test env (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2848">issue 2848</a>)</p></li>
<li><p>Add verification to check if Request callback is callable (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2766">issue 2766</a>)</p></li>
<li><p>Port <code class="docutils literal notranslate"><span class="pre">extras/qpsclient.py</span></code> to Python 3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2849">issue 2849</a>)</p></li>
<li><p>Use getfullargspec under the scenes for Python 3 to stop DeprecationWarning
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2862">issue 2862</a>)</p></li>
<li><p>Update deprecated test aliases (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2876">issue 2876</a>)</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">SitemapSpider</span></code> support for alternate links (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2853">issue 2853</a>)</p></li>
</ul>
</div>
<div class="section" id="docs">
<h3>Docs<a class="headerlink" href="#docs" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Added missing bullet point for the <code class="docutils literal notranslate"><span class="pre">AUTOTHROTTLE_TARGET_CONCURRENCY</span></code>
setting. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2756">issue 2756</a>)</p></li>
<li><p>Update Contributing docs, document new support channels
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2762">issue 2762</a>, issue:<cite>3038</cite>)</p></li>
<li><p>Include references to Scrapy subreddit in the docs</p></li>
<li><p>Fix broken links; use <a class="reference external" href="https://">https://</a> for external links
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2978">issue 2978</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2982">issue 2982</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2958">issue 2958</a>)</p></li>
<li><p>Document CloseSpider extension better (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2759">issue 2759</a>)</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">pymongo.collection.Collection.insert_one()</span></code> in MongoDB example
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2781">issue 2781</a>)</p></li>
<li><p>Spelling mistake and typos
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2828">issue 2828</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2837">issue 2837</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2884">issue 2884</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2924">issue 2924</a>)</p></li>
<li><p>Clarify <code class="docutils literal notranslate"><span class="pre">CSVFeedSpider.headers</span></code> documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2826">issue 2826</a>)</p></li>
<li><p>Document <code class="docutils literal notranslate"><span class="pre">DontCloseSpider</span></code> exception and clarify <code class="docutils literal notranslate"><span class="pre">spider_idle</span></code>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2791">issue 2791</a>)</p></li>
<li><p>Update “Releases” section in README (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2764">issue 2764</a>)</p></li>
<li><p>Fix rst syntax in <code class="docutils literal notranslate"><span class="pre">DOWNLOAD_FAIL_ON_DATALOSS</span></code> docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2763">issue 2763</a>)</p></li>
<li><p>Small fix in description of startproject arguments (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2866">issue 2866</a>)</p></li>
<li><p>Clarify data types in Response.body docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2922">issue 2922</a>)</p></li>
<li><p>Add a note about <code class="docutils literal notranslate"><span class="pre">request.meta['depth']</span></code> to DepthMiddleware docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2374">issue 2374</a>)</p></li>
<li><p>Add a note about <code class="docutils literal notranslate"><span class="pre">request.meta['dont_merge_cookies']</span></code> to CookiesMiddleware
docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2999">issue 2999</a>)</p></li>
<li><p>Up-to-date example of project structure (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2964">issue 2964</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2976">issue 2976</a>)</p></li>
<li><p>A better example of ItemExporters usage (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2989">issue 2989</a>)</p></li>
<li><p>Document <code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> methods for spider and downloader middlewares
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/3019">issue 3019</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-4-0-2017-05-18">
<span id="release-1-4-0"></span><h2>Scrapy 1.4.0 (2017-05-18)<a class="headerlink" href="#scrapy-1-4-0-2017-05-18" title="Permalink to this headline">¶</a></h2>
<p>Scrapy 1.4 does not bring that many breathtaking new features
but quite a few handy improvements nonetheless.</p>
<p>Scrapy now supports anonymous FTP sessions with customizable user and
password via the new <a class="reference internal" href="topics/settings.html#std:setting-FTP_USER"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FTP_USER</span></code></a> and <a class="reference internal" href="topics/settings.html#std:setting-FTP_PASSWORD"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FTP_PASSWORD</span></code></a> settings.
And if you’re using Twisted version 17.1.0 or above, FTP is now available
with Python 3.</p>
<p>There’s a new <a class="reference internal" href="topics/request-response.html#scrapy.http.TextResponse.follow" title="scrapy.http.TextResponse.follow"><code class="xref py py-meth docutils literal notranslate"><span class="pre">response.follow</span></code></a> method
for creating requests; <strong>it is now a recommended way to create Requests
in Scrapy spiders</strong>. This method makes it easier to write correct
spiders; <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> has several advantages over creating
<code class="docutils literal notranslate"><span class="pre">scrapy.Request</span></code> objects directly:</p>
<ul class="simple">
<li><p>it handles relative URLs;</p></li>
<li><p>it works properly with non-ascii URLs on non-UTF8 pages;</p></li>
<li><p>in addition to absolute and relative URLs it supports Selectors;
for <code class="docutils literal notranslate"><span class="pre">&lt;a&gt;</span></code> elements it can also extract their href values.</p></li>
</ul>
<p>For example, instead of this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.page a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">href</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">encoding</span><span class="p">)</span>
</pre></div>
</div>
<p>One can now write this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.page a&#39;</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>Link extractors are also improved. They work similarly to what a regular
modern browser would do: leading and trailing whitespace are removed
from attributes (think <code class="docutils literal notranslate"><span class="pre">href=&quot;</span>&#160;&#160; <span class="pre">http://example.com&quot;</span></code>) when building
<code class="docutils literal notranslate"><span class="pre">Link</span></code> objects. This whitespace-stripping also happens for <code class="docutils literal notranslate"><span class="pre">action</span></code>
attributes with <code class="docutils literal notranslate"><span class="pre">FormRequest</span></code>.</p>
<p><strong>Please also note that link extractors do not canonicalize URLs by default
anymore.</strong> This was puzzling users every now and then, and it’s not what
browsers do in fact, so we removed that extra transformation on extracted
links.</p>
<p>For those of you wanting more control on the <code class="docutils literal notranslate"><span class="pre">Referer:</span></code> header that Scrapy
sends when following links, you can set your own <code class="docutils literal notranslate"><span class="pre">Referrer</span> <span class="pre">Policy</span></code>.
Prior to Scrapy 1.4, the default <code class="docutils literal notranslate"><span class="pre">RefererMiddleware</span></code> would simply and
blindly set it to the URL of the response that generated the HTTP request
(which could leak information on your URL seeds).
By default, Scrapy now behaves much like your regular browser does.
And this policy is fully customizable with W3C standard values
(or with something really custom of your own if you wish).
See <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERRER_POLICY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">REFERRER_POLICY</span></code></a> for details.</p>
<p>To make Scrapy spiders easier to debug, Scrapy logs more stats by default
in 1.4: memory usage stats, detailed retry stats, detailed HTTP error code
stats. A similar change is that HTTP cache path is also visible in logs now.</p>
<p>Last but not least, Scrapy now has the option to make JSON and XML items
more human-readable, with newlines between items and even custom indenting
offset, using the new <a class="reference internal" href="topics/feed-exports.html#std:setting-FEED_EXPORT_INDENT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FEED_EXPORT_INDENT</span></code></a> setting.</p>
<p>Enjoy! (Or read on for the rest of changes in this release.)</p>
<div class="section" id="deprecations-and-backwards-incompatible-changes">
<h3>Deprecations and Backwards Incompatible Changes<a class="headerlink" href="#deprecations-and-backwards-incompatible-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Default to <code class="docutils literal notranslate"><span class="pre">canonicalize=False</span></code> in <code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.linkextractors.LinkExtractor</span></code>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2537">issue 2537</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1941">issue 1941</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1982">issue 1982</a>):
<strong>warning, this is technically backwards-incompatible</strong></p></li>
<li><p>Enable memusage extension by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2539">issue 2539</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2187">issue 2187</a>);
<strong>this is technically backwards-incompatible</strong> so please check if you have
any non-default <code class="docutils literal notranslate"><span class="pre">MEMUSAGE_***</span></code> options set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EDITOR</span></code> environment variable now takes precedence over <code class="docutils literal notranslate"><span class="pre">EDITOR</span></code>
option defined in settings.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1829">issue 1829</a>); Scrapy default settings
no longer depend on environment variables. <strong>This is technically a backwards
incompatible change</strong>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Spider.make_requests_from_url</span></code> is deprecated
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1728">issue 1728</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1495">issue 1495</a>).</p></li>
</ul>
</div>
<div class="section" id="id2">
<h3>New Features<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Accept proxy credentials in <a class="reference internal" href="topics/downloader-middleware.html#std:reqmeta-proxy"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">proxy</span></code></a> request meta key (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2526">issue 2526</a>)</p></li>
<li><p>Support <a class="reference external" href="https://github.com/google/brotli">brotli</a>-compressed content; requires optional <a class="reference external" href="https://github.com/python-hyper/brotlipy/">brotlipy</a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2535">issue 2535</a>)</p></li>
<li><p>New <a class="reference internal" href="intro/tutorial.html#response-follow-example"><span class="std std-ref">response.follow</span></a> shortcut
for creating requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1940">issue 1940</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">flags</span></code> argument and attribute to <a class="reference internal" href="topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>
objects (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2047">issue 2047</a>)</p></li>
<li><p>Support Anonymous FTP (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2342">issue 2342</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">retry/count</span></code>, <code class="docutils literal notranslate"><span class="pre">retry/max_reached</span></code> and <code class="docutils literal notranslate"><span class="pre">retry/reason_count/&lt;reason&gt;</span></code>
stats to <a class="reference internal" href="topics/downloader-middleware.html#scrapy.downloadermiddlewares.retry.RetryMiddleware" title="scrapy.downloadermiddlewares.retry.RetryMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">RetryMiddleware</span></code></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2543">issue 2543</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">httperror/response_ignored_count</span></code> and <code class="docutils literal notranslate"><span class="pre">httperror/response_ignored_status_count/&lt;status&gt;</span></code>
stats to <a class="reference internal" href="topics/spider-middleware.html#scrapy.spidermiddlewares.httperror.HttpErrorMiddleware" title="scrapy.spidermiddlewares.httperror.HttpErrorMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">HttpErrorMiddleware</span></code></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2566">issue 2566</a>)</p></li>
<li><p>Customizable <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERRER_POLICY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">Referrer</span> <span class="pre">policy</span></code></a> in
<a class="reference internal" href="topics/spider-middleware.html#scrapy.spidermiddlewares.referer.RefererMiddleware" title="scrapy.spidermiddlewares.referer.RefererMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">RefererMiddleware</span></code></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2306">issue 2306</a>)</p></li>
<li><p>New <code class="docutils literal notranslate"><span class="pre">data:</span></code> URI download handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2334">issue 2334</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2156">issue 2156</a>)</p></li>
<li><p>Log cache directory when HTTP Cache is used (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2611">issue 2611</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2604">issue 2604</a>)</p></li>
<li><p>Warn users when project contains duplicate spider names (fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2181">issue 2181</a>)</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">CaselessDict</span></code> now accepts <code class="docutils literal notranslate"><span class="pre">Mapping</span></code> instances and not only dicts (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2646">issue 2646</a>)</p></li>
<li><p><a class="reference internal" href="topics/media-pipeline.html#topics-media-pipeline"><span class="std std-ref">Media downloads</span></a>, with <code class="xref py py-class docutils literal notranslate"><span class="pre">FilesPipelines</span></code>
or <code class="xref py py-class docutils literal notranslate"><span class="pre">ImagesPipelines</span></code>, can now optionally handle HTTP redirects
using the new <a class="reference internal" href="topics/media-pipeline.html#std:setting-MEDIA_ALLOW_REDIRECTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEDIA_ALLOW_REDIRECTS</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2616">issue 2616</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2004">issue 2004</a>)</p></li>
<li><p>Accept non-complete responses from websites using a new
<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_FAIL_ON_DATALOSS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_FAIL_ON_DATALOSS</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2590">issue 2590</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2586">issue 2586</a>)</p></li>
<li><p>Optional pretty-printing of JSON and XML items via
<a class="reference internal" href="topics/feed-exports.html#std:setting-FEED_EXPORT_INDENT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FEED_EXPORT_INDENT</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2456">issue 2456</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1327">issue 1327</a>)</p></li>
<li><p>Allow dropping fields in <code class="docutils literal notranslate"><span class="pre">FormRequest.from_response</span></code> formdata when
<code class="docutils literal notranslate"><span class="pre">None</span></code> value is passed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/667">issue 667</a>)</p></li>
<li><p>Per-request retry times with the new <a class="reference internal" href="topics/request-response.html#std:reqmeta-max_retry_times"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">max_retry_times</span></code></a> meta key
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2642">issue 2642</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">scrapy</span></code> as a more explicit alternative to <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2740">issue 2740</a>)</p></li>
</ul>
</div>
<div class="section" id="id3">
<h3>Bug fixes<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>LinkExtractor now strips leading and trailing whitespaces from attributes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2547">issue 2547</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1614">issue 1614</a>)</p></li>
<li><p>Properly handle whitespaces in action attribute in <code class="xref py py-class docutils literal notranslate"><span class="pre">FormRequest</span></code>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2548">issue 2548</a>)</p></li>
<li><p>Buffer CONNECT response bytes from proxy until all HTTP headers are received
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2495">issue 2495</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2491">issue 2491</a>)</p></li>
<li><p>FTP downloader now works on Python 3, provided you use Twisted&gt;=17.1
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2599">issue 2599</a>)</p></li>
<li><p>Use body to choose response type after decompressing content (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2393">issue 2393</a>,
fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2145">issue 2145</a>)</p></li>
<li><p>Always decompress <code class="docutils literal notranslate"><span class="pre">Content-Encoding:</span> <span class="pre">gzip</span></code> at <a class="reference internal" href="topics/downloader-middleware.html#scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware" title="scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">HttpCompressionMiddleware</span></code></a> stage (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2391">issue 2391</a>)</p></li>
<li><p>Respect custom log level in <code class="docutils literal notranslate"><span class="pre">Spider.custom_settings</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2581">issue 2581</a>,
fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1612">issue 1612</a>)</p></li>
<li><p>‘make htmlview’ fix for macOS (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2661">issue 2661</a>)</p></li>
<li><p>Remove “commands” from the command list  (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2695">issue 2695</a>)</p></li>
<li><p>Fix duplicate Content-Length header for POST requests with empty body (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2677">issue 2677</a>)</p></li>
<li><p>Properly cancel large downloads, i.e. above <a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_MAXSIZE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_MAXSIZE</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1616">issue 1616</a>)</p></li>
<li><p>ImagesPipeline: fixed processing of transparent PNG images with palette
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2675">issue 2675</a>)</p></li>
</ul>
</div>
<div class="section" id="cleanups-refactoring">
<h3>Cleanups &amp; Refactoring<a class="headerlink" href="#cleanups-refactoring" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Tests: remove temp files and folders (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2570">issue 2570</a>),
fixed ProjectUtilsTest on OS X (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2569">issue 2569</a>),
use portable pypy for Linux on Travis CI (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2710">issue 2710</a>)</p></li>
<li><p>Separate building request from <code class="docutils literal notranslate"><span class="pre">_requests_to_follow</span></code> in CrawlSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2562">issue 2562</a>)</p></li>
<li><p>Remove “Python 3 progress” badge (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2567">issue 2567</a>)</p></li>
<li><p>Add a couple more lines to <code class="docutils literal notranslate"><span class="pre">.gitignore</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2557">issue 2557</a>)</p></li>
<li><p>Remove bumpversion prerelease configuration (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2159">issue 2159</a>)</p></li>
<li><p>Add codecov.yml file (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2750">issue 2750</a>)</p></li>
<li><p>Set context factory implementation based on Twisted version (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2577">issue 2577</a>,
fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2560">issue 2560</a>)</p></li>
<li><p>Add omitted <code class="docutils literal notranslate"><span class="pre">self</span></code> arguments in default project middleware template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2595">issue 2595</a>)</p></li>
<li><p>Remove redundant <code class="docutils literal notranslate"><span class="pre">slot.add_request()</span></code> call in ExecutionEngine (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2617">issue 2617</a>)</p></li>
<li><p>Catch more specific <code class="docutils literal notranslate"><span class="pre">os.error</span></code> exception in <code class="xref py py-class docutils literal notranslate"><span class="pre">FSFilesStore</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2644">issue 2644</a>)</p></li>
<li><p>Change “localhost” test server certificate (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2720">issue 2720</a>)</p></li>
<li><p>Remove unused <code class="docutils literal notranslate"><span class="pre">MEMUSAGE_REPORT</span></code> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2576">issue 2576</a>)</p></li>
</ul>
</div>
<div class="section" id="documentation">
<h3>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Binary mode is required for exporters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2564">issue 2564</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2553">issue 2553</a>)</p></li>
<li><p>Mention issue with <a class="reference internal" href="topics/request-response.html#scrapy.http.FormRequest.from_response" title="scrapy.http.FormRequest.from_response"><code class="xref py py-meth docutils literal notranslate"><span class="pre">FormRequest.from_response</span></code></a> due to bug in lxml (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2572">issue 2572</a>)</p></li>
<li><p>Use single quotes uniformly in templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2596">issue 2596</a>)</p></li>
<li><p>Document <code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">ftp_user</span></code> and <code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">ftp_password</span></code> meta keys (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2587">issue 2587</a>)</p></li>
<li><p>Removed section on deprecated <code class="docutils literal notranslate"><span class="pre">contrib/</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2636">issue 2636</a>)</p></li>
<li><p>Recommend Anaconda when installing Scrapy on Windows
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2477">issue 2477</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2475">issue 2475</a>)</p></li>
<li><p>FAQ: rewrite note on Python 3 support on Windows (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2690">issue 2690</a>)</p></li>
<li><p>Rearrange selector sections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2705">issue 2705</a>)</p></li>
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">__nonzero__</span></code> from <code class="xref py py-class docutils literal notranslate"><span class="pre">SelectorList</span></code> docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2683">issue 2683</a>)</p></li>
<li><p>Mention how to disable request filtering in documentation of
<a class="reference internal" href="topics/settings.html#std:setting-DUPEFILTER_CLASS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_CLASS</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2714">issue 2714</a>)</p></li>
<li><p>Add sphinx_rtd_theme to docs setup readme (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2668">issue 2668</a>)</p></li>
<li><p>Open file in text mode in JSON item writer example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2729">issue 2729</a>)</p></li>
<li><p>Clarify <code class="docutils literal notranslate"><span class="pre">allowed_domains</span></code> example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2670">issue 2670</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-3-3-2017-03-10">
<span id="release-1-3-3"></span><h2>Scrapy 1.3.3 (2017-03-10)<a class="headerlink" href="#scrapy-1-3-3-2017-03-10" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>Bug fixes<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Make <code class="docutils literal notranslate"><span class="pre">SpiderLoader</span></code> raise <code class="docutils literal notranslate"><span class="pre">ImportError</span></code> again by default for missing
dependencies and wrong <a class="reference internal" href="topics/settings.html#std:setting-SPIDER_MODULES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MODULES</span></code></a>.
These exceptions were silenced as warnings since 1.3.0.
A new setting is introduced to toggle between warning or exception if needed ;
see <a class="reference internal" href="topics/settings.html#std:setting-SPIDER_LOADER_WARN_ONLY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_LOADER_WARN_ONLY</span></code></a> for details.</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-3-2-2017-02-13">
<span id="release-1-3-2"></span><h2>Scrapy 1.3.2 (2017-02-13)<a class="headerlink" href="#scrapy-1-3-2-2017-02-13" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id5">
<h3>Bug fixes<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Preserve request class when converting to/from dicts (utils.reqser) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2510">issue 2510</a>).</p></li>
<li><p>Use consistent selectors for author field in tutorial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2551">issue 2551</a>).</p></li>
<li><p>Fix TLS compatibility in Twisted 17+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2558">issue 2558</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-3-1-2017-02-08">
<span id="release-1-3-1"></span><h2>Scrapy 1.3.1 (2017-02-08)<a class="headerlink" href="#scrapy-1-3-1-2017-02-08" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id6">
<h3>New features<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Support <code class="docutils literal notranslate"><span class="pre">'True'</span></code> and <code class="docutils literal notranslate"><span class="pre">'False'</span></code> string values for boolean settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2519">issue 2519</a>);
you can now do something like <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">crawl</span> <span class="pre">myspider</span> <span class="pre">-s</span> <span class="pre">REDIRECT_ENABLED=False</span></code>.</p></li>
<li><p>Support kwargs with <code class="docutils literal notranslate"><span class="pre">response.xpath()</span></code> to use <a class="reference internal" href="topics/selectors.html#topics-selectors-xpath-variables"><span class="std std-ref">XPath variables</span></a>
and ad-hoc namespaces declarations ;
this requires at least Parsel v1.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2457">issue 2457</a>).</p></li>
<li><p>Add support for Python 3.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2485">issue 2485</a>).</p></li>
<li><p>Run tests on PyPy (warning: some tests still fail, so PyPy is not supported yet).</p></li>
</ul>
</div>
<div class="section" id="id7">
<h3>Bug fixes<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Enforce <code class="docutils literal notranslate"><span class="pre">DNS_TIMEOUT</span></code> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2496">issue 2496</a>).</p></li>
<li><p>Fix <a class="reference internal" href="topics/commands.html#std:command-view"><code class="xref std std-command docutils literal notranslate"><span class="pre">view</span></code></a> command ; it was a regression in v1.3.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2503">issue 2503</a>).</p></li>
<li><p>Fix tests regarding <code class="docutils literal notranslate"><span class="pre">*_EXPIRES</span> <span class="pre">settings</span></code> with Files/Images pipelines (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2460">issue 2460</a>).</p></li>
<li><p>Fix name of generated pipeline class when using basic project template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2466">issue 2466</a>).</p></li>
<li><p>Fix compatiblity with Twisted 17+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2496">issue 2496</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2528">issue 2528</a>).</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">scrapy.Item</span></code> inheritance on Python 3.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2511">issue 2511</a>).</p></li>
<li><p>Enforce numeric values for components order in <code class="docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES</span></code>,
<code class="docutils literal notranslate"><span class="pre">DOWNLOADER_MIDDLEWARES</span></code>, <code class="docutils literal notranslate"><span class="pre">EXTENIONS</span></code> and <code class="docutils literal notranslate"><span class="pre">SPIDER_CONTRACTS</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2420">issue 2420</a>).</p></li>
</ul>
</div>
<div class="section" id="id8">
<h3>Documentation<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Reword Code of Coduct section and upgrade to Contributor Covenant v1.4
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2469">issue 2469</a>).</p></li>
<li><p>Clarify that passing spider arguments converts them to spider attributes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2483">issue 2483</a>).</p></li>
<li><p>Document <code class="docutils literal notranslate"><span class="pre">formid</span></code> argument on <code class="docutils literal notranslate"><span class="pre">FormRequest.from_response()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2497">issue 2497</a>).</p></li>
<li><p>Add .rst extension to README files (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2507">issue 2507</a>).</p></li>
<li><p>Mention LevelDB cache storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2525">issue 2525</a>).</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">yield</span></code> in sample callback code (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2533">issue 2533</a>).</p></li>
<li><p>Add note about HTML entities decoding with <code class="docutils literal notranslate"><span class="pre">.re()/.re_first()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1704">issue 1704</a>).</p></li>
<li><p>Typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2512">issue 2512</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2534">issue 2534</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2531">issue 2531</a>).</p></li>
</ul>
</div>
<div class="section" id="cleanups">
<h3>Cleanups<a class="headerlink" href="#cleanups" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Remove reduntant check in <code class="docutils literal notranslate"><span class="pre">MetaRefreshMiddleware</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2542">issue 2542</a>).</p></li>
<li><p>Faster checks in <code class="docutils literal notranslate"><span class="pre">LinkExtractor</span></code> for allow/deny patterns (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2538">issue 2538</a>).</p></li>
<li><p>Remove dead code supporting old Twisted versions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2544">issue 2544</a>).</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-3-0-2016-12-21">
<span id="release-1-3-0"></span><h2>Scrapy 1.3.0 (2016-12-21)<a class="headerlink" href="#scrapy-1-3-0-2016-12-21" title="Permalink to this headline">¶</a></h2>
<p>This release comes rather soon after 1.2.2 for one main reason:
it was found out that releases since 0.18 up to 1.2.2 (included) use
some backported code from Twisted (<code class="docutils literal notranslate"><span class="pre">scrapy.xlib.tx.*</span></code>),
even if newer Twisted modules are available.
Scrapy now uses <code class="docutils literal notranslate"><span class="pre">twisted.web.client</span></code> and <code class="docutils literal notranslate"><span class="pre">twisted.internet.endpoints</span></code> directly.
(See also cleanups below.)</p>
<p>As it is a major change, we wanted to get the bug fix out quickly
while not breaking any projects using the 1.2 series.</p>
<div class="section" id="id9">
<h3>New Features<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MailSender</span></code> now accepts single strings as values for <code class="docutils literal notranslate"><span class="pre">to</span></code> and <code class="docutils literal notranslate"><span class="pre">cc</span></code>
arguments (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2272">issue 2272</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">fetch</span> <span class="pre">url</span></code>, <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">url</span></code> and <code class="docutils literal notranslate"><span class="pre">fetch(url)</span></code> inside
scrapy shell now follow HTTP redirections by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2290">issue 2290</a>);
See <a class="reference internal" href="topics/commands.html#std:command-fetch"><code class="xref std std-command docutils literal notranslate"><span class="pre">fetch</span></code></a> and <a class="reference internal" href="topics/commands.html#std:command-shell"><code class="xref std std-command docutils literal notranslate"><span class="pre">shell</span></code></a> for details.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HttpErrorMiddleware</span></code> now logs errors with <code class="docutils literal notranslate"><span class="pre">INFO</span></code> level instead of <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code>;
this is technically <strong>backwards incompatible</strong> so please check your log parsers.</p></li>
<li><p>By default, logger names now use a long-form path, e.g. <code class="docutils literal notranslate"><span class="pre">[scrapy.extensions.logstats]</span></code>,
instead of the shorter “top-level” variant of prior releases (e.g. <code class="docutils literal notranslate"><span class="pre">[scrapy]</span></code>);
this is <strong>backwards incompatible</strong> if you have log parsers expecting the short
logger name part. You can switch back to short logger names using <a class="reference internal" href="topics/settings.html#std:setting-LOG_SHORT_NAMES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">LOG_SHORT_NAMES</span></code></a>
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</div>
<div class="section" id="dependencies-cleanups">
<h3>Dependencies &amp; Cleanups<a class="headerlink" href="#dependencies-cleanups" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scrapy now requires Twisted &gt;= 13.1 which is the case for many Linux
distributions already.</p></li>
<li><p>As a consequence, we got rid of <code class="docutils literal notranslate"><span class="pre">scrapy.xlib.tx.*</span></code> modules, which
copied some of Twisted code for users stuck with an “old” Twisted version</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ChunkedTransferMiddleware</span></code> is deprecated and removed from the default
downloader middlewares.</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-2-3-2017-03-03">
<span id="release-1-2-3"></span><h2>Scrapy 1.2.3 (2017-03-03)<a class="headerlink" href="#scrapy-1-2-3-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Packaging fix: disallow unsupported Twisted versions in setup.py</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-2-2-2016-12-06">
<span id="release-1-2-2"></span><h2>Scrapy 1.2.2 (2016-12-06)<a class="headerlink" href="#scrapy-1-2-2-2016-12-06" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id10">
<h3>Bug fixes<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Fix a cryptic traceback when a pipeline fails on <code class="docutils literal notranslate"><span class="pre">open_spider()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2011">issue 2011</a>)</p></li>
<li><p>Fix embedded IPython shell variables (fixing <a class="reference external" href="https://github.com/scrapy/scrapy/issues/396">issue 396</a> that re-appeared
in 1.2.0, fixed in <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2418">issue 2418</a>)</p></li>
<li><p>A couple of patches when dealing with robots.txt:</p>
<ul>
<li><p>handle (non-standard) relative sitemap URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2390">issue 2390</a>)</p></li>
<li><p>handle non-ASCII URLs and User-Agents in Python 2 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2373">issue 2373</a>)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id11">
<h3>Documentation<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Document <code class="docutils literal notranslate"><span class="pre">&quot;download_latency&quot;</span></code> key in <code class="docutils literal notranslate"><span class="pre">Request</span></code>’s <code class="docutils literal notranslate"><span class="pre">meta</span></code> dict (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2033">issue 2033</a>)</p></li>
<li><p>Remove page on (deprecated &amp; unsupported) Ubuntu packages from ToC (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2335">issue 2335</a>)</p></li>
<li><p>A few fixed typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2346">issue 2346</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2369">issue 2369</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2369">issue 2369</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2380">issue 2380</a>)
and clarifications (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2354">issue 2354</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2325">issue 2325</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2414">issue 2414</a>)</p></li>
</ul>
</div>
<div class="section" id="other-changes">
<h3>Other changes<a class="headerlink" href="#other-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Advertize <a class="reference external" href="https://anaconda.org/conda-forge/scrapy">conda-forge</a> as Scrapy’s official conda channel (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2387">issue 2387</a>)</p></li>
<li><p>More helpful error messages when trying to use <code class="docutils literal notranslate"><span class="pre">.css()</span></code> or <code class="docutils literal notranslate"><span class="pre">.xpath()</span></code>
on non-Text Responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2264">issue 2264</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">startproject</span></code> command now generates a sample <code class="docutils literal notranslate"><span class="pre">middlewares.py</span></code> file (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2335">issue 2335</a>)</p></li>
<li><p>Add more dependencies’ version info in <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span></code> verbose output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2404">issue 2404</a>)</p></li>
<li><p>Remove all <code class="docutils literal notranslate"><span class="pre">*.pyc</span></code> files from source distribution (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2386">issue 2386</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-2-1-2016-10-21">
<span id="release-1-2-1"></span><h2>Scrapy 1.2.1 (2016-10-21)<a class="headerlink" href="#scrapy-1-2-1-2016-10-21" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id12">
<h3>Bug fixes<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Include OpenSSL’s more permissive default ciphers when establishing
TLS/SSL connections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2314">issue 2314</a>).</p></li>
<li><p>Fix “Location” HTTP header decoding on non-ASCII URL redirects (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2321">issue 2321</a>).</p></li>
</ul>
</div>
<div class="section" id="id13">
<h3>Documentation<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Fix JsonWriterPipeline example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2302">issue 2302</a>).</p></li>
<li><p>Various notes: <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2330">issue 2330</a> on spider names,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2329">issue 2329</a> on middleware methods processing order,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2327">issue 2327</a> on getting multi-valued HTTP headers as lists.</p></li>
</ul>
</div>
<div class="section" id="id14">
<h3>Other changes<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">www.</span></code> from <code class="docutils literal notranslate"><span class="pre">start_urls</span></code> in built-in spider templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2299">issue 2299</a>).</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-2-0-2016-10-03">
<span id="release-1-2-0"></span><h2>Scrapy 1.2.0 (2016-10-03)<a class="headerlink" href="#scrapy-1-2-0-2016-10-03" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id15">
<h3>New Features<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>New <a class="reference internal" href="topics/feed-exports.html#std:setting-FEED_EXPORT_ENCODING"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FEED_EXPORT_ENCODING</span></code></a> setting to customize the encoding
used when writing items to a file.
This can be used to turn off <code class="docutils literal notranslate"><span class="pre">\uXXXX</span></code> escapes in JSON output.
This is also useful for those wanting something else than UTF-8
for XML or CSV output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2034">issue 2034</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">startproject</span></code> command now supports an optional destination directory
to override the default one based on the project name (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2005">issue 2005</a>).</p></li>
<li><p>New <a class="reference internal" href="topics/settings.html#std:setting-SCHEDULER_DEBUG"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SCHEDULER_DEBUG</span></code></a> setting to log requests serialization
failures (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1610">issue 1610</a>).</p></li>
<li><p>JSON encoder now supports serialization of <code class="docutils literal notranslate"><span class="pre">set</span></code> instances (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2058">issue 2058</a>).</p></li>
<li><p>Interpret <code class="docutils literal notranslate"><span class="pre">application/json-amazonui-streaming</span></code> as <code class="docutils literal notranslate"><span class="pre">TextResponse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1503">issue 1503</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy</span></code> is imported by default when using shell tools (<a class="reference internal" href="topics/commands.html#std:command-shell"><code class="xref std std-command docutils literal notranslate"><span class="pre">shell</span></code></a>,
<a class="reference internal" href="topics/shell.html#topics-shell-inspect-response"><span class="std std-ref">inspect_response</span></a>) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2248">issue 2248</a>).</p></li>
</ul>
</div>
<div class="section" id="id16">
<h3>Bug fixes<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>DefaultRequestHeaders middleware now runs before UserAgent middleware
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2088">issue 2088</a>). <strong>Warning: this is technically backwards incompatible</strong>,
though we consider this a bug fix.</p></li>
<li><p>HTTP cache extension and plugins that use the <code class="docutils literal notranslate"><span class="pre">.scrapy</span></code> data directory now
work outside projects (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1581">issue 1581</a>).  <strong>Warning: this is technically
backwards incompatible</strong>, though we consider this a bug fix.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Selector</span></code> does not allow passing both <code class="docutils literal notranslate"><span class="pre">response</span></code> and <code class="docutils literal notranslate"><span class="pre">text</span></code> anymore
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2153">issue 2153</a>).</p></li>
<li><p>Fixed logging of wrong callback name with <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2169">issue 2169</a>).</p></li>
<li><p>Fix for an odd gzip decompression bug (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1606">issue 1606</a>).</p></li>
<li><p>Fix for selected callbacks when using <code class="docutils literal notranslate"><span class="pre">CrawlSpider</span></code> with <a class="reference internal" href="topics/commands.html#std:command-parse"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span></code></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2225">issue 2225</a>).</p></li>
<li><p>Fix for invalid JSON and XML files when spider yields no items (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/872">issue 872</a>).</p></li>
<li><p>Implement <code class="docutils literal notranslate"><span class="pre">flush()</span></code> fpr <code class="docutils literal notranslate"><span class="pre">StreamLogger</span></code> avoiding a warning in logs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2125">issue 2125</a>).</p></li>
</ul>
</div>
<div class="section" id="refactoring">
<h3>Refactoring<a class="headerlink" href="#refactoring" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">canonicalize_url</span></code> has been moved to <a class="reference external" href="https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.url.canonicalize_url">w3lib.url</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2168">issue 2168</a>).</p></li>
</ul>
</div>
<div class="section" id="tests-requirements">
<h3>Tests &amp; Requirements<a class="headerlink" href="#tests-requirements" title="Permalink to this headline">¶</a></h3>
<p>Scrapy’s new requirements baseline is Debian 8 “Jessie”. It was previously
Ubuntu 12.04 Precise.
What this means in practice is that we run continuous integration tests
with these (main) packages versions at a minimum:
Twisted 14.0, pyOpenSSL 0.14, lxml 3.4.</p>
<p>Scrapy may very well work with older versions of these packages
(the code base still has switches for older Twisted versions for example)
but it is not guaranteed (because it’s not tested anymore).</p>
</div>
<div class="section" id="id17">
<h3>Documentation<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Grammar fixes: <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2128">issue 2128</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1566">issue 1566</a>.</p></li>
<li><p>Download stats badge removed from README (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2160">issue 2160</a>).</p></li>
<li><p>New scrapy <a class="reference internal" href="topics/architecture.html#topics-architecture"><span class="std std-ref">architecture diagram</span></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2165">issue 2165</a>).</p></li>
<li><p>Updated <code class="docutils literal notranslate"><span class="pre">Response</span></code> parameters documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2197">issue 2197</a>).</p></li>
<li><p>Reworded misleading <a class="reference internal" href="topics/settings.html#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a> description (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2190">issue 2190</a>).</p></li>
<li><p>Add StackOverflow as a support channel (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2257">issue 2257</a>).</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-4-2017-03-03">
<span id="release-1-1-4"></span><h2>Scrapy 1.1.4 (2017-03-03)<a class="headerlink" href="#scrapy-1-1-4-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Packaging fix: disallow unsupported Twisted versions in setup.py</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-1-3-2016-09-22">
<span id="release-1-1-3"></span><h2>Scrapy 1.1.3 (2016-09-22)<a class="headerlink" href="#scrapy-1-1-3-2016-09-22" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id18">
<h3>Bug fixes<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Class attributes for subclasses of <code class="docutils literal notranslate"><span class="pre">ImagesPipeline</span></code> and <code class="docutils literal notranslate"><span class="pre">FilesPipeline</span></code>
work as they did before 1.1.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2243">issue 2243</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2198">issue 2198</a>)</p></li>
</ul>
</div>
<div class="section" id="id19">
<h3>Documentation<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference internal" href="intro/overview.html#intro-overview"><span class="std std-ref">Overview</span></a> and <a class="reference internal" href="intro/tutorial.html#intro-tutorial"><span class="std std-ref">tutorial</span></a>
rewritten to use <a class="reference external" href="http://toscrape.com">http://toscrape.com</a> websites
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2236">issue 2236</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2249">issue 2249</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2252">issue 2252</a>).</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-2-2016-08-18">
<span id="release-1-1-2"></span><h2>Scrapy 1.1.2 (2016-08-18)<a class="headerlink" href="#scrapy-1-1-2-2016-08-18" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id20">
<h3>Bug fixes<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Introduce a missing <a class="reference internal" href="topics/media-pipeline.html#std:setting-IMAGES_STORE_S3_ACL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">IMAGES_STORE_S3_ACL</span></code></a> setting to override
the default ACL policy in <code class="docutils literal notranslate"><span class="pre">ImagesPipeline</span></code> when uploading images to S3
(note that default ACL policy is “private” – instead of “public-read” –
since Scrapy 1.1.0)</p></li>
<li><p><a class="reference internal" href="topics/media-pipeline.html#std:setting-IMAGES_EXPIRES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">IMAGES_EXPIRES</span></code></a> default value set back to 90
(the regression was introduced in 1.1.1)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-1-2016-07-13">
<span id="release-1-1-1"></span><h2>Scrapy 1.1.1 (2016-07-13)<a class="headerlink" href="#scrapy-1-1-1-2016-07-13" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id21">
<h3>Bug fixes<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Add “Host” header in CONNECT requests to HTTPS proxies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2069">issue 2069</a>)</p></li>
<li><p>Use response <code class="docutils literal notranslate"><span class="pre">body</span></code> when choosing response class
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2001">issue 2001</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2000">issue 2000</a>)</p></li>
<li><p>Do not fail on canonicalizing URLs with wrong netlocs
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2038">issue 2038</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2010">issue 2010</a>)</p></li>
<li><p>a few fixes for <code class="docutils literal notranslate"><span class="pre">HttpCompressionMiddleware</span></code> (and <code class="docutils literal notranslate"><span class="pre">SitemapSpider</span></code>):</p>
<ul>
<li><p>Do not decode HEAD responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2008">issue 2008</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1899">issue 1899</a>)</p></li>
<li><p>Handle charset parameter in gzip Content-Type header
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2050">issue 2050</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2049">issue 2049</a>)</p></li>
<li><p>Do not decompress gzip octet-stream responses
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2065">issue 2065</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2063">issue 2063</a>)</p></li>
</ul>
</li>
<li><p>Catch (and ignore with a warning) exception when verifying certificate
against IP-address hosts (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2094">issue 2094</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2092">issue 2092</a>)</p></li>
<li><p>Make <code class="docutils literal notranslate"><span class="pre">FilesPipeline</span></code> and <code class="docutils literal notranslate"><span class="pre">ImagesPipeline</span></code> backward compatible again
regarding the use of legacy class attributes for customization
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1989">issue 1989</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1985">issue 1985</a>)</p></li>
</ul>
</div>
<div class="section" id="id22">
<h3>New features<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Enable genspider command outside project folder (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2052">issue 2052</a>)</p></li>
<li><p>Retry HTTPS CONNECT <code class="docutils literal notranslate"><span class="pre">TunnelError</span></code> by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1974">issue 1974</a>)</p></li>
</ul>
</div>
<div class="section" id="id23">
<h3>Documentation<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">FEED_TEMPDIR</span></code> setting at lexicographical position (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9b3c72c">commit 9b3c72c</a>)</p></li>
<li><p>Use idiomatic <code class="docutils literal notranslate"><span class="pre">.extract_first()</span></code> in overview (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1994">issue 1994</a>)</p></li>
<li><p>Update years in copyright notice (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c2c8036">commit c2c8036</a>)</p></li>
<li><p>Add information and example on errbacks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1995">issue 1995</a>)</p></li>
<li><p>Use “url” variable in downloader middleware example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2015">issue 2015</a>)</p></li>
<li><p>Grammar fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2054">issue 2054</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2120">issue 2120</a>)</p></li>
<li><p>New FAQ entry on using BeautifulSoup in spider callbacks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2048">issue 2048</a>)</p></li>
<li><p>Add notes about scrapy not working on Windows with Python 3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2060">issue 2060</a>)</p></li>
<li><p>Encourage complete titles in pull requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2026">issue 2026</a>)</p></li>
</ul>
</div>
<div class="section" id="tests">
<h3>Tests<a class="headerlink" href="#tests" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Upgrade py.test requirement on Travis CI and Pin pytest-cov to 2.2.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2095">issue 2095</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-0-2016-05-11">
<span id="release-1-1-0"></span><h2>Scrapy 1.1.0 (2016-05-11)<a class="headerlink" href="#scrapy-1-1-0-2016-05-11" title="Permalink to this headline">¶</a></h2>
<p>This 1.1 release brings a lot of interesting features and bug fixes:</p>
<ul class="simple">
<li><p>Scrapy 1.1 has beta Python 3 support (requires Twisted &gt;= 15.5). See
<a class="reference internal" href="#news-betapy3"><span class="std std-ref">Beta Python 3 Support</span></a> for more details and some limitations.</p></li>
<li><p>Hot new features:</p>
<ul>
<li><p>Item loaders now support nested loaders (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1467">issue 1467</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FormRequest.from_response</span></code> improvements (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1382">issue 1382</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1137">issue 1137</a>).</p></li>
<li><p>Added setting <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AUTOTHROTTLE_TARGET_CONCURRENCY</span></code></a> and improved
AutoThrottle docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1324">issue 1324</a>).</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">response.text</span></code> to get body as unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1730">issue 1730</a>).</p></li>
<li><p>Anonymous S3 connections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1358">issue 1358</a>).</p></li>
<li><p>Deferreds in downloader middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1473">issue 1473</a>). This enables better
robots.txt handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1471">issue 1471</a>).</p></li>
<li><p>HTTP caching now follows RFC2616 more closely, added settings
<a class="reference internal" href="topics/downloader-middleware.html#std:setting-HTTPCACHE_ALWAYS_STORE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">HTTPCACHE_ALWAYS_STORE</span></code></a> and
<a class="reference internal" href="topics/downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1151">issue 1151</a>).</p></li>
<li><p>Selectors were extracted to the <a class="reference external" href="https://github.com/scrapy/parsel">parsel</a> library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1409">issue 1409</a>). This means
you can use Scrapy Selectors without Scrapy and also upgrade the
selectors engine without needing to upgrade Scrapy.</p></li>
<li><p>HTTPS downloader now does TLS protocol negotiation by default,
instead of forcing TLS 1.0. You can also set the SSL/TLS method
using the new <a class="reference internal" href="topics/settings.html#std:setting-DOWNLOADER_CLIENT_TLS_METHOD"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOADER_CLIENT_TLS_METHOD</span></code></a>.</p></li>
</ul>
</li>
<li><p>These bug fixes may require your attention:</p>
<ul>
<li><p>Don’t retry bad requests (HTTP 400) by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1289">issue 1289</a>).
If you need the old behavior, add <code class="docutils literal notranslate"><span class="pre">400</span></code> to <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_HTTP_CODES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_HTTP_CODES</span></code></a>.</p></li>
<li><p>Fix shell files argument handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1710">issue 1710</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1550">issue 1550</a>).
If you try <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">index.html</span></code> it will try to load the URL <a class="reference external" href="http://index.html">http://index.html</a>,
use <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">./index.html</span></code> to load a local file.</p></li>
<li><p>Robots.txt compliance is now enabled by default for newly-created projects
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1724">issue 1724</a>). Scrapy will also wait for robots.txt to be downloaded
before proceeding with the crawl (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1735">issue 1735</a>). If you want to disable
this behavior, update <a class="reference internal" href="topics/settings.html#std:setting-ROBOTSTXT_OBEY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">ROBOTSTXT_OBEY</span></code></a> in <code class="docutils literal notranslate"><span class="pre">settings.py</span></code> file
after creating a new project.</p></li>
<li><p>Exporters now work on unicode, instead of bytes by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1080">issue 1080</a>).
If you use <code class="docutils literal notranslate"><span class="pre">PythonItemExporter</span></code>, you may want to update your code to
disable binary mode which is now deprecated.</p></li>
<li><p>Accept XML node names containing dots as valid (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1533">issue 1533</a>).</p></li>
<li><p>When uploading files or images to S3 (with <code class="docutils literal notranslate"><span class="pre">FilesPipeline</span></code> or
<code class="docutils literal notranslate"><span class="pre">ImagesPipeline</span></code>), the default ACL policy is now “private” instead
of “public” <strong>Warning: backwards incompatible!</strong>.
You can use <a class="reference internal" href="topics/media-pipeline.html#std:setting-FILES_STORE_S3_ACL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FILES_STORE_S3_ACL</span></code></a> to change it.</p></li>
<li><p>We’ve reimplemented <code class="docutils literal notranslate"><span class="pre">canonicalize_url()</span></code> for more correct output,
especially for URLs with non-ASCII characters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1947">issue 1947</a>).
This could change link extractors output compared to previous scrapy versions.
This may also invalidate some cache entries you could still have from pre-1.1 runs.
<strong>Warning: backwards incompatible!</strong>.</p></li>
</ul>
</li>
</ul>
<p>Keep reading for more details on other improvements and bug fixes.</p>
<div class="section" id="beta-python-3-support">
<span id="news-betapy3"></span><h3>Beta Python 3 Support<a class="headerlink" href="#beta-python-3-support" title="Permalink to this headline">¶</a></h3>
<p>We have been <a class="reference external" href="https://github.com/scrapy/scrapy/wiki/Python-3-Porting">hard at work to make Scrapy run on Python 3</a>. As a result, now
you can run spiders on Python 3.3, 3.4 and 3.5 (Twisted &gt;= 15.5 required). Some
features are still missing (and some may never be ported).</p>
<p>Almost all builtin extensions/middlewares are expected to work.
However, we are aware of some limitations in Python 3:</p>
<ul class="simple">
<li><p>Scrapy does not work on Windows with Python 3</p></li>
<li><p>Sending emails is not supported</p></li>
<li><p>FTP download handler is not supported</p></li>
<li><p>Telnet console is not supported</p></li>
</ul>
</div>
<div class="section" id="additional-new-features-and-enhancements">
<h3>Additional New Features and Enhancements<a class="headerlink" href="#additional-new-features-and-enhancements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scrapy now has a <a class="reference external" href="https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md">Code of Conduct</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1681">issue 1681</a>).</p></li>
<li><p>Command line tool now has completion for zsh (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/934">issue 934</a>).</p></li>
<li><p>Improvements to <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span></code>:</p>
<ul>
<li><p>Support for bpython and configure preferred Python shell via
<code class="docutils literal notranslate"><span class="pre">SCRAPY_PYTHON_SHELL</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1100">issue 1100</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1444">issue 1444</a>).</p></li>
<li><p>Support URLs without scheme (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1498">issue 1498</a>)
<strong>Warning: backwards incompatible!</strong></p></li>
<li><p>Bring back support for relative file path (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1710">issue 1710</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1550">issue 1550</a>).</p></li>
</ul>
</li>
<li><p>Added <a class="reference internal" href="topics/settings.html#std:setting-MEMUSAGE_CHECK_INTERVAL_SECONDS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_CHECK_INTERVAL_SECONDS</span></code></a> setting to change default check
interval (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1282">issue 1282</a>).</p></li>
<li><p>Download handlers are now lazy-loaded on first request using their
scheme (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1390">issue 1390</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1421">issue 1421</a>).</p></li>
<li><p>HTTPS download handlers do not force TLS 1.0 anymore; instead,
OpenSSL’s <code class="docutils literal notranslate"><span class="pre">SSLv23_method()/TLS_method()</span></code> is used allowing to try
negotiating with the remote hosts the highest TLS protocol version
it can (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1794">issue 1794</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1629">issue 1629</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RedirectMiddleware</span></code> now skips the status codes from
<code class="docutils literal notranslate"><span class="pre">handle_httpstatus_list</span></code> on spider attribute
or in <code class="docutils literal notranslate"><span class="pre">Request</span></code>’s <code class="docutils literal notranslate"><span class="pre">meta</span></code> key (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1334">issue 1334</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1364">issue 1364</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1447">issue 1447</a>).</p></li>
<li><p>Form submission:</p>
<ul>
<li><p>now works with <code class="docutils literal notranslate"><span class="pre">&lt;button&gt;</span></code> elements too (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1469">issue 1469</a>).</p></li>
<li><p>an empty string is now used for submit buttons without a value
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1472">issue 1472</a>)</p></li>
</ul>
</li>
<li><p>Dict-like settings now have per-key priorities
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1135">issue 1135</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1149">issue 1149</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1586">issue 1586</a>).</p></li>
<li><p>Sending non-ASCII emails (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1662">issue 1662</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CloseSpider</span></code> and <code class="docutils literal notranslate"><span class="pre">SpiderState</span></code> extensions now get disabled if no relevant
setting is set (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1723">issue 1723</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1725">issue 1725</a>).</p></li>
<li><p>Added method <code class="docutils literal notranslate"><span class="pre">ExecutionEngine.close</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1423">issue 1423</a>).</p></li>
<li><p>Added method <code class="docutils literal notranslate"><span class="pre">CrawlerRunner.create_crawler</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1528">issue 1528</a>).</p></li>
<li><p>Scheduler priority queue can now be customized via
<a class="reference internal" href="topics/settings.html#std:setting-SCHEDULER_PRIORITY_QUEUE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SCHEDULER_PRIORITY_QUEUE</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1822">issue 1822</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.pps</span></code> links are now ignored by default in link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1835">issue 1835</a>).</p></li>
<li><p>temporary data folder for FTP and S3 feed storages can be customized
using a new <a class="reference internal" href="topics/settings.html#std:setting-FEED_TEMPDIR"><code class="xref std std-setting docutils literal notranslate"><span class="pre">FEED_TEMPDIR</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1847">issue 1847</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FilesPipeline</span></code> and <code class="docutils literal notranslate"><span class="pre">ImagesPipeline</span></code> settings are now instance attributes
instead of class attributes, enabling spider-specific behaviors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1891">issue 1891</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">JsonItemExporter</span></code> now formats opening and closing square brackets
on their own line (first and last lines of output file) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1950">issue 1950</a>).</p></li>
<li><p>If available, <code class="docutils literal notranslate"><span class="pre">botocore</span></code> is used for <code class="docutils literal notranslate"><span class="pre">S3FeedStorage</span></code>, <code class="docutils literal notranslate"><span class="pre">S3DownloadHandler</span></code>
and <code class="docutils literal notranslate"><span class="pre">S3FilesStore</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1761">issue 1761</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1883">issue 1883</a>).</p></li>
<li><p>Tons of documentation updates and related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1291">issue 1291</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1302">issue 1302</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1335">issue 1335</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1683">issue 1683</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1660">issue 1660</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1642">issue 1642</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1721">issue 1721</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1727">issue 1727</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1879">issue 1879</a>).</p></li>
<li><p>Other refactoring, optimizations and cleanup (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1476">issue 1476</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1481">issue 1481</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1477">issue 1477</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1315">issue 1315</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1290">issue 1290</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1750">issue 1750</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1881">issue 1881</a>).</p></li>
</ul>
</div>
<div class="section" id="deprecations-and-removals">
<h3>Deprecations and Removals<a class="headerlink" href="#deprecations-and-removals" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">to_bytes</span></code> and <code class="docutils literal notranslate"><span class="pre">to_unicode</span></code>, deprecated <code class="docutils literal notranslate"><span class="pre">str_to_unicode</span></code> and
<code class="docutils literal notranslate"><span class="pre">unicode_to_str</span></code> functions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/778">issue 778</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">binary_is_text</span></code> is introduced, to replace use of <code class="docutils literal notranslate"><span class="pre">isbinarytext</span></code>
(but with inverse return value) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1851">issue 1851</a>)</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">optional_features</span></code> set has been removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1359">issue 1359</a>).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">--lsprof</span></code> command line option has been removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1689">issue 1689</a>).
<strong>Warning: backward incompatible</strong>, but doesn’t break user code.</p></li>
<li><p>The following datatypes were deprecated (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1720">issue 1720</a>):</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.utils.datatypes.MultiValueDictKeyError</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.utils.datatypes.MultiValueDict</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.utils.datatypes.SiteNode</span></code></p></li>
</ul>
</li>
<li><p>The previously bundled <code class="docutils literal notranslate"><span class="pre">scrapy.xlib.pydispatch</span></code> library was deprecated and
replaced by <a class="reference external" href="https://pypi.python.org/pypi/PyDispatcher">pydispatcher</a>.</p></li>
</ul>
</div>
<div class="section" id="relocations">
<h3>Relocations<a class="headerlink" href="#relocations" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">telnetconsole</span></code> was relocated to <code class="docutils literal notranslate"><span class="pre">extensions/</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1524">issue 1524</a>).</p>
<ul>
<li><p>Note: telnet is not enabled on Python 3
(<a class="reference external" href="https://github.com/scrapy/scrapy/pull/1524#issuecomment-146985595">https://github.com/scrapy/scrapy/pull/1524#issuecomment-146985595</a>)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="bugfixes">
<h3>Bugfixes<a class="headerlink" href="#bugfixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scrapy does not retry requests that got a <code class="docutils literal notranslate"><span class="pre">HTTP</span> <span class="pre">400</span> <span class="pre">Bad</span> <span class="pre">Request</span></code>
response anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1289">issue 1289</a>). <strong>Warning: backwards incompatible!</strong></p></li>
<li><p>Support empty password for http_proxy config (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1274">issue 1274</a>).</p></li>
<li><p>Interpret <code class="docutils literal notranslate"><span class="pre">application/x-json</span></code> as <code class="docutils literal notranslate"><span class="pre">TextResponse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1333">issue 1333</a>).</p></li>
<li><p>Support link rel attribute with multiple values (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1201">issue 1201</a>).</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">scrapy.http.FormRequest.from_response</span></code> when there is a <code class="docutils literal notranslate"><span class="pre">&lt;base&gt;</span></code>
tag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1564">issue 1564</a>).</p></li>
<li><p>Fixed <a class="reference internal" href="topics/settings.html#std:setting-TEMPLATES_DIR"><code class="xref std std-setting docutils literal notranslate"><span class="pre">TEMPLATES_DIR</span></code></a> handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1575">issue 1575</a>).</p></li>
<li><p>Various <code class="docutils literal notranslate"><span class="pre">FormRequest</span></code> fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1595">issue 1595</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1596">issue 1596</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1597">issue 1597</a>).</p></li>
<li><p>Makes <code class="docutils literal notranslate"><span class="pre">_monkeypatches</span></code> more robust (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1634">issue 1634</a>).</p></li>
<li><p>Fixed bug on <code class="docutils literal notranslate"><span class="pre">XMLItemExporter</span></code> with non-string fields in
items (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1738">issue 1738</a>).</p></li>
<li><p>Fixed startproject command in OS X (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1635">issue 1635</a>).</p></li>
<li><p>Fixed PythonItemExporter and CSVExporter for non-string item
types (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1737">issue 1737</a>).</p></li>
<li><p>Various logging related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1294">issue 1294</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1419">issue 1419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1263">issue 1263</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1624">issue 1624</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1654">issue 1654</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1722">issue 1722</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1726">issue 1726</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1303">issue 1303</a>).</p></li>
<li><p>Fixed bug in <code class="docutils literal notranslate"><span class="pre">utils.template.render_templatefile()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1212">issue 1212</a>).</p></li>
<li><p>sitemaps extraction from <code class="docutils literal notranslate"><span class="pre">robots.txt</span></code> is now case-insensitive (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1902">issue 1902</a>).</p></li>
<li><p>HTTPS+CONNECT tunnels could get mixed up when using multiple proxies
to same remote host (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1912">issue 1912</a>).</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-0-7-2017-03-03">
<span id="release-1-0-7"></span><h2>Scrapy 1.0.7 (2017-03-03)<a class="headerlink" href="#scrapy-1-0-7-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Packaging fix: disallow unsupported Twisted versions in setup.py</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-6-2016-05-04">
<span id="release-1-0-6"></span><h2>Scrapy 1.0.6 (2016-05-04)<a class="headerlink" href="#scrapy-1-0-6-2016-05-04" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>FIX: RetryMiddleware is now robust to non-standard HTTP status codes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1857">issue 1857</a>)</p></li>
<li><p>FIX: Filestorage HTTP cache was checking wrong modified time (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1875">issue 1875</a>)</p></li>
<li><p>DOC: Support for Sphinx 1.4+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1893">issue 1893</a>)</p></li>
<li><p>DOC: Consistency in selectors examples (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1869">issue 1869</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-5-2016-02-04">
<span id="release-1-0-5"></span><h2>Scrapy 1.0.5 (2016-02-04)<a class="headerlink" href="#scrapy-1-0-5-2016-02-04" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>FIX: [Backport] Ignore bogus links in LinkExtractors (fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/907">issue 907</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/108195e">commit 108195e</a>)</p></li>
<li><p>TST: Changed buildbot makefile to use ‘pytest’ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1f3d90a">commit 1f3d90a</a>)</p></li>
<li><p>DOC: Fixed typos in tutorial and media-pipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/808a9ea">commit 808a9ea</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/commit/803bd87">commit 803bd87</a>)</p></li>
<li><p>DOC: Add AjaxCrawlMiddleware to DOWNLOADER_MIDDLEWARES_BASE in settings docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/aa94121">commit aa94121</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-4-2015-12-30">
<span id="release-1-0-4"></span><h2>Scrapy 1.0.4 (2015-12-30)<a class="headerlink" href="#scrapy-1-0-4-2015-12-30" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Ignoring xlib/tx folder, depending on Twisted version. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7dfa979">commit 7dfa979</a>)</p></li>
<li><p>Run on new travis-ci infra (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6e42f0b">commit 6e42f0b</a>)</p></li>
<li><p>Spelling fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/823a1cc">commit 823a1cc</a>)</p></li>
<li><p>escape nodename in xmliter regex (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/da3c155">commit da3c155</a>)</p></li>
<li><p>test xml nodename with dots (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4418fc3">commit 4418fc3</a>)</p></li>
<li><p>TST don’t use broken Pillow version in tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a55078c">commit a55078c</a>)</p></li>
<li><p>disable log on version command. closes #1426 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86fc330">commit 86fc330</a>)</p></li>
<li><p>disable log on startproject command (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/db4c9fe">commit db4c9fe</a>)</p></li>
<li><p>Add PyPI download stats badge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/df2b944">commit df2b944</a>)</p></li>
<li><p>don’t run tests twice on Travis if a PR is made from a scrapy/scrapy branch (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a83ab41">commit a83ab41</a>)</p></li>
<li><p>Add Python 3 porting status badge to the README (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/73ac80d">commit 73ac80d</a>)</p></li>
<li><p>fixed RFPDupeFilter persistence (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/97d080e">commit 97d080e</a>)</p></li>
<li><p>TST a test to show that dupefilter persistence is not working (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/97f2fb3">commit 97f2fb3</a>)</p></li>
<li><p>explicit close file on <a class="reference external" href="file://">file://</a> scheme handler (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d9b4850">commit d9b4850</a>)</p></li>
<li><p>Disable dupefilter in shell (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c0d0734">commit c0d0734</a>)</p></li>
<li><p>DOC: Add captions to toctrees which appear in sidebar (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/aa239ad">commit aa239ad</a>)</p></li>
<li><p>DOC Removed pywin32 from install instructions as it’s already declared as dependency. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10eb400">commit 10eb400</a>)</p></li>
<li><p>Added installation notes about using Conda for Windows and other OSes. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1c3600a">commit 1c3600a</a>)</p></li>
<li><p>Fixed minor grammar issues. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7f4ddd5">commit 7f4ddd5</a>)</p></li>
<li><p>fixed a typo in the documentation. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b71f677">commit b71f677</a>)</p></li>
<li><p>Version 1 now exists (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5456c0e">commit 5456c0e</a>)</p></li>
<li><p>fix another invalid xpath error (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a1366e">commit 0a1366e</a>)</p></li>
<li><p>fix ValueError: Invalid XPath: //div/[id=”not-exists”]/text() on selectors.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ca8d60f">commit ca8d60f</a>)</p></li>
<li><p>Typos corrections (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7067117">commit 7067117</a>)</p></li>
<li><p>fix typos in downloader-middleware.rst and exceptions.rst, middlware -&gt; middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/32f115c">commit 32f115c</a>)</p></li>
<li><p>Add note to ubuntu install section about debian compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/23fda69">commit 23fda69</a>)</p></li>
<li><p>Replace alternative OSX install workaround with virtualenv (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98b63ee">commit 98b63ee</a>)</p></li>
<li><p>Reference Homebrew’s homepage for installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1925db1">commit 1925db1</a>)</p></li>
<li><p>Add oldest supported tox version to contributing docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5d10d6d">commit 5d10d6d</a>)</p></li>
<li><p>Note in install docs about pip being already included in python&gt;=2.7.9 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/85c980e">commit 85c980e</a>)</p></li>
<li><p>Add non-python dependencies to Ubuntu install section in the docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fbd010d">commit fbd010d</a>)</p></li>
<li><p>Add OS X installation section to docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d8f4cba">commit d8f4cba</a>)</p></li>
<li><p>DOC(ENH): specify path to rtd theme explicitly (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de73b1a">commit de73b1a</a>)</p></li>
<li><p>minor: scrapy.Spider docs grammar (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1ddcc7b">commit 1ddcc7b</a>)</p></li>
<li><p>Make common practices sample code match the comments (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1b85bcf">commit 1b85bcf</a>)</p></li>
<li><p>nextcall repetitive calls (heartbeats). (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/55f7104">commit 55f7104</a>)</p></li>
<li><p>Backport fix compatibility with Twisted 15.4.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b262411">commit b262411</a>)</p></li>
<li><p>pin pytest to 2.7.3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a6535c2">commit a6535c2</a>)</p></li>
<li><p>Merge pull request #1512 from mgedmin/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8876111">commit 8876111</a>)</p></li>
<li><p>Merge pull request #1513 from mgedmin/patch-2 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5d4daf8">commit 5d4daf8</a>)</p></li>
<li><p>Typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f8d0682">commit f8d0682</a>)</p></li>
<li><p>Fix list formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f83a93">commit 5f83a93</a>)</p></li>
<li><p>fix scrapy squeue tests after recent changes to queuelib (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3365c01">commit 3365c01</a>)</p></li>
<li><p>Merge pull request #1475 from rweindl/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2d688cd">commit 2d688cd</a>)</p></li>
<li><p>Update tutorial.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fbc1f25">commit fbc1f25</a>)</p></li>
<li><p>Merge pull request #1449 from rhoekman/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7d6538c">commit 7d6538c</a>)</p></li>
<li><p>Small grammatical change (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8752294">commit 8752294</a>)</p></li>
<li><p>Add openssl version to version command (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c45ac">commit 13c45ac</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-3-2015-08-11">
<span id="release-1-0-3"></span><h2>Scrapy 1.0.3 (2015-08-11)<a class="headerlink" href="#scrapy-1-0-3-2015-08-11" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>add service_identity to scrapy install_requires (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cbc2501">commit cbc2501</a>)</p></li>
<li><p>Workaround for travis#296 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/66af9cd">commit 66af9cd</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-2-2015-08-06">
<span id="release-1-0-2"></span><h2>Scrapy 1.0.2 (2015-08-06)<a class="headerlink" href="#scrapy-1-0-2-2015-08-06" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Twisted 15.3.0 does not raises PicklingError serializing lambda functions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b04dd7d">commit b04dd7d</a>)</p></li>
<li><p>Minor method name fix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f85c7f">commit 6f85c7f</a>)</p></li>
<li><p>minor: scrapy.Spider grammar and clarity (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9c9d2e0">commit 9c9d2e0</a>)</p></li>
<li><p>Put a blurb about support channels in CONTRIBUTING (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c63882b">commit c63882b</a>)</p></li>
<li><p>Fixed typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a9ae7b0">commit a9ae7b0</a>)</p></li>
<li><p>Fix doc reference. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7c8a4fe">commit 7c8a4fe</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-1-2015-07-01">
<span id="release-1-0-1"></span><h2>Scrapy 1.0.1 (2015-07-01)<a class="headerlink" href="#scrapy-1-0-1-2015-07-01" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Unquote request path before passing to FTPClient, it already escape paths (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc00ad2">commit cc00ad2</a>)</p></li>
<li><p>include tests/ to source distribution in MANIFEST.in (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/eca227e">commit eca227e</a>)</p></li>
<li><p>DOC Fix SelectJmes documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b8567bc">commit b8567bc</a>)</p></li>
<li><p>DOC Bring Ubuntu and Archlinux outside of Windows subsection (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/392233f">commit 392233f</a>)</p></li>
<li><p>DOC remove version suffix from ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5303c66">commit 5303c66</a>)</p></li>
<li><p>DOC Update release date for 1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c89fa29">commit c89fa29</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-1-0-0-2015-06-19">
<span id="release-1-0-0"></span><h2>Scrapy 1.0.0 (2015-06-19)<a class="headerlink" href="#scrapy-1-0-0-2015-06-19" title="Permalink to this headline">¶</a></h2>
<p>You will find a lot of new features and bugfixes in this major release.  Make
sure to check our updated <a class="reference internal" href="intro/overview.html#intro-overview"><span class="std std-ref">overview</span></a> to get a glance of
some of the changes, along with our brushed <a class="reference internal" href="intro/tutorial.html#intro-tutorial"><span class="std std-ref">tutorial</span></a>.</p>
<div class="section" id="support-for-returning-dictionaries-in-spiders">
<h3>Support for returning dictionaries in spiders<a class="headerlink" href="#support-for-returning-dictionaries-in-spiders" title="Permalink to this headline">¶</a></h3>
<p>Declaring and returning Scrapy Items is no longer necessary to collect the
scraped data from your spider, you can now return explicit dictionaries
instead.</p>
<p><em>Classic version</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MyItem</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p><em>New version</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="per-spider-settings-gsoc-2014">
<h3>Per-spider settings (GSoC 2014)<a class="headerlink" href="#per-spider-settings-gsoc-2014" title="Permalink to this headline">¶</a></h3>
<p>Last Google Summer of Code project accomplished an important redesign of the
mechanism used for populating settings, introducing explicit priorities to
override any given setting. As an extension of that goal, we included a new
level of priority for settings that act exclusively for a single spider,
allowing them to redefine project settings.</p>
<p>Start using it by defining a <a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.custom_settings" title="scrapy.spiders.Spider.custom_settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">custom_settings</span></code></a>
class variable in your spider:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;DOWNLOAD_DELAY&quot;</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>
        <span class="s2">&quot;RETRY_ENABLED&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
</div>
<p>Read more about settings population: <a class="reference internal" href="topics/settings.html#topics-settings"><span class="std std-ref">设置</span></a></p>
</div>
<div class="section" id="python-logging">
<h3>Python Logging<a class="headerlink" href="#python-logging" title="Permalink to this headline">¶</a></h3>
<p>Scrapy 1.0 has moved away from Twisted logging to support Python built in’s
as default logging system. We’re maintaining backward compatibility for most
of the old custom interface to call logging functions, but you’ll get
warnings to switch to the Python logging API entirely.</p>
<p><em>Old version</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy</span> <span class="k">import</span> <span class="n">log</span>
<span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s1">&#39;MESSAGE&#39;</span><span class="p">,</span> <span class="n">log</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>
</div>
<p><em>New version</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;MESSAGE&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Logging with spiders remains the same, but on top of the
<a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.log" title="scrapy.spiders.Spider.log"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code></a> method you’ll have access to a custom
<a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.logger" title="scrapy.spiders.Spider.logger"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logger</span></code></a> created for the spider to issue log
events:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Response received&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Read more in the logging documentation: <a class="reference internal" href="topics/logging.html#topics-logging"><span class="std std-ref">Logging</span></a></p>
</div>
<div class="section" id="crawler-api-refactoring-gsoc-2014">
<h3>Crawler API refactoring (GSoC 2014)<a class="headerlink" href="#crawler-api-refactoring-gsoc-2014" title="Permalink to this headline">¶</a></h3>
<p>Another milestone for last Google Summer of Code was a refactoring of the
internal API, seeking a simpler and easier usage. Check new core interface
in: <a class="reference internal" href="topics/api.html#topics-api"><span class="std std-ref">Core API</span></a></p>
<p>A common situation where you will face these changes is while running Scrapy
from scripts. Here’s a quick example of how to run a Spider manually with the
new API:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="k">import</span> <span class="n">CrawlerProcess</span>

<span class="n">process</span> <span class="o">=</span> <span class="n">CrawlerProcess</span><span class="p">({</span>
    <span class="s1">&#39;USER_AGENT&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)&#39;</span>
<span class="p">})</span>
<span class="n">process</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">MySpider</span><span class="p">)</span>
<span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>Bear in mind this feature is still under development and its API may change
until it reaches a stable status.</p>
<p>See more examples for scripts running Scrapy: <a class="reference internal" href="topics/practices.html#topics-practices"><span class="std std-ref">Common Practices</span></a></p>
</div>
<div class="section" id="module-relocations">
<span id="id24"></span><h3>Module Relocations<a class="headerlink" href="#module-relocations" title="Permalink to this headline">¶</a></h3>
<p>There’s been a large rearrangement of modules trying to improve the general
structure of Scrapy. Main changes were separating various subpackages into
new projects and dissolving both <cite>scrapy.contrib</cite> and <cite>scrapy.contrib_exp</cite>
into top level packages. Backward compatibility was kept among internal
relocations, while importing deprecated modules expect warnings indicating
their new place.</p>
<div class="section" id="full-list-of-relocations">
<h4>Full list of relocations<a class="headerlink" href="#full-list-of-relocations" title="Permalink to this headline">¶</a></h4>
<p>Outsourced packages</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These extensions went through some minor changes, e.g. some setting names
were changed. Please check the documentation in each new repository to
get familiar with the new usage.</p>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Old location</p></th>
<th class="head"><p>New location</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>scrapy.commands.deploy</p></td>
<td><p><a class="reference external" href="https://github.com/scrapy/scrapyd-client">scrapyd-client</a>
(See other alternatives here:
<a class="reference internal" href="topics/deploy.html#topics-deploy"><span class="std std-ref">Deploying Spiders</span></a>)</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib.djangoitem</p></td>
<td><p><a class="reference external" href="https://github.com/scrapy-plugins/scrapy-djangoitem">scrapy-djangoitem</a></p></td>
</tr>
<tr class="row-even"><td><p>scrapy.webservice</p></td>
<td><p><a class="reference external" href="https://github.com/scrapy-plugins/scrapy-jsonrpc">scrapy-jsonrpc</a></p></td>
</tr>
</tbody>
</table>
<p><cite>scrapy.contrib_exp</cite> and <cite>scrapy.contrib</cite> dissolutions</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Old location</p></th>
<th class="head"><p>New location</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>scrapy.contrib_exp.downloadermiddleware.decompression</p></td>
<td><p>scrapy.downloadermiddlewares.decompression</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib_exp.iterators</p></td>
<td><p>scrapy.utils.iterators</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.contrib.downloadermiddleware</p></td>
<td><p>scrapy.downloadermiddlewares</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib.exporter</p></td>
<td><p>scrapy.exporters</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.contrib.linkextractors</p></td>
<td><p>scrapy.linkextractors</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib.loader</p></td>
<td><p>scrapy.loader</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.contrib.loader.processor</p></td>
<td><p>scrapy.loader.processors</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib.pipeline</p></td>
<td><p>scrapy.pipelines</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.contrib.spidermiddleware</p></td>
<td><p>scrapy.spidermiddlewares</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.contrib.spiders</p></td>
<td><p>scrapy.spiders</p></td>
</tr>
<tr class="row-even"><td><ul class="simple">
<li><p>scrapy.contrib.closespider</p></li>
<li><p>scrapy.contrib.corestats</p></li>
<li><p>scrapy.contrib.debug</p></li>
<li><p>scrapy.contrib.feedexport</p></li>
<li><p>scrapy.contrib.httpcache</p></li>
<li><p>scrapy.contrib.logstats</p></li>
<li><p>scrapy.contrib.memdebug</p></li>
<li><p>scrapy.contrib.memusage</p></li>
<li><p>scrapy.contrib.spiderstate</p></li>
<li><p>scrapy.contrib.statsmailer</p></li>
<li><p>scrapy.contrib.throttle</p></li>
</ul>
</td>
<td><p>scrapy.extensions.*</p></td>
</tr>
</tbody>
</table>
<p>Plural renames and Modules unification</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Old location</p></th>
<th class="head"><p>New location</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>scrapy.command</p></td>
<td><p>scrapy.commands</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.dupefilter</p></td>
<td><p>scrapy.dupefilters</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.linkextractor</p></td>
<td><p>scrapy.linkextractors</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.spider</p></td>
<td><p>scrapy.spiders</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.squeue</p></td>
<td><p>scrapy.squeues</p></td>
</tr>
<tr class="row-odd"><td><p>scrapy.statscol</p></td>
<td><p>scrapy.statscollectors</p></td>
</tr>
<tr class="row-even"><td><p>scrapy.utils.decorator</p></td>
<td><p>scrapy.utils.decorators</p></td>
</tr>
</tbody>
</table>
<p>Class renames</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Old location</p></th>
<th class="head"><p>New location</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>scrapy.spidermanager.SpiderManager</p></td>
<td><p>scrapy.spiderloader.SpiderLoader</p></td>
</tr>
</tbody>
</table>
<p>Settings renames</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Old location</p></th>
<th class="head"><p>New location</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SPIDER_MANAGER_CLASS</p></td>
<td><p>SPIDER_LOADER_CLASS</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="changelog">
<h3>Changelog<a class="headerlink" href="#changelog" title="Permalink to this headline">¶</a></h3>
<p>New Features and Enhancements</p>
<ul class="simple">
<li><p>Python logging (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1060">issue 1060</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1235">issue 1235</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1236">issue 1236</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1240">issue 1240</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1259">issue 1259</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1278">issue 1278</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1286">issue 1286</a>)</p></li>
<li><p>FEED_EXPORT_FIELDS option (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1159">issue 1159</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1224">issue 1224</a>)</p></li>
<li><p>Dns cache size and timeout options (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1132">issue 1132</a>)</p></li>
<li><p>support namespace prefix in xmliter_lxml (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/963">issue 963</a>)</p></li>
<li><p>Reactor threadpool max size setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1123">issue 1123</a>)</p></li>
<li><p>Allow spiders to return dicts. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1081">issue 1081</a>)</p></li>
<li><p>Add Response.urljoin() helper (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1086">issue 1086</a>)</p></li>
<li><p>look in ~/.config/scrapy.cfg for user config (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1098">issue 1098</a>)</p></li>
<li><p>handle TLS SNI (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1101">issue 1101</a>)</p></li>
<li><p>Selectorlist extract first (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/624">issue 624</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1145">issue 1145</a>)</p></li>
<li><p>Added JmesSelect (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1016">issue 1016</a>)</p></li>
<li><p>add gzip compression to filesystem http cache backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1020">issue 1020</a>)</p></li>
<li><p>CSS support in link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/983">issue 983</a>)</p></li>
<li><p>httpcache dont_cache meta #19 #689 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/821">issue 821</a>)</p></li>
<li><p>add signal to be sent when request is dropped by the scheduler
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/961">issue 961</a>)</p></li>
<li><p>avoid download large response (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/946">issue 946</a>)</p></li>
<li><p>Allow to specify the quotechar in CSVFeedSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/882">issue 882</a>)</p></li>
<li><p>Add referer to “Spider error processing” log message (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/795">issue 795</a>)</p></li>
<li><p>process robots.txt once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/896">issue 896</a>)</p></li>
<li><p>GSoC Per-spider settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/854">issue 854</a>)</p></li>
<li><p>Add project name validation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/817">issue 817</a>)</p></li>
<li><p>GSoC API cleanup (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/816">issue 816</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1128">issue 1128</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1147">issue 1147</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1148">issue 1148</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1156">issue 1156</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1185">issue 1185</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1187">issue 1187</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1258">issue 1258</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1268">issue 1268</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1276">issue 1276</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1285">issue 1285</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1284">issue 1284</a>)</p></li>
<li><p>Be more responsive with IO operations (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1074">issue 1074</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1075">issue 1075</a>)</p></li>
<li><p>Do leveldb compaction for httpcache on closing (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1297">issue 1297</a>)</p></li>
</ul>
<p>Deprecations and Removals</p>
<ul class="simple">
<li><p>Deprecate htmlparser link extractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1205">issue 1205</a>)</p></li>
<li><p>remove deprecated code from FeedExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1155">issue 1155</a>)</p></li>
<li><p>a leftover for.15 compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/925">issue 925</a>)</p></li>
<li><p>drop support for CONCURRENT_REQUESTS_PER_SPIDER (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/895">issue 895</a>)</p></li>
<li><p>Drop old engine code (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/911">issue 911</a>)</p></li>
<li><p>Deprecate SgmlLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/777">issue 777</a>)</p></li>
</ul>
<p>Relocations</p>
<ul class="simple">
<li><p>Move exporters/__init__.py to exporters.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1242">issue 1242</a>)</p></li>
<li><p>Move base classes to their packages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1218">issue 1218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1233">issue 1233</a>)</p></li>
<li><p>Module relocation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1181">issue 1181</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1210">issue 1210</a>)</p></li>
<li><p>rename SpiderManager to SpiderLoader (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1166">issue 1166</a>)</p></li>
<li><p>Remove djangoitem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1177">issue 1177</a>)</p></li>
<li><p>remove scrapy deploy command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1102">issue 1102</a>)</p></li>
<li><p>dissolve contrib_exp (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1134">issue 1134</a>)</p></li>
<li><p>Deleted bin folder from root, fixes #913 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/914">issue 914</a>)</p></li>
<li><p>Remove jsonrpc based webservice (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/859">issue 859</a>)</p></li>
<li><p>Move Test cases under project root dir (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/827">issue 827</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/841">issue 841</a>)</p></li>
<li><p>Fix backward incompatibility for relocated paths in settings
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1267">issue 1267</a>)</p></li>
</ul>
<p>Documentation</p>
<ul class="simple">
<li><p>CrawlerProcess documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1190">issue 1190</a>)</p></li>
<li><p>Favoring web scraping over screen scraping in the descriptions
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1188">issue 1188</a>)</p></li>
<li><p>Some improvements for Scrapy tutorial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1180">issue 1180</a>)</p></li>
<li><p>Documenting Files Pipeline together with Images Pipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1150">issue 1150</a>)</p></li>
<li><p>deployment docs tweaks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1164">issue 1164</a>)</p></li>
<li><p>Added deployment section covering scrapyd-deploy and shub (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1124">issue 1124</a>)</p></li>
<li><p>Adding more settings to project template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1073">issue 1073</a>)</p></li>
<li><p>some improvements to overview page (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1106">issue 1106</a>)</p></li>
<li><p>Updated link in docs/topics/architecture.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/647">issue 647</a>)</p></li>
<li><p>DOC reorder topics (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1022">issue 1022</a>)</p></li>
<li><p>updating list of Request.meta special keys (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1071">issue 1071</a>)</p></li>
<li><p>DOC document download_timeout (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/898">issue 898</a>)</p></li>
<li><p>DOC simplify extension docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/893">issue 893</a>)</p></li>
<li><p>Leaks docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/894">issue 894</a>)</p></li>
<li><p>DOC document from_crawler method for item pipelines (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/904">issue 904</a>)</p></li>
<li><p>Spider_error doesn’t support deferreds (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1292">issue 1292</a>)</p></li>
<li><p>Corrections &amp; Sphinx related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1220">issue 1220</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1219">issue 1219</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1196">issue 1196</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1172">issue 1172</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1171">issue 1171</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1169">issue 1169</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1160">issue 1160</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1154">issue 1154</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1127">issue 1127</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1112">issue 1112</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1105">issue 1105</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1041">issue 1041</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1082">issue 1082</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1033">issue 1033</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/944">issue 944</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/866">issue 866</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/864">issue 864</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/796">issue 796</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1260">issue 1260</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1271">issue 1271</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1293">issue 1293</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1298">issue 1298</a>)</p></li>
</ul>
<p>Bugfixes</p>
<ul class="simple">
<li><p>Item multi inheritance fix (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/353">issue 353</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1228">issue 1228</a>)</p></li>
<li><p>ItemLoader.load_item: iterate over copy of fields (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/722">issue 722</a>)</p></li>
<li><p>Fix Unhandled error in Deferred (RobotsTxtMiddleware) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1131">issue 1131</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1197">issue 1197</a>)</p></li>
<li><p>Force to read DOWNLOAD_TIMEOUT as int (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/954">issue 954</a>)</p></li>
<li><p>scrapy.utils.misc.load_object should print full traceback (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/902">issue 902</a>)</p></li>
<li><p>Fix bug for “.local” host name (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/878">issue 878</a>)</p></li>
<li><p>Fix for Enabled extensions, middlewares, pipelines info not printed
anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/879">issue 879</a>)</p></li>
<li><p>fix dont_merge_cookies bad behaviour when set to false on meta
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/846">issue 846</a>)</p></li>
</ul>
<p>Python 3 In Progress Support</p>
<ul class="simple">
<li><p>disable scrapy.telnet if twisted.conch is not available (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1161">issue 1161</a>)</p></li>
<li><p>fix Python 3 syntax errors in ajaxcrawl.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1162">issue 1162</a>)</p></li>
<li><p>more python3 compatibility changes for urllib (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1121">issue 1121</a>)</p></li>
<li><p>assertItemsEqual was renamed to assertCountEqual in Python 3.
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1070">issue 1070</a>)</p></li>
<li><p>Import unittest.mock if available. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1066">issue 1066</a>)</p></li>
<li><p>updated deprecated cgi.parse_qsl to use six’s parse_qsl (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/909">issue 909</a>)</p></li>
<li><p>Prevent Python 3 port regressions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/830">issue 830</a>)</p></li>
<li><p>PY3: use MutableMapping for python 3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/810">issue 810</a>)</p></li>
<li><p>PY3: use six.BytesIO and six.moves.cStringIO (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/803">issue 803</a>)</p></li>
<li><p>PY3: fix xmlrpclib and email imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/801">issue 801</a>)</p></li>
<li><p>PY3: use six for robotparser and urlparse (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/800">issue 800</a>)</p></li>
<li><p>PY3: use six.iterkeys, six.iteritems, and tempfile (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/799">issue 799</a>)</p></li>
<li><p>PY3: fix has_key and use six.moves.configparser (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/798">issue 798</a>)</p></li>
<li><p>PY3: use six.moves.cPickle (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/797">issue 797</a>)</p></li>
<li><p>PY3 make it possible to run some tests in Python3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/776">issue 776</a>)</p></li>
</ul>
<p>Tests</p>
<ul class="simple">
<li><p>remove unnecessary lines from py3-ignores (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1243">issue 1243</a>)</p></li>
<li><p>Fix remaining warnings from pytest while collecting tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1206">issue 1206</a>)</p></li>
<li><p>Add docs build to travis (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1234">issue 1234</a>)</p></li>
<li><p>TST don’t collect tests from deprecated modules. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1165">issue 1165</a>)</p></li>
<li><p>install service_identity package in tests to prevent warnings
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1168">issue 1168</a>)</p></li>
<li><p>Fix deprecated settings API in tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1152">issue 1152</a>)</p></li>
<li><p>Add test for webclient with POST method and no body given (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1089">issue 1089</a>)</p></li>
<li><p>py3-ignores.txt supports comments (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1044">issue 1044</a>)</p></li>
<li><p>modernize some of the asserts (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/835">issue 835</a>)</p></li>
<li><p>selector.__repr__ test (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/779">issue 779</a>)</p></li>
</ul>
<p>Code refactoring</p>
<ul class="simple">
<li><p>CSVFeedSpider cleanup: use iterate_spider_output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1079">issue 1079</a>)</p></li>
<li><p>remove unnecessary check from scrapy.utils.spider.iter_spider_output
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1078">issue 1078</a>)</p></li>
<li><p>Pydispatch pep8 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/992">issue 992</a>)</p></li>
<li><p>Removed unused ‘load=False’ parameter from walk_modules() (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/871">issue 871</a>)</p></li>
<li><p>For consistency, use <cite>job_dir</cite> helper in <cite>SpiderState</cite> extension.
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/805">issue 805</a>)</p></li>
<li><p>rename “sflo” local variables to less cryptic “log_observer” (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/775">issue 775</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-24-6-2015-04-20">
<h2>Scrapy 0.24.6 (2015-04-20)<a class="headerlink" href="#scrapy-0-24-6-2015-04-20" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>encode invalid xpath with unicode_escape under PY2 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/07cb3e5">commit 07cb3e5</a>)</p></li>
<li><p>fix IPython shell scope issue and load IPython user config (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2c8e573">commit 2c8e573</a>)</p></li>
<li><p>Fix small typo in the docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d694019">commit d694019</a>)</p></li>
<li><p>Fix small typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f92fa83">commit f92fa83</a>)</p></li>
<li><p>Converted sel.xpath() calls to response.xpath() in Extracting the data (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c2c6d15">commit c2c6d15</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-5-2015-02-25">
<h2>Scrapy 0.24.5 (2015-02-25)<a class="headerlink" href="#scrapy-0-24-5-2015-02-25" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Support new _getEndpoint Agent signatures on Twisted 15.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/540b9bc">commit 540b9bc</a>)</p></li>
<li><p>DOC a couple more references are fixed (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4c454b">commit b4c454b</a>)</p></li>
<li><p>DOC fix a reference (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3c1260">commit e3c1260</a>)</p></li>
<li><p>t.i.b.ThreadedResolver is now a new-style class (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9e13f42">commit 9e13f42</a>)</p></li>
<li><p>S3DownloadHandler: fix auth for requests with quoted paths/query params (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cdb9a0b">commit cdb9a0b</a>)</p></li>
<li><p>fixed the variable types in mailsender documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb3a848">commit bb3a848</a>)</p></li>
<li><p>Reset items_scraped instead of item_count (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/edb07a4">commit edb07a4</a>)</p></li>
<li><p>Tentative attention message about what document to read for contributions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7ee6f7a">commit 7ee6f7a</a>)</p></li>
<li><p>mitmproxy 0.10.1 needs netlib 0.10.1 too (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/874fcdd">commit 874fcdd</a>)</p></li>
<li><p>pin mitmproxy 0.10.1 as &gt;0.11 does not work with tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c6b21f0">commit c6b21f0</a>)</p></li>
<li><p>Test the parse command locally instead of against an external url (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c3a6628">commit c3a6628</a>)</p></li>
<li><p>Patches Twisted issue while closing the connection pool on HTTPDownloadHandler (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0bf957">commit d0bf957</a>)</p></li>
<li><p>Updates documentation on dynamic item classes. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/eeb589a">commit eeb589a</a>)</p></li>
<li><p>Merge pull request #943 from Lazar-T/patch-3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5fdab02">commit 5fdab02</a>)</p></li>
<li><p>typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b0ae199">commit b0ae199</a>)</p></li>
<li><p>pywin32 is required by Twisted. closes #937 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5cb0cfb">commit 5cb0cfb</a>)</p></li>
<li><p>Update install.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/781286b">commit 781286b</a>)</p></li>
<li><p>Merge pull request #928 from Lazar-T/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b415d04">commit b415d04</a>)</p></li>
<li><p>comma instead of fullstop (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/627b9ba">commit 627b9ba</a>)</p></li>
<li><p>Merge pull request #885 from jsma/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de909ad">commit de909ad</a>)</p></li>
<li><p>Update request-response.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3f3263d">commit 3f3263d</a>)</p></li>
<li><p>SgmlLinkExtractor - fix for parsing &lt;area&gt; tag with Unicode present (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/49b40f0">commit 49b40f0</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-4-2014-08-09">
<h2>Scrapy 0.24.4 (2014-08-09)<a class="headerlink" href="#scrapy-0-24-4-2014-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>pem file is used by mockserver and required by scrapy bench (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5eddc68">commit 5eddc68</a>)</p></li>
<li><p>scrapy bench needs scrapy.tests* (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d6cb999">commit d6cb999</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-3-2014-08-09">
<h2>Scrapy 0.24.3 (2014-08-09)<a class="headerlink" href="#scrapy-0-24-3-2014-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>no need to waste travis-ci time on py3 for 0.24 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e080c1">commit 8e080c1</a>)</p></li>
<li><p>Update installation docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1d0c096">commit 1d0c096</a>)</p></li>
<li><p>There is a trove classifier for Scrapy framework! (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4c701d7">commit 4c701d7</a>)</p></li>
<li><p>update other places where w3lib version is mentioned (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d109c13">commit d109c13</a>)</p></li>
<li><p>Update w3lib requirement to 1.8.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/39d2ce5">commit 39d2ce5</a>)</p></li>
<li><p>Use w3lib.html.replace_entities() (remove_entities() is deprecated) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/180d3ad">commit 180d3ad</a>)</p></li>
<li><p>set zip_safe=False (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a51ee8b">commit a51ee8b</a>)</p></li>
<li><p>do not ship tests package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ee3b371">commit ee3b371</a>)</p></li>
<li><p>scrapy.bat is not needed anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c3861cf">commit c3861cf</a>)</p></li>
<li><p>Modernize setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/362e322">commit 362e322</a>)</p></li>
<li><p>headers can not handle non-string values (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/94a5c65">commit 94a5c65</a>)</p></li>
<li><p>fix ftp test cases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274a7f">commit a274a7f</a>)</p></li>
<li><p>The sum up of travis-ci builds are taking like 50min to complete (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ae1e2cc">commit ae1e2cc</a>)</p></li>
<li><p>Update shell.rst typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e49c96a">commit e49c96a</a>)</p></li>
<li><p>removes weird indentation in the shell results (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1ca489d">commit 1ca489d</a>)</p></li>
<li><p>improved explanations, clarified blog post as source, added link for XPath string functions in the spec (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/65c8f05">commit 65c8f05</a>)</p></li>
<li><p>renamed UserTimeoutError and ServerTimeouterror #583 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/037f6ab">commit 037f6ab</a>)</p></li>
<li><p>adding some xpath tips to selectors docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2d103e0">commit 2d103e0</a>)</p></li>
<li><p>fix tests to account for <a class="reference external" href="https://github.com/scrapy/w3lib/pull/23">https://github.com/scrapy/w3lib/pull/23</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f8d366a">commit f8d366a</a>)</p></li>
<li><p>get_func_args maximum recursion fix #728 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/81344ea">commit 81344ea</a>)</p></li>
<li><p>Updated input/ouput processor example according to #560. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f7c4ea8">commit f7c4ea8</a>)</p></li>
<li><p>Fixed Python syntax in tutorial. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/db59ed9">commit db59ed9</a>)</p></li>
<li><p>Add test case for tunneling proxy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f090260">commit f090260</a>)</p></li>
<li><p>Bugfix for leaking Proxy-Authorization header to remote host when using tunneling (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d8793af">commit d8793af</a>)</p></li>
<li><p>Extract links from XHTML documents with MIME-Type “application/xml” (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ed1f376">commit ed1f376</a>)</p></li>
<li><p>Merge pull request #793 from roysc/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/91a1106">commit 91a1106</a>)</p></li>
<li><p>Fix typo in commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/743e1e2">commit 743e1e2</a>)</p></li>
<li><p>better testcase for settings.overrides.setdefault (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e22daaf">commit e22daaf</a>)</p></li>
<li><p>Using CRLF as line marker according to http 1.1 definition (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ec430b">commit 5ec430b</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-2-2014-07-08">
<h2>Scrapy 0.24.2 (2014-07-08)<a class="headerlink" href="#scrapy-0-24-2-2014-07-08" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Use a mutable mapping to proxy deprecated settings.overrides and settings.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e5e8133">commit e5e8133</a>)</p></li>
<li><p>there is not support for python3 yet (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3cd6146">commit 3cd6146</a>)</p></li>
<li><p>Update python compatible version set to debian packages (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa5d76b">commit fa5d76b</a>)</p></li>
<li><p>DOC fix formatting in release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c6a9e20">commit c6a9e20</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-1-2014-06-27">
<h2>Scrapy 0.24.1 (2014-06-27)<a class="headerlink" href="#scrapy-0-24-1-2014-06-27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Fix deprecated CrawlerSettings and increase backwards compatibility with
.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e3f20a">commit 8e3f20a</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-24-0-2014-06-26">
<h2>Scrapy 0.24.0 (2014-06-26)<a class="headerlink" href="#scrapy-0-24-0-2014-06-26" title="Permalink to this headline">¶</a></h2>
<div class="section" id="enhancements">
<h3>Enhancements<a class="headerlink" href="#enhancements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Improve Scrapy top-level namespace (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/494">issue 494</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/684">issue 684</a>)</p></li>
<li><p>Add selector shortcuts to responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/554">issue 554</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/690">issue 690</a>)</p></li>
<li><p>Add new lxml based LinkExtractor to replace unmantained SgmlLinkExtractor
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/559">issue 559</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/761">issue 761</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/763">issue 763</a>)</p></li>
<li><p>Cleanup settings API - part of per-spider settings <strong>GSoC project</strong> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/737">issue 737</a>)</p></li>
<li><p>Add UTF8 encoding header to templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/688">issue 688</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/762">issue 762</a>)</p></li>
<li><p>Telnet console now binds to 127.0.0.1 by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/699">issue 699</a>)</p></li>
<li><p>Update debian/ubuntu install instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/509">issue 509</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/549">issue 549</a>)</p></li>
<li><p>Disable smart strings in lxml XPath evaluations (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/535">issue 535</a>)</p></li>
<li><p>Restore filesystem based cache as default for http
cache middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/571">issue 571</a>)</p></li>
<li><p>Expose current crawler in Scrapy shell (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/557">issue 557</a>)</p></li>
<li><p>Improve testsuite comparing CSV and XML exporters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/570">issue 570</a>)</p></li>
<li><p>New <cite>offsite/filtered</cite> and <cite>offsite/domains</cite> stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/566">issue 566</a>)</p></li>
<li><p>Support process_links as generator in CrawlSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/555">issue 555</a>)</p></li>
<li><p>Verbose logging and new stats counters for DupeFilter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/553">issue 553</a>)</p></li>
<li><p>Add a mimetype parameter to <cite>MailSender.send()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/602">issue 602</a>)</p></li>
<li><p>Generalize file pipeline log messages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/622">issue 622</a>)</p></li>
<li><p>Replace unencodeable codepoints with html entities in SGMLLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/565">issue 565</a>)</p></li>
<li><p>Converted SEP documents to rst format (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/629">issue 629</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/630">issue 630</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/638">issue 638</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/632">issue 632</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/636">issue 636</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/640">issue 640</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/635">issue 635</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/634">issue 634</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/639">issue 639</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/637">issue 637</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/631">issue 631</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/633">issue 633</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/641">issue 641</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/642">issue 642</a>)</p></li>
<li><p>Tests and docs for clickdata’s nr index in FormRequest (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/646">issue 646</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/645">issue 645</a>)</p></li>
<li><p>Allow to disable a downloader handler just like any other component (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/650">issue 650</a>)</p></li>
<li><p>Log when a request is discarded after too many redirections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>)</p></li>
<li><p>Log error responses if they are not handled by spider callbacks
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/612">issue 612</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/656">issue 656</a>)</p></li>
<li><p>Add content-type check to http compression mw (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/193">issue 193</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/660">issue 660</a>)</p></li>
<li><p>Run pypy tests using latest pypi from ppa (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/674">issue 674</a>)</p></li>
<li><p>Run test suite using pytest instead of trial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/679">issue 679</a>)</p></li>
<li><p>Build docs and check for dead links in tox environment (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/687">issue 687</a>)</p></li>
<li><p>Make scrapy.version_info a tuple of integers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/681">issue 681</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/692">issue 692</a>)</p></li>
<li><p>Infer exporter’s output format from filename extensions
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/546">issue 546</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/659">issue 659</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/760">issue 760</a>)</p></li>
<li><p>Support case-insensitive domains in <cite>url_is_from_any_domain()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/693">issue 693</a>)</p></li>
<li><p>Remove pep8 warnings in project and spider templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/698">issue 698</a>)</p></li>
<li><p>Tests and docs for <cite>request_fingerprint</cite> function (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/597">issue 597</a>)</p></li>
<li><p>Update SEP-19 for GSoC project <cite>per-spider settings</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/705">issue 705</a>)</p></li>
<li><p>Set exit code to non-zero when contracts fails (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/727">issue 727</a>)</p></li>
<li><p>Add a setting to control what class is instanciated as Downloader component
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/738">issue 738</a>)</p></li>
<li><p>Pass response in <cite>item_dropped</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/724">issue 724</a>)</p></li>
<li><p>Improve <cite>scrapy check</cite> contracts command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/733">issue 733</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/752">issue 752</a>)</p></li>
<li><p>Document <cite>spider.closed()</cite> shortcut (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/719">issue 719</a>)</p></li>
<li><p>Document <cite>request_scheduled</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/746">issue 746</a>)</p></li>
<li><p>Add a note about reporting security issues (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/697">issue 697</a>)</p></li>
<li><p>Add LevelDB http cache storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/626">issue 626</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>)</p></li>
<li><p>Sort spider list output of <cite>scrapy list</cite> command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/742">issue 742</a>)</p></li>
<li><p>Multiple documentation enhancemens and fixes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/575">issue 575</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/587">issue 587</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/590">issue 590</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/596">issue 596</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/610">issue 610</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/617">issue 617</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/618">issue 618</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/627">issue 627</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/613">issue 613</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/643">issue 643</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/675">issue 675</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/663">issue 663</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/711">issue 711</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/714">issue 714</a>)</p></li>
</ul>
</div>
<div class="section" id="id25">
<h3>Bugfixes<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Encode unicode URL value when creating Links in RegexLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/561">issue 561</a>)</p></li>
<li><p>Ignore None values in ItemLoader processors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/556">issue 556</a>)</p></li>
<li><p>Fix link text when there is an inner tag in SGMLLinkExtractor and
HtmlParserLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/485">issue 485</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/574">issue 574</a>)</p></li>
<li><p>Fix wrong checks on subclassing of deprecated classes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/581">issue 581</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/584">issue 584</a>)</p></li>
<li><p>Handle errors caused by inspect.stack() failures (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/582">issue 582</a>)</p></li>
<li><p>Fix a reference to unexistent engine attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/593">issue 593</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/594">issue 594</a>)</p></li>
<li><p>Fix dynamic itemclass example usage of type() (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/603">issue 603</a>)</p></li>
<li><p>Use lucasdemarchi/codespell to fix typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/628">issue 628</a>)</p></li>
<li><p>Fix default value of attrs argument in SgmlLinkExtractor to be tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/661">issue 661</a>)</p></li>
<li><p>Fix XXE flaw in sitemap reader (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/676">issue 676</a>)</p></li>
<li><p>Fix engine to support filtered start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/707">issue 707</a>)</p></li>
<li><p>Fix offsite middleware case on urls with no hostnames (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/745">issue 745</a>)</p></li>
<li><p>Testsuite doesn’t require PIL anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/585">issue 585</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-22-2-released-2014-02-14">
<h2>Scrapy 0.22.2 (released 2014-02-14)<a class="headerlink" href="#scrapy-0-22-2-released-2014-02-14" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>fix a reference to unexistent engine.slots. closes #593 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c099a">commit 13c099a</a>)</p></li>
<li><p>downloaderMW doc typo (spiderMW doc copy remnant) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8ae11bf">commit 8ae11bf</a>)</p></li>
<li><p>Correct typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1346037">commit 1346037</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-22-1-released-2014-02-08">
<h2>Scrapy 0.22.1 (released 2014-02-08)<a class="headerlink" href="#scrapy-0-22-1-released-2014-02-08" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>localhost666 can resolve under certain circumstances (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2ec2279">commit 2ec2279</a>)</p></li>
<li><p>test inspect.stack failure (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc3eda3">commit cc3eda3</a>)</p></li>
<li><p>Handle cases when inspect.stack() fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8cb44f9">commit 8cb44f9</a>)</p></li>
<li><p>Fix wrong checks on subclassing of deprecated classes. closes #581 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/46d98d6">commit 46d98d6</a>)</p></li>
<li><p>Docs: 4-space indent for final spider example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13846de">commit 13846de</a>)</p></li>
<li><p>Fix HtmlParserLinkExtractor and tests after #485 merge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/368a946">commit 368a946</a>)</p></li>
<li><p>BaseSgmlLinkExtractor: Fixed the missing space when the link has an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b566388">commit b566388</a>)</p></li>
<li><p>BaseSgmlLinkExtractor: Added unit test of a link with an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c1cb418">commit c1cb418</a>)</p></li>
<li><p>BaseSgmlLinkExtractor: Fixed unknown_endtag() so that it only set current_link=None when the end tag match the opening tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7e4d627">commit 7e4d627</a>)</p></li>
<li><p>Fix tests for Travis-CI build (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/76c7e20">commit 76c7e20</a>)</p></li>
<li><p>replace unencodeable codepoints with html entities. fixes #562 and #285 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f87b17">commit 5f87b17</a>)</p></li>
<li><p>RegexLinkExtractor: encode URL unicode value when creating Links (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0ee545">commit d0ee545</a>)</p></li>
<li><p>Updated the tutorial crawl output with latest output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8da65de">commit 8da65de</a>)</p></li>
<li><p>Updated shell docs with the crawler reference and fixed the actual shell output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/875b9ab">commit 875b9ab</a>)</p></li>
<li><p>PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f89efaf">commit f89efaf</a>)</p></li>
<li><p>Expose current crawler in the scrapy shell. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5349cec">commit 5349cec</a>)</p></li>
<li><p>Unused re import and PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/387f414">commit 387f414</a>)</p></li>
<li><p>Ignore None’s values when using the ItemLoader. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0632546">commit 0632546</a>)</p></li>
<li><p>DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Filesystem instead Dbm. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cde9a8c">commit cde9a8c</a>)</p></li>
<li><p>show ubuntu setup instructions as literal code (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fb5c9c5">commit fb5c9c5</a>)</p></li>
<li><p>Update Ubuntu installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/70fb105">commit 70fb105</a>)</p></li>
<li><p>Merge pull request #550 from stray-leone/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f70b6a">commit 6f70b6a</a>)</p></li>
<li><p>modify the version of scrapy ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/725900d">commit 725900d</a>)</p></li>
<li><p>fix 0.22.0 release date (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/af0219a">commit af0219a</a>)</p></li>
<li><p>fix typos in news.rst and remove (not released yet) header (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7f58f4">commit b7f58f4</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-22-0-released-2014-01-17">
<h2>Scrapy 0.22.0 (released 2014-01-17)<a class="headerlink" href="#scrapy-0-22-0-released-2014-01-17" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id26">
<h3>Enhancements<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>[<strong>Backwards incompatible</strong>] Switched HTTPCacheMiddleware backend to filesystem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>)
To restore old backend set <cite>HTTPCACHE_STORAGE</cite> to <cite>scrapy.contrib.httpcache.DbmCacheStorage</cite></p></li>
<li><p>Proxy https:// urls using CONNECT method (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/392">issue 392</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/397">issue 397</a>)</p></li>
<li><p>Add a middleware to crawl ajax crawleable pages as defined by google (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/343">issue 343</a>)</p></li>
<li><p>Rename scrapy.spider.BaseSpider to scrapy.spider.Spider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/510">issue 510</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/519">issue 519</a>)</p></li>
<li><p>Selectors register EXSLT namespaces by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/472">issue 472</a>)</p></li>
<li><p>Unify item loaders similar to selectors renaming (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/461">issue 461</a>)</p></li>
<li><p>Make <cite>RFPDupeFilter</cite> class easily subclassable (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/533">issue 533</a>)</p></li>
<li><p>Improve test coverage and forthcoming Python 3 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/525">issue 525</a>)</p></li>
<li><p>Promote startup info on settings and middleware to INFO level (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/520">issue 520</a>)</p></li>
<li><p>Support partials in <cite>get_func_args</cite> util (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/506">issue 506</a>, issue:<cite>504</cite>)</p></li>
<li><p>Allow running indiviual tests via tox (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/503">issue 503</a>)</p></li>
<li><p>Update extensions ignored by link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/498">issue 498</a>)</p></li>
<li><p>Add middleware methods to get files/images/thumbs paths (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/490">issue 490</a>)</p></li>
<li><p>Improve offsite middleware tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/478">issue 478</a>)</p></li>
<li><p>Add a way to skip default Referer header set by RefererMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/475">issue 475</a>)</p></li>
<li><p>Do not send <cite>x-gzip</cite> in default <cite>Accept-Encoding</cite> header (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/469">issue 469</a>)</p></li>
<li><p>Support defining http error handling using settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/466">issue 466</a>)</p></li>
<li><p>Use modern python idioms wherever you find legacies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/497">issue 497</a>)</p></li>
<li><p>Improve and correct documentation
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/527">issue 527</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/524">issue 524</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/521">issue 521</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/517">issue 517</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/512">issue 512</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/505">issue 505</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/502">issue 502</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/489">issue 489</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/465">issue 465</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/460">issue 460</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/425">issue 425</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/536">issue 536</a>)</p></li>
</ul>
</div>
<div class="section" id="fixes">
<h3>Fixes<a class="headerlink" href="#fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Update Selector class imports in CrawlSpider template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/484">issue 484</a>)</p></li>
<li><p>Fix unexistent reference to <cite>engine.slots</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/464">issue 464</a>)</p></li>
<li><p>Do not try to call <cite>body_as_unicode()</cite> on a non-TextResponse instance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/462">issue 462</a>)</p></li>
<li><p>Warn when subclassing XPathItemLoader, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/523">issue 523</a>)</p></li>
<li><p>Warn when subclassing XPathSelector, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/537">issue 537</a>)</p></li>
<li><p>Multiple fixes to memory stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/531">issue 531</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/530">issue 530</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/529">issue 529</a>)</p></li>
<li><p>Fix overriding url in <cite>FormRequest.from_response()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/507">issue 507</a>)</p></li>
<li><p>Fix tests runner under pip 1.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/513">issue 513</a>)</p></li>
<li><p>Fix logging error when spider name is unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/479">issue 479</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-20-2-released-2013-12-09">
<h2>Scrapy 0.20.2 (released 2013-12-09)<a class="headerlink" href="#scrapy-0-20-2-released-2013-12-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Update CrawlSpider Template with Selector changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d1457d">commit 6d1457d</a>)</p></li>
<li><p>fix method name in tutorial. closes GH-480 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4fc359">commit b4fc359</a></p></li>
</ul>
</div>
<div class="section" id="scrapy-0-20-1-released-2013-11-28">
<h2>Scrapy 0.20.1 (released 2013-11-28)<a class="headerlink" href="#scrapy-0-20-1-released-2013-11-28" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>include_package_data is required to build wheels from published sources (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ba1ad5">commit 5ba1ad5</a>)</p></li>
<li><p>process_parallel was leaking the failures on its internal deferreds.  closes #458 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/419a780">commit 419a780</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-20-0-released-2013-11-08">
<h2>Scrapy 0.20.0 (released 2013-11-08)<a class="headerlink" href="#scrapy-0-20-0-released-2013-11-08" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id27">
<h3>Enhancements<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>New Selector’s API including CSS selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/395">issue 395</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/426">issue 426</a>),</p></li>
<li><p>Request/Response url/body attributes are now immutable
(modifying them had been deprecated for a long time)</p></li>
<li><p><a class="reference internal" href="topics/settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">ITEM_PIPELINES</span></code></a> is now defined as a dict (instead of a list)</p></li>
<li><p>Sitemap spider can fetch alternate URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/360">issue 360</a>)</p></li>
<li><p><cite>Selector.remove_namespaces()</cite> now remove namespaces from element’s attributes. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/416">issue 416</a>)</p></li>
<li><p>Paved the road for Python 3.3+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/435">issue 435</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/436">issue 436</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/431">issue 431</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/452">issue 452</a>)</p></li>
<li><p>New item exporter using native python types with nesting support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/366">issue 366</a>)</p></li>
<li><p>Tune HTTP1.1 pool size so it matches concurrency defined by settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b43b5f575">commit b43b5f575</a>)</p></li>
<li><p>scrapy.mail.MailSender now can connect over TLS or upgrade using STARTTLS (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/327">issue 327</a>)</p></li>
<li><p>New FilesPipeline with functionality factored out from ImagesPipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/370">issue 370</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/409">issue 409</a>)</p></li>
<li><p>Recommend Pillow instead of PIL for image handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/317">issue 317</a>)</p></li>
<li><p>Added debian packages for Ubuntu quantal and raring (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86230c0">commit 86230c0</a>)</p></li>
<li><p>Mock server (used for tests) can listen for HTTPS requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/410">issue 410</a>)</p></li>
<li><p>Remove multi spider support from multiple core components
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/422">issue 422</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/421">issue 421</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/420">issue 420</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/419">issue 419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/423">issue 423</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>)</p></li>
<li><p>Travis-CI now tests Scrapy changes against development versions of <cite>w3lib</cite> and <cite>queuelib</cite> python packages.</p></li>
<li><p>Add pypy 2.1 to continuous integration tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ecfa7431">commit ecfa7431</a>)</p></li>
<li><p>Pylinted, pep8 and removed old-style exceptions from source (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/430">issue 430</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/432">issue 432</a>)</p></li>
<li><p>Use importlib for parametric imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/445">issue 445</a>)</p></li>
<li><p>Handle a regression introduced in Python 2.7.5 that affects XmlItemExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/372">issue 372</a>)</p></li>
<li><p>Bugfix crawling shutdown on SIGINT (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/450">issue 450</a>)</p></li>
<li><p>Do not submit <cite>reset</cite> type inputs in FormRequest.from_response (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b326b87">commit b326b87</a>)</p></li>
<li><p>Do not silence download errors when request errback raises an exception (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/684cfc0">commit 684cfc0</a>)</p></li>
</ul>
</div>
<div class="section" id="id28">
<h3>Bugfixes<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Fix tests under Django 1.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b6bed44c">commit b6bed44c</a>)</p></li>
<li><p>Lot of bugfixes to retry middleware under disconnections using HTTP 1.1 download handler</p></li>
<li><p>Fix inconsistencies among Twisted releases (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/406">issue 406</a>)</p></li>
<li><p>Fix scrapy shell bugs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/407">issue 407</a>)</p></li>
<li><p>Fix invalid variable name in setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/429">issue 429</a>)</p></li>
<li><p>Fix tutorial references (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/387">issue 387</a>)</p></li>
<li><p>Improve request-response docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/391">issue 391</a>)</p></li>
<li><p>Improve best practices docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/399">issue 399</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/400">issue 400</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/401">issue 401</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/402">issue 402</a>)</p></li>
<li><p>Improve django integration docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/404">issue 404</a>)</p></li>
<li><p>Document <cite>bindaddress</cite> request meta (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/37c24e01d7">commit 37c24e01d7</a>)</p></li>
<li><p>Improve <cite>Request</cite> class documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/226">issue 226</a>)</p></li>
</ul>
</div>
<div class="section" id="other">
<h3>Other<a class="headerlink" href="#other" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Dropped Python 2.6 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/448">issue 448</a>)</p></li>
<li><p>Add <a class="reference external" href="https://github.com/SimonSapin/cssselect">cssselect</a> python package as install dependency</p></li>
<li><p>Drop libxml2 and multi selector’s backend support, <a class="reference external" href="http://lxml.de/">lxml</a> is required from now on.</p></li>
<li><p>Minimum Twisted version increased to 10.0.0, dropped Twisted 8.0 support.</p></li>
<li><p>Running test suite now requires <cite>mock</cite> python library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/390">issue 390</a>)</p></li>
</ul>
</div>
<div class="section" id="thanks">
<h3>Thanks<a class="headerlink" href="#thanks" title="Permalink to this headline">¶</a></h3>
<p>Thanks to everyone who contribute to this release!</p>
<p>List of contributors sorted by number of commits:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">69</span> <span class="n">Daniel</span> <span class="n">Graña</span> <span class="o">&lt;</span><span class="n">dangra</span><span class="o">@...&gt;</span>
<span class="mi">37</span> <span class="n">Pablo</span> <span class="n">Hoffman</span> <span class="o">&lt;</span><span class="n">pablo</span><span class="o">@...&gt;</span>
<span class="mi">13</span> <span class="n">Mikhail</span> <span class="n">Korobov</span> <span class="o">&lt;</span><span class="n">kmike84</span><span class="o">@...&gt;</span>
 <span class="mi">9</span> <span class="n">Alex</span> <span class="n">Cepoi</span> <span class="o">&lt;</span><span class="n">alex</span><span class="o">.</span><span class="n">cepoi</span><span class="o">@...&gt;</span>
 <span class="mi">9</span> <span class="n">alexanderlukanin13</span> <span class="o">&lt;</span><span class="n">alexander</span><span class="o">.</span><span class="n">lukanin</span><span class="o">.</span><span class="mi">13</span><span class="o">@...&gt;</span>
 <span class="mi">8</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="n">La</span> <span class="n">fuente</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
 <span class="mi">8</span> <span class="n">Lukasz</span> <span class="n">Biedrycki</span> <span class="o">&lt;</span><span class="n">lukasz</span><span class="o">.</span><span class="n">biedrycki</span><span class="o">@...&gt;</span>
 <span class="mi">6</span> <span class="n">Nicolas</span> <span class="n">Ramirez</span> <span class="o">&lt;</span><span class="n">nramirez</span><span class="o">.</span><span class="n">uy</span><span class="o">@...&gt;</span>
 <span class="mi">3</span> <span class="n">Paul</span> <span class="n">Tremberth</span> <span class="o">&lt;</span><span class="n">paul</span><span class="o">.</span><span class="n">tremberth</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Martin</span> <span class="n">Olveyra</span> <span class="o">&lt;</span><span class="n">molveyra</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Stefan</span> <span class="o">&lt;</span><span class="n">misc</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Loren</span> <span class="n">Davie</span> <span class="o">&lt;</span><span class="n">loren</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">irgmedeiros</span> <span class="o">&lt;</span><span class="n">irgmedeiros</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Stefan</span> <span class="n">Koch</span> <span class="o">&lt;</span><span class="n">taikano</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Stefan</span> <span class="o">&lt;</span><span class="n">cct</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">scraperdragon</span> <span class="o">&lt;</span><span class="n">dragon</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Kumara</span> <span class="n">Tharmalingam</span> <span class="o">&lt;</span><span class="n">ktharmal</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Francesco</span> <span class="n">Piccinno</span> <span class="o">&lt;</span><span class="n">stack</span><span class="o">.</span><span class="n">box</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Marcos</span> <span class="n">Campal</span> <span class="o">&lt;</span><span class="n">duendex</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Dragon</span> <span class="n">Dave</span> <span class="o">&lt;</span><span class="n">dragon</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Capi</span> <span class="n">Etheriel</span> <span class="o">&lt;</span><span class="n">barraponto</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">cacovsky</span> <span class="o">&lt;</span><span class="n">amarquesferraz</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Berend</span> <span class="n">Iwema</span> <span class="o">&lt;</span><span class="n">berend</span><span class="o">@...&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="scrapy-0-18-4-released-2013-10-10">
<h2>Scrapy 0.18.4 (released 2013-10-10)<a class="headerlink" href="#scrapy-0-18-4-released-2013-10-10" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>IPython refuses to update the namespace. fix #396 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3d32c4f">commit 3d32c4f</a>)</p></li>
<li><p>Fix AlreadyCalledError replacing a request in shell command. closes #407 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b1d8919">commit b1d8919</a>)</p></li>
<li><p>Fix start_requests laziness and early hangs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/89faf52">commit 89faf52</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-18-3-released-2013-10-03">
<h2>Scrapy 0.18.3 (released 2013-10-03)<a class="headerlink" href="#scrapy-0-18-3-released-2013-10-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>fix regression on lazy evaluation of start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/12693a5">commit 12693a5</a>)</p></li>
<li><p>forms: do not submit reset inputs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e429f63">commit e429f63</a>)</p></li>
<li><p>increase unittest timeouts to decrease travis false positive failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/912202e">commit 912202e</a>)</p></li>
<li><p>backport master fixes to json exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cfc2d46">commit cfc2d46</a>)</p></li>
<li><p>Fix permission and set umask before generating sdist tarball (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/06149e0">commit 06149e0</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-18-2-released-2013-09-03">
<h2>Scrapy 0.18.2 (released 2013-09-03)<a class="headerlink" href="#scrapy-0-18-2-released-2013-09-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Backport <cite>scrapy check</cite> command fixes and backward compatible multi
crawler process(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/339">issue 339</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-18-1-released-2013-08-27">
<h2>Scrapy 0.18.1 (released 2013-08-27)<a class="headerlink" href="#scrapy-0-18-1-released-2013-08-27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>remove extra import added by cherry picked changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d20304e">commit d20304e</a>)</p></li>
<li><p>fix crawling tests under twisted pre 11.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1994f38">commit 1994f38</a>)</p></li>
<li><p>py26 can not format zero length fields {} (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/abf756f">commit abf756f</a>)</p></li>
<li><p>test PotentiaDataLoss errors on unbound responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b15470d">commit b15470d</a>)</p></li>
<li><p>Treat responses without content-length or Transfer-Encoding as good responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4bf324">commit c4bf324</a>)</p></li>
<li><p>do no include ResponseFailed if http11 handler is not enabled (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cbe684">commit 6cbe684</a>)</p></li>
<li><p>New HTTP client wraps connection losts in ResponseFailed exception. fix #373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1a20bba">commit 1a20bba</a>)</p></li>
<li><p>limit travis-ci build matrix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3b01bb8">commit 3b01bb8</a>)</p></li>
<li><p>Merge pull request #375 from peterarenot/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa766d7">commit fa766d7</a>)</p></li>
<li><p>Fixed so it refers to the correct folder (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3283809">commit 3283809</a>)</p></li>
<li><p>added quantal &amp; raring to support ubuntu releases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1411923">commit 1411923</a>)</p></li>
<li><p>fix retry middleware which didn’t retry certain connection errors after the upgrade to http1 client, closes GH-373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb35ed0">commit bb35ed0</a>)</p></li>
<li><p>fix XmlItemExporter in Python 2.7.4 and 2.7.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de3e451">commit de3e451</a>)</p></li>
<li><p>minor updates to 0.18 release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c45e5f1">commit c45e5f1</a>)</p></li>
<li><p>fix contributters list format (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0b60031">commit 0b60031</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-18-0-released-2013-08-09">
<h2>Scrapy 0.18.0 (released 2013-08-09)<a class="headerlink" href="#scrapy-0-18-0-released-2013-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Lot of improvements to testsuite run using Tox, including a way to test on pypi</p></li>
<li><p>Handle GET parameters for AJAX crawleable urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3fe2a32">commit 3fe2a32</a>)</p></li>
<li><p>Use lxml recover option to parse sitemaps (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/347">issue 347</a>)</p></li>
<li><p>Bugfix cookie merging by hostname and not by netloc (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/352">issue 352</a>)</p></li>
<li><p>Support disabling <cite>HttpCompressionMiddleware</cite> using a flag setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/359">issue 359</a>)</p></li>
<li><p>Support xml namespaces using <cite>iternodes</cite> parser in <cite>XMLFeedSpider</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/12">issue 12</a>)</p></li>
<li><p>Support <cite>dont_cache</cite> request meta flag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/19">issue 19</a>)</p></li>
<li><p>Bugfix <cite>scrapy.utils.gz.gunzip</cite> broken by changes in python 2.7.4 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4dc76e">commit 4dc76e</a>)</p></li>
<li><p>Bugfix url encoding on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/24">issue 24</a>)</p></li>
<li><p>Bugfix <cite>TakeFirst</cite> processor shouldn’t discard zero (0) value (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/59">issue 59</a>)</p></li>
<li><p>Support nested items in xml exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/66">issue 66</a>)</p></li>
<li><p>Improve cookies handling performance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/77">issue 77</a>)</p></li>
<li><p>Log dupe filtered requests once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/105">issue 105</a>)</p></li>
<li><p>Split redirection middleware into status and meta based middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/78">issue 78</a>)</p></li>
<li><p>Use HTTP1.1 as default downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/109">issue 109</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/318">issue 318</a>)</p></li>
<li><p>Support xpath form selection on <cite>FormRequest.from_response</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/185">issue 185</a>)</p></li>
<li><p>Bugfix unicode decoding error on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/199">issue 199</a>)</p></li>
<li><p>Bugfix signal dispatching on pypi interpreter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/205">issue 205</a>)</p></li>
<li><p>Improve request delay and concurrency handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/206">issue 206</a>)</p></li>
<li><p>Add RFC2616 cache policy to <cite>HttpCacheMiddleware</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/212">issue 212</a>)</p></li>
<li><p>Allow customization of messages logged by engine (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/214">issue 214</a>)</p></li>
<li><p>Multiples improvements to <cite>DjangoItem</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/217">issue 217</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/218">issue 218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/221">issue 221</a>)</p></li>
<li><p>Extend Scrapy commands using setuptools entry points (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</p></li>
<li><p>Allow spider <cite>allowed_domains</cite> value to be set/tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/261">issue 261</a>)</p></li>
<li><p>Support <cite>settings.getdict</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/269">issue 269</a>)</p></li>
<li><p>Simplify internal <cite>scrapy.core.scraper</cite> slot handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/271">issue 271</a>)</p></li>
<li><p>Added <cite>Item.copy</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/290">issue 290</a>)</p></li>
<li><p>Collect idle downloader slots (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/297">issue 297</a>)</p></li>
<li><p>Add <cite>ftp://</cite> scheme downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/329">issue 329</a>)</p></li>
<li><p>Added downloader benchmark webserver and spider tools <a class="reference internal" href="topics/benchmarking.html#benchmarking"><span class="std std-ref">Benchmarking</span></a></p></li>
<li><p>Moved persistent (on disk) queues to a separate project (<a class="reference external" href="https://github.com/scrapy/queuelib">queuelib</a>) which scrapy now depends on</p></li>
<li><p>Add scrapy commands using external libraries (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">--pdb</span></code> option to <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command line tool</p></li>
<li><p>Added <code class="xref py py-meth docutils literal notranslate"><span class="pre">XPathSelector.remove_namespaces()</span></code> which allows to remove all namespaces from XML documents for convenience (to work with namespace-less XPaths). Documented in <a class="reference internal" href="topics/selectors.html#topics-selectors"><span class="std std-ref">选择器</span></a>.</p></li>
<li><p>Several improvements to spider contracts</p></li>
<li><p>New default middleware named MetaRefreshMiddldeware that handles meta-refresh html tag redirections,</p></li>
<li><p>MetaRefreshMiddldeware and RedirectMiddleware have different priorities to address #62</p></li>
<li><p>added from_crawler method to spiders</p></li>
<li><p>added system tests with mock server</p></li>
<li><p>more improvements to Mac OS compatibility (thanks Alex Cepoi)</p></li>
<li><p>several more cleanups to singletons and multi-spider support (thanks Nicolas Ramirez)</p></li>
<li><p>support custom download slots</p></li>
<li><p>added –spider option to “shell” command.</p></li>
<li><p>log overridden settings when scrapy starts</p></li>
</ul>
<p>Thanks to everyone who contribute to this release. Here is a list of
contributors sorted by number of commits:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">130</span> <span class="n">Pablo</span> <span class="n">Hoffman</span> <span class="o">&lt;</span><span class="n">pablo</span><span class="o">@...&gt;</span>
 <span class="mi">97</span> <span class="n">Daniel</span> <span class="n">Graña</span> <span class="o">&lt;</span><span class="n">dangra</span><span class="o">@...&gt;</span>
 <span class="mi">20</span> <span class="n">Nicolás</span> <span class="n">Ramírez</span> <span class="o">&lt;</span><span class="n">nramirez</span><span class="o">.</span><span class="n">uy</span><span class="o">@...&gt;</span>
 <span class="mi">13</span> <span class="n">Mikhail</span> <span class="n">Korobov</span> <span class="o">&lt;</span><span class="n">kmike84</span><span class="o">@...&gt;</span>
 <span class="mi">12</span> <span class="n">Pedro</span> <span class="n">Faustino</span> <span class="o">&lt;</span><span class="n">pedrobandim</span><span class="o">@...&gt;</span>
 <span class="mi">11</span> <span class="n">Steven</span> <span class="n">Almeroth</span> <span class="o">&lt;</span><span class="n">sroth77</span><span class="o">@...&gt;</span>
  <span class="mi">5</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="n">La</span> <span class="n">fuente</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Michal</span> <span class="n">Danilak</span> <span class="o">&lt;</span><span class="n">mimino</span><span class="o">.</span><span class="n">coder</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Alex</span> <span class="n">Cepoi</span> <span class="o">&lt;</span><span class="n">alex</span><span class="o">.</span><span class="n">cepoi</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Alexandr</span> <span class="n">N</span> <span class="n">Zamaraev</span> <span class="p">(</span><span class="n">aka</span> <span class="n">tonal</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">tonal</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">paul</span> <span class="o">&lt;</span><span class="n">paul</span><span class="o">.</span><span class="n">tremberth</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">Martin</span> <span class="n">Olveyra</span> <span class="o">&lt;</span><span class="n">molveyra</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">Jordi</span> <span class="n">Llonch</span> <span class="o">&lt;</span><span class="n">llonchj</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">arijitchakraborty</span> <span class="o">&lt;</span><span class="n">myself</span><span class="o">.</span><span class="n">arijit</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Shane</span> <span class="n">Evans</span> <span class="o">&lt;</span><span class="n">shane</span><span class="o">.</span><span class="n">evans</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">joehillen</span> <span class="o">&lt;</span><span class="n">joehillen</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Hart</span> <span class="o">&lt;</span><span class="n">HartSimha</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Dan</span> <span class="o">&lt;</span><span class="n">ellisd23</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Zuhao</span> <span class="n">Wan</span> <span class="o">&lt;</span><span class="n">wanzuhao</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">whodatninja</span> <span class="o">&lt;</span><span class="n">blake</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">vkrest</span> <span class="o">&lt;</span><span class="n">v</span><span class="o">.</span><span class="n">krestiannykov</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">tpeng</span> <span class="o">&lt;</span><span class="n">pengtaoo</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Tom</span> <span class="n">Mortimer</span><span class="o">-</span><span class="n">Jones</span> <span class="o">&lt;</span><span class="n">tom</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Rocio</span> <span class="n">Aramberri</span> <span class="o">&lt;</span><span class="n">roschegel</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Pedro</span> <span class="o">&lt;</span><span class="n">pedro</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">notsobad</span> <span class="o">&lt;</span><span class="n">wangxiaohugg</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Natan</span> <span class="n">L</span> <span class="o">&lt;</span><span class="n">kuyanatan</span><span class="o">.</span><span class="n">nlao</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Mark</span> <span class="n">Grey</span> <span class="o">&lt;</span><span class="n">mark</span><span class="o">.</span><span class="n">grey</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Luan</span> <span class="o">&lt;</span><span class="n">luanpab</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Libor</span> <span class="n">Nenadál</span> <span class="o">&lt;</span><span class="n">libor</span><span class="o">.</span><span class="n">nenadal</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Juan</span> <span class="n">M</span> <span class="n">Uys</span> <span class="o">&lt;</span><span class="n">opyate</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Jonas</span> <span class="n">Brunsgaard</span> <span class="o">&lt;</span><span class="n">jonas</span><span class="o">.</span><span class="n">brunsgaard</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Ilya</span> <span class="n">Baryshev</span> <span class="o">&lt;</span><span class="n">baryshev</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Hasnain</span> <span class="n">Lakhani</span> <span class="o">&lt;</span><span class="n">m</span><span class="o">.</span><span class="n">hasnain</span><span class="o">.</span><span class="n">lakhani</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Emanuel</span> <span class="n">Schorsch</span> <span class="o">&lt;</span><span class="n">emschorsch</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Chris</span> <span class="n">Tilden</span> <span class="o">&lt;</span><span class="n">chris</span><span class="o">.</span><span class="n">tilden</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Capi</span> <span class="n">Etheriel</span> <span class="o">&lt;</span><span class="n">barraponto</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">cacovsky</span> <span class="o">&lt;</span><span class="n">amarquesferraz</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Berend</span> <span class="n">Iwema</span> <span class="o">&lt;</span><span class="n">berend</span><span class="o">@...&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="scrapy-0-16-5-released-2013-05-30">
<h2>Scrapy 0.16.5 (released 2013-05-30)<a class="headerlink" href="#scrapy-0-16-5-released-2013-05-30" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>obey request method when scrapy deploy is redirected to a new endpoint (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c4fcee">commit 8c4fcee</a>)</p></li>
<li><p>fix inaccurate downloader middleware documentation. refs #280 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/40667cb">commit 40667cb</a>)</p></li>
<li><p>doc: remove links to diveintopython.org, which is no longer available. closes #246 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bd58bfa">commit bd58bfa</a>)</p></li>
<li><p>Find form nodes in invalid html5 documents (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3d6945">commit e3d6945</a>)</p></li>
<li><p>Fix typo labeling attrs type bool instead of list (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274276">commit a274276</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-16-4-released-2013-01-23">
<h2>Scrapy 0.16.4 (released 2013-01-23)<a class="headerlink" href="#scrapy-0-16-4-released-2013-01-23" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>fixes spelling errors in documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d2b3aa">commit 6d2b3aa</a>)</p></li>
<li><p>add doc about disabling an extension. refs #132 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c90de33">commit c90de33</a>)</p></li>
<li><p>Fixed error message formatting. log.err() doesn’t support cool formatting and when error occurred, the message was:    “ERROR: Error processing %(item)s” (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c16150c">commit c16150c</a>)</p></li>
<li><p>lint and improve images pipeline error logging (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/56b45fc">commit 56b45fc</a>)</p></li>
<li><p>fixed doc typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/243be84">commit 243be84</a>)</p></li>
<li><p>add documentation topics: Broad Crawls &amp; Common Practies (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1fbb715">commit 1fbb715</a>)</p></li>
<li><p>fix bug in scrapy parse command when spider is not specified explicitly. closes #209 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c72e682">commit c72e682</a>)</p></li>
<li><p>Update docs/topics/commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/28eac7a">commit 28eac7a</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-16-3-released-2012-12-07">
<h2>Scrapy 0.16.3 (released 2012-12-07)<a class="headerlink" href="#scrapy-0-16-3-released-2012-12-07" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Remove concurrency limitation when using download delays and still ensure inter-request delays are enforced (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/487b9b5">commit 487b9b5</a>)</p></li>
<li><p>add error details when image pipeline fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8232569">commit 8232569</a>)</p></li>
<li><p>improve mac os compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8dcf8aa">commit 8dcf8aa</a>)</p></li>
<li><p>setup.py: use README.rst to populate long_description (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7b5310d">commit 7b5310d</a>)</p></li>
<li><p>doc: removed obsolete references to ClientForm (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/80f9bb6">commit 80f9bb6</a>)</p></li>
<li><p>correct docs for default storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2aa491b">commit 2aa491b</a>)</p></li>
<li><p>doc: removed broken proxyhub link from FAQ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bdf61c4">commit bdf61c4</a>)</p></li>
<li><p>Fixed docs typo in SpiderOpenCloseLogging example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7184094">commit 7184094</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-16-2-released-2012-11-09">
<h2>Scrapy 0.16.2 (released 2012-11-09)<a class="headerlink" href="#scrapy-0-16-2-released-2012-11-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>scrapy contracts: python2.6 compat (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a4a9199">commit a4a9199</a>)</p></li>
<li><p>scrapy contracts verbose option (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ec41673">commit ec41673</a>)</p></li>
<li><p>proper unittest-like output for scrapy contracts (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86635e4">commit 86635e4</a>)</p></li>
<li><p>added open_in_browser to debugging doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c9b690d">commit c9b690d</a>)</p></li>
<li><p>removed reference to global scrapy stats from settings doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/dd55067">commit dd55067</a>)</p></li>
<li><p>Fix SpiderState bug in Windows platforms (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/58998f4">commit 58998f4</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-16-1-released-2012-10-26">
<h2>Scrapy 0.16.1 (released 2012-10-26)<a class="headerlink" href="#scrapy-0-16-1-released-2012-10-26" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>fixed LogStats extension, which got broken after a wrong merge before the 0.16 release (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c780fd">commit 8c780fd</a>)</p></li>
<li><p>better backwards compatibility for scrapy.conf.settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3403089">commit 3403089</a>)</p></li>
<li><p>extended documentation on how to access crawler stats from extensions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4da0b5">commit c4da0b5</a>)</p></li>
<li><p>removed .hgtags (no longer needed now that scrapy uses git) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d52c188">commit d52c188</a>)</p></li>
<li><p>fix dashes under rst headers (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa4f7f9">commit fa4f7f9</a>)</p></li>
<li><p>set release date for 0.16.0 in news (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e292246">commit e292246</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-16-0-released-2012-10-18">
<h2>Scrapy 0.16.0 (released 2012-10-18)<a class="headerlink" href="#scrapy-0-16-0-released-2012-10-18" title="Permalink to this headline">¶</a></h2>
<p>Scrapy changes:</p>
<ul class="simple">
<li><p>added <a class="reference internal" href="topics/contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>, a mechanism for testing spiders in a formal/reproducible way</p></li>
<li><p>added options <code class="docutils literal notranslate"><span class="pre">-o</span></code> and <code class="docutils literal notranslate"><span class="pre">-t</span></code> to the <a class="reference internal" href="topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">runspider</span></code></a> command</p></li>
<li><p>documented <a class="reference internal" href="topics/autothrottle.html"><span class="doc">AutoThrottle 扩展</span></a> and added to extensions installed by default. You still need to enable it with <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AUTOTHROTTLE_ENABLED</span></code></a></p></li>
<li><p>major Stats Collection refactoring: removed separation of global/per-spider stats, removed stats-related signals (<code class="docutils literal notranslate"><span class="pre">stats_spider_opened</span></code>, etc). Stats are much simpler now, backwards compatibility is kept on the Stats Collector API and signals.</p></li>
<li><p>added <code class="xref py py-meth docutils literal notranslate"><span class="pre">process_start_requests()</span></code> method to spider middlewares</p></li>
<li><p>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</p></li>
<li><p>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</p></li>
<li><p>dropped Stats Collector singleton. Stats can now be accessed through the Crawler.stats attribute. See the stats collection documentation for more info.</p></li>
<li><p>documented <a class="reference internal" href="topics/api.html#topics-api"><span class="std std-ref">Core API</span></a></p></li>
<li><p><cite>lxml</cite> is now the default selectors backend instead of <cite>libxml2</cite></p></li>
<li><p>ported FormRequest.from_response() to use <a class="reference external" href="http://lxml.de/">lxml</a> instead of <a class="reference external" href="http://wwwsearch.sourceforge.net/old/ClientForm/">ClientForm</a></p></li>
<li><p>removed modules: <code class="docutils literal notranslate"><span class="pre">scrapy.xlib.BeautifulSoup</span></code> and <code class="docutils literal notranslate"><span class="pre">scrapy.xlib.ClientForm</span></code></p></li>
<li><p>SitemapSpider: added support for sitemap urls ending in .xml and .xml.gz, even if they advertise a wrong content type (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10ed28b">commit 10ed28b</a>)</p></li>
<li><p>StackTraceDump extension: also dump trackref live references (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fe2ce93">commit fe2ce93</a>)</p></li>
<li><p>nested items now fully supported in JSON and JSONLines exporters</p></li>
<li><p>added <a class="reference internal" href="topics/downloader-middleware.html#std:reqmeta-cookiejar"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">cookiejar</span></code></a> Request meta key to support multiple cookie sessions per spider</p></li>
<li><p>decoupled encoding detection code to <a class="reference external" href="https://github.com/scrapy/w3lib/blob/master/w3lib/encoding.py">w3lib.encoding</a>, and ported Scrapy code to use that module</p></li>
<li><p>dropped support for Python 2.5. See <a class="reference external" href="https://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/">https://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/</a></p></li>
<li><p>dropped support for Twisted 2.5</p></li>
<li><p>added <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERER_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">REFERER_ENABLED</span></code></a> setting, to control referer middleware</p></li>
<li><p>changed default user agent to: <code class="docutils literal notranslate"><span class="pre">Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)</span></code></p></li>
<li><p>removed (undocumented) <code class="docutils literal notranslate"><span class="pre">HTMLImageLinkExtractor</span></code> class from <code class="docutils literal notranslate"><span class="pre">scrapy.contrib.linkextractors.image</span></code></p></li>
<li><p>removed per-spider settings (to be replaced by instantiating multiple crawler objects)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">USER_AGENT</span></code> spider attribute will no longer work, use <code class="docutils literal notranslate"><span class="pre">user_agent</span></code> attribute instead</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DOWNLOAD_TIMEOUT</span></code> spider attribute will no longer work, use <code class="docutils literal notranslate"><span class="pre">download_timeout</span></code> attribute instead</p></li>
<li><p>removed <code class="docutils literal notranslate"><span class="pre">ENCODING_ALIASES</span></code> setting, as encoding auto-detection has been moved to the <a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> library</p></li>
<li><p>promoted <a class="reference internal" href="topics/djangoitem.html#topics-djangoitem"><span class="std std-ref">DjangoItem</span></a> to main contrib</p></li>
<li><p>LogFormatter method now return dicts(instead of strings) to support lazy formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/164">issue 164</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/dcef7b0">commit dcef7b0</a>)</p></li>
<li><p>downloader handlers (<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> setting) now receive settings as the first argument of the constructor</p></li>
<li><p>replaced memory usage acounting with (more portable) <a class="reference external" href="https://docs.python.org/2/library/resource.html">resource</a> module, removed <code class="docutils literal notranslate"><span class="pre">scrapy.utils.memory</span></code> module</p></li>
<li><p>removed signal: <code class="docutils literal notranslate"><span class="pre">scrapy.mail.mail_sent</span></code></p></li>
<li><p>removed <code class="docutils literal notranslate"><span class="pre">TRACK_REFS</span></code> setting, now <a class="reference internal" href="topics/leaks.html#topics-leaks-trackrefs"><span class="std std-ref">trackrefs</span></a> is always enabled</p></li>
<li><p>DBM is now the default storage backend for HTTP cache middleware</p></li>
<li><p>number of log messages (per level) are now tracked through Scrapy stats (stat name: <code class="docutils literal notranslate"><span class="pre">log_count/LEVEL</span></code>)</p></li>
<li><p>number received responses are now tracked through Scrapy stats (stat name: <code class="docutils literal notranslate"><span class="pre">response_received_count</span></code>)</p></li>
<li><p>removed <code class="docutils literal notranslate"><span class="pre">scrapy.log.started</span></code> attribute</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-14-4">
<h2>Scrapy 0.14.4<a class="headerlink" href="#scrapy-0-14-4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>added precise to supported ubuntu distros (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7e46df">commit b7e46df</a>)</p></li>
<li><p>fixed bug in json-rpc webservice reported in <a class="reference external" href="https://groups.google.com/forum/#!topic/scrapy-users/qgVBmFybNAQ/discussion">https://groups.google.com/forum/#!topic/scrapy-users/qgVBmFybNAQ/discussion</a>. also removed no longer supported ‘run’ command from extras/scrapy-ws.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/340fbdb">commit 340fbdb</a>)</p></li>
<li><p>meta tag attributes for content-type http equiv can be in any order. #123 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0cb68af">commit 0cb68af</a>)</p></li>
<li><p>replace “import Image” by more standard “from PIL import Image”. closes #88 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4d17048">commit 4d17048</a>)</p></li>
<li><p>return trial status as bin/runtests.sh exit value. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7b2e7f">commit b7b2e7f</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-14-3">
<h2>Scrapy 0.14.3<a class="headerlink" href="#scrapy-0-14-3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>forgot to include pydispatch license. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fd85f9c">commit fd85f9c</a>)</p></li>
<li><p>include egg files used by testsuite in source distribution. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c897793">commit c897793</a>)</p></li>
<li><p>update docstring in project template to avoid confusion with genspider command, which may be considered as an advanced feature. refs #107 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2548dcc">commit 2548dcc</a>)</p></li>
<li><p>added note to docs/topics/firebug.rst about google directory being shut down (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/668e352">commit 668e352</a>)</p></li>
<li><p>dont discard slot when empty, just save in another dict in order to recycle if needed again. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e9f607">commit 8e9f607</a>)</p></li>
<li><p>do not fail handling unicode xpaths in libxml2 backed selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b830e95">commit b830e95</a>)</p></li>
<li><p>fixed minor mistake in Request objects documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bf3c9ee">commit bf3c9ee</a>)</p></li>
<li><p>fixed minor defect in link extractors documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ba14f38">commit ba14f38</a>)</p></li>
<li><p>removed some obsolete remaining code related to sqlite support in scrapy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0665175">commit 0665175</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-14-2">
<h2>Scrapy 0.14.2<a class="headerlink" href="#scrapy-0-14-2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>move buffer pointing to start of file before computing checksum. refs #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6a5bef2">commit 6a5bef2</a>)</p></li>
<li><p>Compute image checksum before persisting images. closes #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9817df1">commit 9817df1</a>)</p></li>
<li><p>remove leaking references in cached failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/673a120">commit 673a120</a>)</p></li>
<li><p>fixed bug in MemoryUsage extension: get_engine_status() takes exactly 1 argument (0 given) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/11133e9">commit 11133e9</a>)</p></li>
<li><p>fixed struct.error on http compression middleware. closes #87 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1423140">commit 1423140</a>)</p></li>
<li><p>ajax crawling wasn’t expanding for unicode urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0de3fb4">commit 0de3fb4</a>)</p></li>
<li><p>Catch start_requests iterator errors. refs #83 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/454a21d">commit 454a21d</a>)</p></li>
<li><p>Speed-up libxml2 XPathSelector (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2fbd662">commit 2fbd662</a>)</p></li>
<li><p>updated versioning doc according to recent changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a070f5">commit 0a070f5</a>)</p></li>
<li><p>scrapyd: fixed documentation link (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2b4e4c3">commit 2b4e4c3</a>)</p></li>
<li><p>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-14-1">
<h2>Scrapy 0.14.1<a class="headerlink" href="#scrapy-0-14-1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</p></li>
<li><p>bumped version to 0.14.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cb9e1c">commit 6cb9e1c</a>)</p></li>
<li><p>fixed reference to tutorial directory (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4b86bd6">commit 4b86bd6</a>)</p></li>
<li><p>doc: removed duplicated callback argument from Request.replace() (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1aeccdd">commit 1aeccdd</a>)</p></li>
<li><p>fixed formatting of scrapyd doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8bf19e6">commit 8bf19e6</a>)</p></li>
<li><p>Dump stacks for all running threads and fix engine status dumped by StackTraceDump extension (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/14a8e6e">commit 14a8e6e</a>)</p></li>
<li><p>added comment about why we disable ssl on boto images upload (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5223575">commit 5223575</a>)</p></li>
<li><p>SSL handshaking hangs when doing too many parallel connections to S3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/63d583d">commit 63d583d</a>)</p></li>
<li><p>change tutorial to follow changes on dmoz site (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bcb3198">commit bcb3198</a>)</p></li>
<li><p>Avoid _disconnectedDeferred AttributeError exception in Twisted&gt;=11.1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98f3f87">commit 98f3f87</a>)</p></li>
<li><p>allow spider to set autothrottle max concurrency (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/175a4b5">commit 175a4b5</a>)</p></li>
</ul>
</div>
<div class="section" id="scrapy-0-14">
<h2>Scrapy 0.14<a class="headerlink" href="#scrapy-0-14" title="Permalink to this headline">¶</a></h2>
<div class="section" id="new-features-and-settings">
<h3>New features and settings<a class="headerlink" href="#new-features-and-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Support for <a class="reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started?csw=1">AJAX crawleable urls</a></p></li>
<li><p>New persistent scheduler that stores requests on disk, allowing to suspend and resume crawls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2737">r2737</a>)</p></li>
<li><p>added <code class="docutils literal notranslate"><span class="pre">-o</span></code> option to <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">crawl</span></code>, a shortcut for dumping scraped items into a file (or standard output using <code class="docutils literal notranslate"><span class="pre">-</span></code>)</p></li>
<li><p>Added support for passing custom settings to Scrapyd <code class="docutils literal notranslate"><span class="pre">schedule.json</span></code> api (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2779">r2779</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2783">r2783</a>)</p></li>
<li><p>New <code class="docutils literal notranslate"><span class="pre">ChunkedTransferMiddleware</span></code> (enabled by default) to support <a class="reference external" href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">chunked transfer encoding</a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2769">r2769</a>)</p></li>
<li><p>Add boto 2.0 support for S3 downloader handler (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2763">r2763</a>)</p></li>
<li><p>Added <a class="reference external" href="https://docs.python.org/2/library/marshal.html">marshal</a> to formats supported by feed exports (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2744">r2744</a>)</p></li>
<li><p>In request errbacks, offending requests are now received in <cite>failure.request</cite> attribute (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2738">r2738</a>)</p></li>
<li><dl class="simple">
<dt>Big downloader refactoring to support per domain/ip concurrency limits (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2732">r2732</a>)</dt><dd><ul>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> setting has been deprecated and replaced by:</dt><dd><ul>
<li><p><a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>check the documentation for more details</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Added builtin caching DNS resolver (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2728">r2728</a>)</p></li>
<li><p>Moved Amazon AWS-related components/extensions (SQS spider queue, SimpleDB stats collector) to a separate project: [scaws](<a class="reference external" href="https://github.com/scrapinghub/scaws">https://github.com/scrapinghub/scaws</a>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2706">r2706</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2714">r2714</a>)</p></li>
<li><p>Moved spider queues to scrapyd: <cite>scrapy.spiderqueue</cite> -&gt; <cite>scrapyd.spiderqueue</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2708">r2708</a>)</p></li>
<li><p>Moved sqlite utils to scrapyd: <cite>scrapy.utils.sqlite</cite> -&gt; <cite>scrapyd.sqlite</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2781">r2781</a>)</p></li>
<li><p>Real support for returning iterators on <cite>start_requests()</cite> method. The iterator is now consumed during the crawl when the spider is getting idle (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p></li>
<li><p>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-REDIRECT_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">REDIRECT_ENABLED</span></code></a> setting to quickly enable/disable the redirect middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2697">r2697</a>)</p></li>
<li><p>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_ENABLED</span></code></a> setting to quickly enable/disable the retry middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2694">r2694</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">CloseSpider</span></code> exception to manually close spiders (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2691">r2691</a>)</p></li>
<li><p>Improved encoding detection by adding support for HTML5 meta charset declaration (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2690">r2690</a>)</p></li>
<li><p>Refactored close spider behavior to wait for all downloads to finish and be processed by spiders, before closing the spider (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2688">r2688</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">SitemapSpider</span></code> (see documentation in Spiders page) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2658">r2658</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">LogStats</span></code> extension for periodically logging basic stats (like crawled pages and scraped items) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2657">r2657</a>)</p></li>
<li><p>Make handling of gzipped responses more robust (#319, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2643">r2643</a>). Now Scrapy will try and decompress as much as possible from a gzipped response, instead of failing with an <cite>IOError</cite>.</p></li>
<li><p>Simplified !MemoryDebugger extension to use stats for dumping memory debugging info (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2639">r2639</a>)</p></li>
<li><p>Added new command to edit spiders: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">edit</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2636">r2636</a>) and <cite>-e</cite> flag to <cite>genspider</cite> command that uses it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2653">r2653</a>)</p></li>
<li><p>Changed default representation of items to pretty-printed dicts. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2631">r2631</a>). This improves default logging by making log more readable in the default case, for both Scraped and Dropped lines.</p></li>
<li><p>Added <a class="reference internal" href="topics/signals.html#std:signal-spider_error"><code class="xref std std-signal docutils literal notranslate"><span class="pre">spider_error</span></code></a> signal (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2628">r2628</a>)</p></li>
<li><p>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-COOKIES_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">COOKIES_ENABLED</span></code></a> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2625">r2625</a>)</p></li>
<li><p>Stats are now dumped to Scrapy log (default value of <a class="reference internal" href="topics/settings.html#std:setting-STATS_DUMP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">STATS_DUMP</span></code></a> setting has been changed to <cite>True</cite>). This is to make Scrapy users more aware of Scrapy stats and the data that is collected there.</p></li>
<li><p>Added support for dynamically adjusting download delay and maximum concurrent requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2599">r2599</a>)</p></li>
<li><p>Added new DBM HTTP cache storage backend (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2576">r2576</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">listjobs.json</span></code> API to Scrapyd (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2571">r2571</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CsvItemExporter</span></code>: added <code class="docutils literal notranslate"><span class="pre">join_multivalued</span></code> parameter (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2578">r2578</a>)</p></li>
<li><p>Added namespace support to <code class="docutils literal notranslate"><span class="pre">xmliter_lxml</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2552">r2552</a>)</p></li>
<li><p>Improved cookies middleware by making <cite>COOKIES_DEBUG</cite> nicer and documenting it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2579">r2579</a>)</p></li>
<li><p>Several improvements to Scrapyd and Link extractors</p></li>
</ul>
</div>
<div class="section" id="code-rearranged-and-removed">
<h3>Code rearranged and removed<a class="headerlink" href="#code-rearranged-and-removed" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt>Merged item passed and item scraped concepts, as they have often proved confusing in the past. This means: (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2630">r2630</a>)</dt><dd><ul>
<li><p>original item_scraped signal was removed</p></li>
<li><p>original item_passed signal was renamed to item_scraped</p></li>
<li><p>old log lines <code class="docutils literal notranslate"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> were removed</p></li>
<li><p>old log lines <code class="docutils literal notranslate"><span class="pre">Passed</span> <span class="pre">Item...</span></code> were renamed to <code class="docutils literal notranslate"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> lines and downgraded to <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code> level</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Reduced Scrapy codebase by striping part of Scrapy code into two new libraries:</dt><dd><ul>
<li><p><a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> (several functions from <code class="docutils literal notranslate"><span class="pre">scrapy.utils.{http,markup,multipart,response,url}</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2584">r2584</a>)</p></li>
<li><p><a class="reference external" href="https://github.com/scrapy/scrapely">scrapely</a> (was <code class="docutils literal notranslate"><span class="pre">scrapy.contrib.ibl</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2586">r2586</a>)</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Removed unused function: <cite>scrapy.utils.request.request_info()</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2577">r2577</a>)</p></li>
<li><p>Removed googledir project from <cite>examples/googledir</cite>. There’s now a new example project called <cite>dirbot</cite> available on github: <a class="reference external" href="https://github.com/scrapy/dirbot">https://github.com/scrapy/dirbot</a></p></li>
<li><p>Removed support for default field values in Scrapy items (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2616">r2616</a>)</p></li>
<li><p>Removed experimental crawlspider v2 (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2632">r2632</a>)</p></li>
<li><p>Removed scheduler middleware to simplify architecture. Duplicates filter is now done in the scheduler itself, using the same dupe fltering class as before (<cite>DUPEFILTER_CLASS</cite> setting) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2640">r2640</a>)</p></li>
<li><p>Removed support for passing urls to <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">crawl</span></code> command (use <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span></code> instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p></li>
<li><p>Removed deprecated Execution Queue (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p></li>
<li><p>Removed (undocumented) spider context extension (from scrapy.contrib.spidercontext) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2780">r2780</a>)</p></li>
<li><p>removed <code class="docutils literal notranslate"><span class="pre">CONCURRENT_SPIDERS</span></code> setting (use scrapyd maxproc instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2789">r2789</a>)</p></li>
<li><p>Renamed attributes of core components: downloader.sites -&gt; downloader.slots, scraper.sites -&gt; scraper.slots (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2717">r2717</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2718">r2718</a>)</p></li>
<li><p>Renamed setting <code class="docutils literal notranslate"><span class="pre">CLOSESPIDER_ITEMPASSED</span></code> to <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2655">r2655</a>). Backwards compatibility kept.</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-12">
<h2>Scrapy 0.12<a class="headerlink" href="#scrapy-0-12" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features-and-improvements">
<h3>New features and improvements<a class="headerlink" href="#new-features-and-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Passed item is now sent in the <code class="docutils literal notranslate"><span class="pre">item</span></code> argument of the <code class="xref std std-signal docutils literal notranslate"><span class="pre">item_passed</span></code> (#273)</p></li>
<li><p>Added verbose option to <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span></code> command, useful for bug reports (#298)</p></li>
<li><p>HTTP cache now stored by default in the project data dir (#279)</p></li>
<li><p>Added project data storage directory (#276, #277)</p></li>
<li><p>Documented file structure of Scrapy projects (see command-line tool doc)</p></li>
<li><p>New lxml backend for XPath selectors (#147)</p></li>
<li><p>Per-spider settings (#245)</p></li>
<li><p>Support exit codes to signal errors in Scrapy commands (#248)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">-c</span></code> argument to <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span></code> command</p></li>
<li><p>Made <code class="docutils literal notranslate"><span class="pre">libxml2</span></code> optional (#260)</p></li>
<li><p>New <code class="docutils literal notranslate"><span class="pre">deploy</span></code> command (#261)</p></li>
<li><p>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_PAGECOUNT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CLOSESPIDER_PAGECOUNT</span></code></a> setting (#253)</p></li>
<li><p>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CLOSESPIDER_ERRORCOUNT</span></code></a> setting (#254)</p></li>
</ul>
</div>
<div class="section" id="scrapyd-changes">
<h3>Scrapyd changes<a class="headerlink" href="#scrapyd-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scrapyd now uses one process per spider</p></li>
<li><p>It stores one log file per spider run, and rotate them keeping the lastest 5 logs per spider (by default)</p></li>
<li><p>A minimal web ui was added, available at <a class="reference external" href="http://localhost:6800">http://localhost:6800</a> by default</p></li>
<li><p>There is now a <cite>scrapy server</cite> command to start a Scrapyd server of the current project</p></li>
</ul>
</div>
<div class="section" id="changes-to-settings">
<h3>Changes to settings<a class="headerlink" href="#changes-to-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>added <cite>HTTPCACHE_ENABLED</cite> setting (False by default) to enable HTTP cache middleware</p></li>
<li><p>changed <cite>HTTPCACHE_EXPIRATION_SECS</cite> semantics: now zero means “never expire”.</p></li>
</ul>
</div>
<div class="section" id="deprecated-obsoleted-functionality">
<h3>Deprecated/obsoleted functionality<a class="headerlink" href="#deprecated-obsoleted-functionality" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Deprecated <code class="docutils literal notranslate"><span class="pre">runserver</span></code> command in favor of <code class="docutils literal notranslate"><span class="pre">server</span></code> command which starts a Scrapyd server. See also: Scrapyd changes</p></li>
<li><p>Deprecated <code class="docutils literal notranslate"><span class="pre">queue</span></code> command in favor of using Scrapyd <code class="docutils literal notranslate"><span class="pre">schedule.json</span></code> API. See also: Scrapyd changes</p></li>
<li><p>Removed the !LxmlItemLoader (experimental contrib which never graduated to main contrib)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-10">
<h2>Scrapy 0.10<a class="headerlink" href="#scrapy-0-10" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id29">
<h3>New features and improvements<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>New Scrapy service called <code class="docutils literal notranslate"><span class="pre">scrapyd</span></code> for deploying Scrapy crawlers in production (#218) (documentation available)</p></li>
<li><p>Simplified Images pipeline usage which doesn’t require subclassing your own images pipeline now (#217)</p></li>
<li><p>Scrapy shell now shows the Scrapy log by default (#206)</p></li>
<li><p>Refactored execution queue in a common base code and pluggable backends called “spider queues” (#220)</p></li>
<li><p>New persistent spider queue (based on SQLite) (#198), available by default, which allows to start Scrapy in server mode and then schedule spiders to run.</p></li>
<li><p>Added documentation for Scrapy command-line tool and all its available sub-commands. (documentation available)</p></li>
<li><p>Feed exporters with pluggable backends (#197) (documentation available)</p></li>
<li><p>Deferred signals (#193)</p></li>
<li><p>Added two new methods to item pipeline open_spider(), close_spider() with deferred support (#195)</p></li>
<li><p>Support for overriding default request headers per spider (#181)</p></li>
<li><p>Replaced default Spider Manager with one with similar functionality but not depending on Twisted Plugins (#186)</p></li>
<li><p>Splitted Debian package into two packages - the library and the service (#187)</p></li>
<li><p>Scrapy log refactoring (#188)</p></li>
<li><p>New extension for keeping persistent spider contexts among different runs (#203)</p></li>
<li><p>Added <cite>dont_redirect</cite> request.meta key for avoiding redirects (#233)</p></li>
<li><p>Added <cite>dont_retry</cite> request.meta key for avoiding retries (#234)</p></li>
</ul>
</div>
<div class="section" id="command-line-tool-changes">
<h3>Command-line tool changes<a class="headerlink" href="#command-line-tool-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>New <cite>scrapy</cite> command which replaces the old <cite>scrapy-ctl.py</cite> (#199)
- there is only one global <cite>scrapy</cite> command now, instead of one <cite>scrapy-ctl.py</cite> per project
- Added <cite>scrapy.bat</cite> script for running more conveniently from Windows</p></li>
<li><p>Added bash completion to command-line tool (#210)</p></li>
<li><p>Renamed command <cite>start</cite> to <cite>runserver</cite> (#209)</p></li>
</ul>
</div>
<div class="section" id="api-changes">
<h3>API changes<a class="headerlink" href="#api-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">url</span></code> and <code class="docutils literal notranslate"><span class="pre">body</span></code> attributes of Request objects are now read-only (#230)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Request.copy()</span></code> and <code class="docutils literal notranslate"><span class="pre">Request.replace()</span></code> now also copies their <code class="docutils literal notranslate"><span class="pre">callback</span></code> and <code class="docutils literal notranslate"><span class="pre">errback</span></code> attributes (#231)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">UrlFilterMiddleware</span></code> from <code class="docutils literal notranslate"><span class="pre">scrapy.contrib</span></code> (already disabled by default)</p></li>
<li><p>Offsite middelware doesn’t filter out any request coming from a spider that doesn’t have a allowed_domains attribute (#225)</p></li>
<li><p>Removed Spider Manager <code class="docutils literal notranslate"><span class="pre">load()</span></code> method. Now spiders are loaded in the constructor itself.</p></li>
<li><dl class="simple">
<dt>Changes to Scrapy Manager (now called “Crawler”):</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.core.manager.ScrapyManager</span></code> class renamed to <code class="docutils literal notranslate"><span class="pre">scrapy.crawler.Crawler</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.core.manager.scrapymanager</span></code> singleton moved to <code class="docutils literal notranslate"><span class="pre">scrapy.project.crawler</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Moved module: <code class="docutils literal notranslate"><span class="pre">scrapy.contrib.spidermanager</span></code> to <code class="docutils literal notranslate"><span class="pre">scrapy.spidermanager</span></code></p></li>
<li><p>Spider Manager singleton moved from <code class="docutils literal notranslate"><span class="pre">scrapy.spider.spiders</span></code> to the <code class="docutils literal notranslate"><span class="pre">spiders`</span> <span class="pre">attribute</span> <span class="pre">of</span> <span class="pre">``scrapy.project.crawler</span></code> singleton.</p></li>
<li><dl class="simple">
<dt>moved Stats Collector classes: (#204)</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.stats.collector.StatsCollector</span></code> to <code class="docutils literal notranslate"><span class="pre">scrapy.statscol.StatsCollector</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.stats.collector.SimpledbStatsCollector</span></code> to <code class="docutils literal notranslate"><span class="pre">scrapy.contrib.statscol.SimpledbStatsCollector</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>default per-command settings are now specified in the <code class="docutils literal notranslate"><span class="pre">default_settings</span></code> attribute of command object class (#201)</p></li>
<li><dl class="simple">
<dt>changed arguments of Item pipeline <code class="docutils literal notranslate"><span class="pre">process_item()</span></code> method from <code class="docutils literal notranslate"><span class="pre">(spider,</span> <span class="pre">item)</span></code> to <code class="docutils literal notranslate"><span class="pre">(item,</span> <span class="pre">spider)</span></code></dt><dd><ul>
<li><p>backwards compatibility kept (with deprecation warning)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>moved <code class="docutils literal notranslate"><span class="pre">scrapy.core.signals</span></code> module to <code class="docutils literal notranslate"><span class="pre">scrapy.signals</span></code></dt><dd><ul>
<li><p>backwards compatibility kept (with deprecation warning)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>moved <code class="docutils literal notranslate"><span class="pre">scrapy.core.exceptions</span></code> module to <code class="docutils literal notranslate"><span class="pre">scrapy.exceptions</span></code></dt><dd><ul>
<li><p>backwards compatibility kept (with deprecation warning)</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>added <code class="docutils literal notranslate"><span class="pre">handles_request()</span></code> class method to <code class="docutils literal notranslate"><span class="pre">BaseSpider</span></code></p></li>
<li><p>dropped <code class="docutils literal notranslate"><span class="pre">scrapy.log.exc()</span></code> function (use <code class="docutils literal notranslate"><span class="pre">scrapy.log.err()</span></code> instead)</p></li>
<li><p>dropped <code class="docutils literal notranslate"><span class="pre">component</span></code> argument of <code class="docutils literal notranslate"><span class="pre">scrapy.log.msg()</span></code> function</p></li>
<li><p>dropped <code class="docutils literal notranslate"><span class="pre">scrapy.log.log_level</span></code> attribute</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">from_settings()</span></code> class methods to Spider Manager, and Item Pipeline Manager</p></li>
</ul>
</div>
<div class="section" id="id30">
<h3>Changes to settings<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">HTTPCACHE_IGNORE_SCHEMES</span></code> setting to ignore certain schemes on !HttpCacheMiddleware (#225)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">SPIDER_QUEUE_CLASS</span></code> setting which defines the spider queue to use (#220)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">KEEP_ALIVE</span></code> setting (#220)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">SERVICE_QUEUE</span></code> setting (#220)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">COMMANDS_SETTINGS_MODULE</span></code> setting (#201)</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">REQUEST_HANDLERS</span></code> to <code class="docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code> and make download handlers classes (instead of functions)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-9">
<h2>Scrapy 0.9<a class="headerlink" href="#scrapy-0-9" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id31">
<h3>New features and improvements<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Added SMTP-AUTH support to scrapy.mail</p></li>
<li><p>New settings added: <code class="docutils literal notranslate"><span class="pre">MAIL_USER</span></code>, <code class="docutils literal notranslate"><span class="pre">MAIL_PASS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2065">r2065</a> | #149)</p></li>
<li><p>Added new scrapy-ctl view command - To view URL in the browser, as seen by Scrapy (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</p></li>
<li><p>Added web service for controlling Scrapy process (this also deprecates the web console. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2053">r2053</a> | #167)</p></li>
<li><p>Support for running Scrapy as a service, for production systems (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1988">r1988</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2054">r2054</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2055">r2055</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2056">r2056</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2057">r2057</a> | #168)</p></li>
<li><p>Added wrapper induction library (documentation only available in source code for now). (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2011">r2011</a>)</p></li>
<li><p>Simplified and improved response encoding support (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1969">r1969</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">LOG_ENCODING</span></code> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1956">r1956</a>, documentation available)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code> setting (enabled by default) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1923">r1923</a>, doc available)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MailSender</span></code> is no longer IO-blocking (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1955">r1955</a> | #146)</p></li>
<li><p>Linkextractors and new Crawlspider now handle relative base tag urls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1960">r1960</a> | #148)</p></li>
<li><p>Several improvements to Item Loaders and processors (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2022">r2022</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2023">r2023</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2024">r2024</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2025">r2025</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2026">r2026</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2027">r2027</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2028">r2028</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2029">r2029</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2030">r2030</a>)</p></li>
<li><p>Added support for adding variables to telnet console (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a> | #165)</p></li>
<li><p>Support for requests without callbacks (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2050">r2050</a> | #166)</p></li>
</ul>
</div>
<div class="section" id="id32">
<h3>API changes<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Change <code class="docutils literal notranslate"><span class="pre">Spider.domain_name</span></code> to <code class="docutils literal notranslate"><span class="pre">Spider.name</span></code> (SEP-012, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1975">r1975</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Response.encoding</span></code> is now the detected encoding (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HttpErrorMiddleware</span></code> now returns None or raises an exception (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2006">r2006</a> | #157)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.command</span></code> modules relocation (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2035">r2035</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2036">r2036</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2037">r2037</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">ExecutionQueue</span></code> for feeding spiders to scrape (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2034">r2034</a>)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">ExecutionEngine</span></code> singleton (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</p></li>
<li><p>Ported <code class="docutils literal notranslate"><span class="pre">S3ImagesStore</span></code> (images pipeline) to use boto and threads (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2033">r2033</a>)</p></li>
<li><p>Moved module: <code class="docutils literal notranslate"><span class="pre">scrapy.management.telnet</span></code> to <code class="docutils literal notranslate"><span class="pre">scrapy.telnet</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a>)</p></li>
</ul>
</div>
<div class="section" id="changes-to-default-settings">
<h3>Changes to default settings<a class="headerlink" href="#changes-to-default-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Changed default <code class="docutils literal notranslate"><span class="pre">SCHEDULER_ORDER</span></code> to <code class="docutils literal notranslate"><span class="pre">DFO</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1939">r1939</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-8">
<h2>Scrapy 0.8<a class="headerlink" href="#scrapy-0-8" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id33">
<h3>New features<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Added DEFAULT_RESPONSE_ENCODING setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1809">r1809</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">dont_click</span></code> argument to <code class="docutils literal notranslate"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1813">r1813</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1816">r1816</a>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">clickdata</span></code> argument to <code class="docutils literal notranslate"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1802">r1802</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1803">r1803</a>)</p></li>
<li><p>Added support for HTTP proxies (<code class="docutils literal notranslate"><span class="pre">HttpProxyMiddleware</span></code>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1781">r1781</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1785">r1785</a>)</p></li>
<li><p>Offsite spider middleware now logs messages when filtering out requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1841">r1841</a>)</p></li>
</ul>
</div>
<div class="section" id="id34">
<h3>Backwards-incompatible changes<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Changed <code class="docutils literal notranslate"><span class="pre">scrapy.utils.response.get_meta_refresh()</span></code> signature (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1804">r1804</a>)</p></li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">scrapy.item.ScrapedItem</span></code> class - use <code class="docutils literal notranslate"><span class="pre">scrapy.item.Item</span> <span class="pre">instead</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1838">r1838</a>)</p></li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">scrapy.xpath</span></code> module - use <code class="docutils literal notranslate"><span class="pre">scrapy.selector</span></code> instead. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1836">r1836</a>)</p></li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">core.signals.domain_open</span></code> signal - use <code class="docutils literal notranslate"><span class="pre">core.signals.domain_opened</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">log.msg()</span></code> now receives a <code class="docutils literal notranslate"><span class="pre">spider</span></code> argument (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</dt><dd><ul>
<li><p>Old domain argument has been deprecated and will be removed in 0.9. For spiders, you should always use the <code class="docutils literal notranslate"><span class="pre">spider</span></code> argument and pass spider references. If you really want to pass a string, use the <code class="docutils literal notranslate"><span class="pre">component</span></code> argument instead.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Changed core signals <code class="docutils literal notranslate"><span class="pre">domain_opened</span></code>, <code class="docutils literal notranslate"><span class="pre">domain_closed</span></code>, <code class="docutils literal notranslate"><span class="pre">domain_idle</span></code></p></li>
<li><dl class="simple">
<dt>Changed Item pipeline to use spiders instead of domains</dt><dd><ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">domain</span></code> argument of  <code class="docutils literal notranslate"><span class="pre">process_item()</span></code> item pipeline method was changed to  <code class="docutils literal notranslate"><span class="pre">spider</span></code>, the new signature is: <code class="docutils literal notranslate"><span class="pre">process_item(spider,</span> <span class="pre">item)</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1827">r1827</a> | #105)</p></li>
<li><p>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal notranslate"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal notranslate"><span class="pre">domain</span></code>.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Changed Stats API to use spiders instead of domains (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1849">r1849</a> | #113)</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">StatsCollector</span></code> was changed to receive spider references (instead of domains) in its methods (<code class="docutils literal notranslate"><span class="pre">set_value</span></code>, <code class="docutils literal notranslate"><span class="pre">inc_value</span></code>, etc).</p></li>
<li><p>added <code class="docutils literal notranslate"><span class="pre">StatsCollector.iter_spider_stats()</span></code> method</p></li>
<li><p>removed <code class="docutils literal notranslate"><span class="pre">StatsCollector.list_domains()</span></code> method</p></li>
<li><p>Also, Stats signals were renamed and now pass around spider references (instead of domains). Here’s a summary of the changes:</p></li>
<li><p>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal notranslate"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal notranslate"><span class="pre">domain</span></code>. <code class="docutils literal notranslate"><span class="pre">spider_stats</span></code> contains exactly the same data as <code class="docutils literal notranslate"><span class="pre">domain_stats</span></code>.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">CloseDomain</span></code> extension moved to <code class="docutils literal notranslate"><span class="pre">scrapy.contrib.closespider.CloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1833">r1833</a>)</dt><dd><ul>
<li><dl class="simple">
<dt>Its settings were also renamed:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">CLOSEDOMAIN_TIMEOUT</span></code> to <code class="docutils literal notranslate"><span class="pre">CLOSESPIDER_TIMEOUT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CLOSEDOMAIN_ITEMCOUNT</span></code> to <code class="docutils literal notranslate"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">SCRAPYSETTINGS_MODULE</span></code> environment variable - use <code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1840">r1840</a>)</p></li>
<li><p>Renamed setting: <code class="docutils literal notranslate"><span class="pre">REQUESTS_PER_DOMAIN</span></code> to <code class="docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1844">r1844</a>)</p></li>
<li><p>Renamed setting: <code class="docutils literal notranslate"><span class="pre">CONCURRENT_DOMAINS</span></code> to <code class="docutils literal notranslate"><span class="pre">CONCURRENT_SPIDERS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>)</p></li>
<li><p>Refactored HTTP Cache middleware</p></li>
<li><p>HTTP Cache middleware has been heavilty refactored, retaining the same functionality except for the domain sectorization which was removed. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1843">r1843</a> )</p></li>
<li><p>Renamed exception: <code class="docutils literal notranslate"><span class="pre">DontCloseDomain</span></code> to <code class="docutils literal notranslate"><span class="pre">DontCloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1859">r1859</a> | #120)</p></li>
<li><p>Renamed extension: <code class="docutils literal notranslate"><span class="pre">DelayedCloseDomain</span></code> to <code class="docutils literal notranslate"><span class="pre">SpiderCloseDelay</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1861">r1861</a> | #121)</p></li>
<li><p>Removed obsolete <code class="docutils literal notranslate"><span class="pre">scrapy.utils.markup.remove_escape_chars</span></code> function - use <code class="docutils literal notranslate"><span class="pre">scrapy.utils.markup.replace_escape_chars</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1865">r1865</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-7">
<h2>Scrapy 0.7<a class="headerlink" href="#scrapy-0-7" title="Permalink to this headline">¶</a></h2>
<p>First release of Scrapy.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contributing.html" class="btn btn-neutral float-right" title="Contributing to Scrapy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="topics/exporters.html" class="btn btn-neutral float-left" title="Item Exporters" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008–2018, Scrapy developers
      <span class="lastupdated">
        Last updated on Feb 27, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>


</body>
</html>