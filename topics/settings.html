

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>设置 &mdash; Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="例外" href="exceptions.html" />
    <link rel="prev" title="链接提取器" href="link-extractors.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
              <div class="version">
                1.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy 一目了然</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">示例</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="commands.html">命令行工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">爬虫（Spiders）</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item 装载器</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline（项目管道）</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed 导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">请求与响应</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">链接提取器</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">设置</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#topics-settings-module-envvar">指定设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">填充设置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">1. 命令行选项</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">2. 设置每个爬虫</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">3. 项目设置模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-settings-per-command">4. Default settings per-command</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">5. 默认全局设置</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id8">如何访问设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">设置名称的原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topics-settings-ref">内置设置参考</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#aws-access-key-id">AWS_ACCESS_KEY_ID</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-secret-access-key">AWS_SECRET_ACCESS_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-endpoint-url">AWS_ENDPOINT_URL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-use-ssl">AWS_USE_SSL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-verify">AWS_VERIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-region-name">AWS_REGION_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bot-name">BOT_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-items">CONCURRENT_ITEMS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests">CONCURRENT_REQUESTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests-per-domain">CONCURRENT_REQUESTS_PER_DOMAIN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests-per-ip">CONCURRENT_REQUESTS_PER_IP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-item-class">DEFAULT_ITEM_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-request-headers">DEFAULT_REQUEST_HEADERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-limit">DEPTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-priority">DEPTH_PRIORITY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-stats-verbose">DEPTH_STATS_VERBOSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnscache-enabled">DNSCACHE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnscache-size">DNSCACHE_SIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dns-timeout">DNS_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader">DOWNLOADER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-httpclientfactory">DOWNLOADER_HTTPCLIENTFACTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-clientcontextfactory">DOWNLOADER_CLIENTCONTEXTFACTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-client-tls-method">DOWNLOADER_CLIENT_TLS_METHOD</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares">DOWNLOADER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares-base">DOWNLOADER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-stats">DOWNLOADER_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-delay">DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers">DOWNLOAD_HANDLERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers-base">DOWNLOAD_HANDLERS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-timeout">DOWNLOAD_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-maxsize">DOWNLOAD_MAXSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-warnsize">DOWNLOAD_WARNSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-fail-on-dataloss">DOWNLOAD_FAIL_ON_DATALOSS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dupefilter-class">DUPEFILTER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dupefilter-debug">DUPEFILTER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#std:setting-EDITOR">编辑</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions">EXTENSIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions-base">EXTENSIONS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#feed-tempdir">FEED_TEMPDIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-passive-mode">FTP_PASSIVE_MODE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-password">FTP_PASSWORD</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-user">FTP_USER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#item-pipelines">ITEM_PIPELINES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#item-pipelines-base">ITEM_PIPELINES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-enabled">LOG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-encoding">LOG_ENCODING</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-file">LOG_FILE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-format">LOG_FORMAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-dateformat">LOG_DATEFORMAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-level">LOG_LEVEL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-stdout">LOG_STDOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-short-names">LOG_SHORT_NAMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-enabled">MEMDEBUG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-notify">MEMDEBUG_NOTIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-enabled">MEMUSAGE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-limit-mb">MEMUSAGE_LIMIT_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-check-interval-seconds">MEMUSAGE_CHECK_INTERVAL_SECONDS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-notify-mail">MEMUSAGE_NOTIFY_MAIL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-warning-mb">MEMUSAGE_WARNING_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#newspider-module">NEWSPIDER_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomize-download-delay">RANDOMIZE_DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reactor-threadpool-maxsize">REACTOR_THREADPOOL_MAXSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-max-times">REDIRECT_MAX_TIMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-priority-adjust">REDIRECT_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#retry-priority-adjust">RETRY_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robotstxt-obey">ROBOTSTXT_OBEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler">SCHEDULER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-debug">SCHEDULER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-disk-queue">SCHEDULER_DISK_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-memory-queue">SCHEDULER_MEMORY_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-priority-queue">SCHEDULER_PRIORITY_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-contracts">SPIDER_CONTRACTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-contracts-base">SPIDER_CONTRACTS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-loader-class">SPIDER_LOADER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-loader-warn-only">SPIDER_LOADER_WARN_ONLY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares">SPIDER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares-base">SPIDER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-modules">SPIDER_MODULES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-class">STATS_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-dump">STATS_DUMP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statsmailer-rcpts">STATSMAILER_RCPTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-enabled">TELNETCONSOLE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-port">TELNETCONSOLE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#templates-dir">TEMPLATES_DIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#urllength-limit">URLLENGTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-agent">USER_AGENT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">其他地方记录的设置:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">例外</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">统计收集</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">发送电子邮件</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet 控制台</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web 服务</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="media-pipeline.html">下载和处理文件与图像</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle 扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">信号(Signals)</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>设置</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/topics/settings.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="topics-settings">
<span id="id1"></span><h1>设置<a class="headerlink" href="#topics-settings" title="Permalink to this headline">¶</a></h1>
<p>Scrapy设置允许您自定义所有Scrapy组件的行为，包括核心，扩展，管道和爬虫本身。</p>
<p>设置的基础结构提供了键值映射的全局命名空间，代码可以使用该命名空间从中提取配置值。可以通过不同的机制填充设置，如下所述。</p>
<p>这些设置也是选择当前活动的Scrapy项目的机制（如果您有很多）。</p>
<p>有关可用内置设置的列表，请参阅: <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">内置设置参考</span></a>.</p>
<div class="section" id="topics-settings-module-envvar">
<span id="id2"></span><h2>指定设置<a class="headerlink" href="#topics-settings-module-envvar" title="Permalink to this headline">¶</a></h2>
<p>当您使用Scrapy时，您必须告诉它您正在使用哪些设置。您可以使用环境变量来完成此操作, <code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> 的值应该是Python路径语法， 例如
<code class="docutils literal notranslate"><span class="pre">myproject.settings</span></code>. 请注意，设置模块应位于Python <a class="reference external" href="https://docs.python.org/2/tutorial/modules.html#the-module-search-path">import search path</a>.</p>
</div>
<div class="section" id="id3">
<h2>填充设置<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>可以使用不同的机制填充设置，每个机制具有不同的优先级。以下是按优先顺序递减的列表：</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>命令行选项（最优先）</p></li>
<li><p>设置每一个爬虫</p></li>
<li><p>项目设置模块</p></li>
<li><p>每个命令的默认设置</p></li>
<li><p>默认全局设置（优先级较低）</p></li>
</ol>
</div></blockquote>
<p>这些设置源的数量由内部处理，但可以使用API调用进行手动处理。 请参阅
<a class="reference internal" href="api.html#topics-api-settings"><span class="std std-ref">Settings API</span></a> 主题以供参考。</p>
<p>下面更详细地描述这些机制。</p>
<div class="section" id="id4">
<h3>1. 命令行选项<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>命令行提供的参数是最优先的参数，覆盖任何其他选项。您可以使用 <code class="docutils literal notranslate"><span class="pre">-s</span></code> (或 <code class="docutils literal notranslate"><span class="pre">--set</span></code>) 命令行选项显式覆盖一个（或多个）设置。</p>
<p>例:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>scrapy crawl myspider -s <span class="nv">LOG_FILE</span><span class="o">=</span>scrapy.log
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>2. 设置每个爬虫<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>Spiders (产检 <a class="reference internal" href="spiders.html#topics-spiders"><span class="std std-ref">爬虫（Spiders）</span></a> 章节以供参考) 可以定义自己的设置，这些设置优先并覆盖项目设置。他们可以通过设置 <a class="reference internal" href="spiders.html#scrapy.spiders.Spider.custom_settings" title="scrapy.spiders.Spider.custom_settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">custom_settings</span></code></a> 属性来实现:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>class MySpider<span class="o">(</span>scrapy.Spider<span class="o">)</span>:
    <span class="nv">name</span> <span class="o">=</span> <span class="s1">&#39;myspider&#39;</span>

    <span class="nv">custom_settings</span> <span class="o">=</span> <span class="o">{</span>
        <span class="s1">&#39;SOME_SETTING&#39;</span>: <span class="s1">&#39;some value&#39;</span>,
    <span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h3>3. 项目设置模块<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>项目设置模块是Scrapy项目的标准配置文件，它将填充大多数自定义设置。对于标准Scrapy项目，这意味着您将添加或更改 <code class="docutils literal notranslate"><span class="pre">settings.py</span></code> 为项目创建的文件中的设置。</p>
</div>
<div class="section" id="default-settings-per-command">
<h3>4. Default settings per-command<a class="headerlink" href="#default-settings-per-command" title="Permalink to this headline">¶</a></h3>
<p>每个 <a class="reference internal" href="commands.html"><span class="doc">Scrapy 工具</span></a> 命令都可以有自己的默认设置，这些设置会覆盖全局默认设置。这些自定义命令设置在 <code class="docutils literal notranslate"><span class="pre">default_settings</span></code> 命令类的属性中指定。
class.</p>
</div>
<div class="section" id="id7">
<h3>5. 默认全局设置<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>全局默认值位于 <code class="docutils literal notranslate"><span class="pre">scrapy.settings.default_settings</span></code>
模块中，并记录在 <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">内置设置参考</span></a> 部分中。</p>
</div>
</div>
<div class="section" id="id8">
<h2>如何访问设置<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>在spider中，可以通过 <code class="docutils literal notranslate"><span class="pre">self.settings</span></code> 使用这些设置:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;myspider&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://example.com&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Existing settings: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">attributes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">settings</span></code> 初始化spider后，在Spider类中设置该属性。如果要在初始化之前使用这些设置（例如，在spider的 <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> 方法中），则需要覆盖该
<a class="reference internal" href="spiders.html#scrapy.spiders.Spider.from_crawler" title="scrapy.spiders.Spider.from_crawler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_crawler()</span></code></a> method.</p>
</div>
<p>可以通过 <a class="reference internal" href="api.html#scrapy.crawler.Crawler.settings" title="scrapy.crawler.Crawler.settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scrapy.crawler.Crawler.settings</span></code></a>
Crawler 的属性访问设置，该属性传递给 <code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> 扩展，中间件和项目管道中的方法:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyExtension</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_is_enabled</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">log_is_enabled</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;log is enabled!&quot;</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">settings</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">getbool</span><span class="p">(</span><span class="s1">&#39;LOG_ENABLED&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>T设置对象可以像dict一样使用（例如,
<code class="docutils literal notranslate"><span class="pre">settings['LOG_ENABLED']</span></code>), 但通常首选使用 <a class="reference internal" href="api.html#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal notranslate"><span class="pre">Settings</span></code></a> API 提供的方法之一以您需要的格式提取设置以避免类型错误。.</p>
</div>
<div class="section" id="id9">
<h2>设置名称的原理<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>设置名称通常以它们配置的组件为前缀。例如，对于一个虚构的robots.txt扩展正确的设置名称为
<code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_ENABLED</span></code>, <code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_OBEY</span></code>, <code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_CACHEDIR</span></code>, 等。</p>
</div>
<div class="section" id="topics-settings-ref">
<span id="id10"></span><h2>内置设置参考<a class="headerlink" href="#topics-settings-ref" title="Permalink to this headline">¶</a></h2>
<p>以下是所有可用Scrapy设置的列表，按字母顺序排列，以及它们的默认值和适用范围。</p>
<p>范围（如果可用）显示设置的使用位置，如果它与任何特定组件相关联。在那种情况下，将显示该组件的模块，通常是扩展，中间件或管道。它还意味着必须启用该组件才能使设置产生任何效果。</p>
<div class="section" id="aws-access-key-id">
<span id="std:setting-AWS_ACCESS_KEY_ID"></span><h3>AWS_ACCESS_KEY_ID<a class="headerlink" href="#aws-access-key-id" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>需要访问 <a class="reference external" href="https://aws.amazon.com/">Amazon Web services</a>,
的代码使用的AWS访问密钥，例如 <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="aws-secret-access-key">
<span id="std:setting-AWS_SECRET_ACCESS_KEY"></span><h3>AWS_SECRET_ACCESS_KEY<a class="headerlink" href="#aws-secret-access-key" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>需要访问 <a class="reference external" href="https://aws.amazon.com/">Amazon Web services</a>,
的代码使用的AWS访问密钥，例如 <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="aws-endpoint-url">
<span id="std:setting-AWS_ENDPOINT_URL"></span><h3>AWS_ENDPOINT_URL<a class="headerlink" href="#aws-endpoint-url" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>用于类似S3的存储的端点URL，例如Minio或s3.scality。仅支持 <code class="docutils literal notranslate"><span class="pre">botocore</span></code> 库.</p>
</div>
<div class="section" id="aws-use-ssl">
<span id="std:setting-AWS_USE_SSL"></span><h3>AWS_USE_SSL<a class="headerlink" href="#aws-use-ssl" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>如果要禁用SSL连接以与S3或类似S3的存储进行通信，请使用此选项。默认情况下，将使用SSL。仅支持 <code class="docutils literal notranslate"><span class="pre">botocore</span></code> 库.</p>
</div>
<div class="section" id="aws-verify">
<span id="std:setting-AWS_VERIFY"></span><h3>AWS_VERIFY<a class="headerlink" href="#aws-verify" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>验证Scrapy与S3或类似S3的存储之间的SSL连接。默认情况下，将进行SSL验证。仅支持 <code class="docutils literal notranslate"><span class="pre">botocore</span></code> 库.</p>
</div>
<div class="section" id="aws-region-name">
<span id="std:setting-AWS_REGION_NAME"></span><h3>AWS_REGION_NAME<a class="headerlink" href="#aws-region-name" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>与AWS客户端关联的区域的名称。仅支持 <code class="docutils literal notranslate"><span class="pre">botocore</span></code> 库.</p>
</div>
<div class="section" id="bot-name">
<span id="std:setting-BOT_NAME"></span><h3>BOT_NAME<a class="headerlink" href="#bot-name" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapybot'</span></code></p>
<p>此Scrapy项目实现的机器人名称（也称为项目名称）。这将默认用于构建User-Agent，也用于日志记录。</p>
<p>使用该 <a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a> 命令创建项目时，它会自动填充项目名称。</p>
</div>
<div class="section" id="concurrent-items">
<span id="std:setting-CONCURRENT_ITEMS"></span><h3>CONCURRENT_ITEMS<a class="headerlink" href="#concurrent-items" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">100</span></code></p>
<p>在项目处理器（也称为 <a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><span class="std std-ref">Item Pipeline</span></a>)  中并行处理的最大并发项数（每个响应）。</p>
</div>
<div class="section" id="concurrent-requests">
<span id="std:setting-CONCURRENT_REQUESTS"></span><h3>CONCURRENT_REQUESTS<a class="headerlink" href="#concurrent-requests" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">16</span></code></p>
<p>TScrapy下载程序将执行的最大并发（即同时）请求数。</p>
</div>
<div class="section" id="concurrent-requests-per-domain">
<span id="std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"></span><h3>CONCURRENT_REQUESTS_PER_DOMAIN<a class="headerlink" href="#concurrent-requests-per-domain" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">8</span></code></p>
<p>将对任何单个域执行的最大并发（即同时）请求数。</p>
<p>另请参阅: <a class="reference internal" href="autothrottle.html#topics-autothrottle"><span class="std std-ref">AutoThrottle 扩展</span></a> 及其
<a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AUTOTHROTTLE_TARGET_CONCURRENCY</span></code></a> 选项.</p>
</div>
<div class="section" id="concurrent-requests-per-ip">
<span id="std:setting-CONCURRENT_REQUESTS_PER_IP"></span><h3>CONCURRENT_REQUESTS_PER_IP<a class="headerlink" href="#concurrent-requests-per-ip" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>将对任何单个IP执行的最大并发（即同时）请求数。如果非零
<a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a> 则忽略该 设置，而使用此设置。换句话说，并发限制将应用于每个IP，而不是每个域。</p>
<p>此设置还会影响 <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> 和
<a class="reference internal" href="autothrottle.html#topics-autothrottle"><span class="std std-ref">AutoThrottle 扩展</span></a>: 如果 <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a>
非零, IP而不是每个域强制执行下载延迟。</p>
</div>
<div class="section" id="default-item-class">
<span id="std:setting-DEFAULT_ITEM_CLASS"></span><h3>DEFAULT_ITEM_CLASS<a class="headerlink" href="#default-item-class" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.item.Item'</span></code></p>
<p>将用于实例化 <a class="reference internal" href="shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a> 中的项的默认类。</p>
</div>
<div class="section" id="default-request-headers">
<span id="std:setting-DEFAULT_REQUEST_HEADERS"></span><h3>DEFAULT_REQUEST_HEADERS<a class="headerlink" href="#default-request-headers" title="Permalink to this headline">¶</a></h3>
<p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;en&#39;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>用于Scrapy HTTP请求的默认标头。他们存放在在
<a class="reference internal" href="downloader-middleware.html#scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware" title="scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">DefaultHeadersMiddleware</span></code></a>.</p>
</div>
<div class="section" id="depth-limit">
<span id="std:setting-DEPTH_LIMIT"></span><h3>DEPTH_LIMIT<a class="headerlink" href="#depth-limit" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>允许为任何站点爬网的最大深度。如果为零，则不会施加任何限制。</p>
</div>
<div class="section" id="depth-priority">
<span id="std:setting-DEPTH_PRIORITY"></span><h3>DEPTH_PRIORITY<a class="headerlink" href="#depth-priority" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>一个整数，用于根据深度调整请求优先级：</p>
<ul class="simple">
<li><p>如果为零（默认），则不从深度进行优先级调整</p></li>
<li><p><strong>正值将降低优先级，即稍后将处理更高深度的请求</strong> ; 这在进行广度优先爬网（BFO）时常用</p></li>
<li><p>负值将增加优先级，即更快的深度请求将被更快地处理（DFO）</p></li>
</ul>
<p>另请参阅: <a class="reference internal" href="../faq.html#faq-bfo-dfo"><span class="std std-ref">Does Scrapy crawl in breadth-first or depth-first order?</span></a> 关于为BFO或DFO调整Scrapy。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>此设置调整优先级 <strong>以相反的方式</strong> 相对于其他优先级设置 <a class="reference internal" href="#std:setting-REDIRECT_PRIORITY_ADJUST"><code class="xref std std-setting docutils literal notranslate"><span class="pre">REDIRECT_PRIORITY_ADJUST</span></code></a>
和 <a class="reference internal" href="#std:setting-RETRY_PRIORITY_ADJUST"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_PRIORITY_ADJUST</span></code></a>.</p>
</div>
</div>
<div class="section" id="depth-stats-verbose">
<span id="std:setting-DEPTH_STATS_VERBOSE"></span><h3>DEPTH_STATS_VERBOSE<a class="headerlink" href="#depth-stats-verbose" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>是否收集详细的深度统计数据。如果启用此选项，则会在统计信息中收集每个深度的请求数。</p>
</div>
<div class="section" id="dnscache-enabled">
<span id="std:setting-DNSCACHE_ENABLED"></span><h3>DNSCACHE_ENABLED<a class="headerlink" href="#dnscache-enabled" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>是否启用DNS内存缓存。</p>
</div>
<div class="section" id="dnscache-size">
<span id="std:setting-DNSCACHE_SIZE"></span><h3>DNSCACHE_SIZE<a class="headerlink" href="#dnscache-size" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">10000</span></code></p>
<p>DNS内存缓存大小。</p>
</div>
<div class="section" id="dns-timeout">
<span id="std:setting-DNS_TIMEOUT"></span><h3>DNS_TIMEOUT<a class="headerlink" href="#dns-timeout" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">60</span></code></p>
<p>在几秒钟内处理DNS查询的超时。支持浮动。</p>
</div>
<div class="section" id="downloader">
<span id="std:setting-DOWNLOADER"></span><h3>DOWNLOADER<a class="headerlink" href="#downloader" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.Downloader'</span></code></p>
<p>用于抓取的下载程序。</p>
</div>
<div class="section" id="downloader-httpclientfactory">
<span id="std:setting-DOWNLOADER_HTTPCLIENTFACTORY"></span><h3>DOWNLOADER_HTTPCLIENTFACTORY<a class="headerlink" href="#downloader-httpclientfactory" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.webclient.ScrapyHTTPClientFactory'</span></code></p>
<p>定义 <code class="docutils literal notranslate"><span class="pre">protocol.ClientFactory</span></code>  用于HTTP / 1.0连接（对于 <code class="docutils literal notranslate"><span class="pre">HTTP10DownloadHandler</span></code>)的Twisted 类。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>HTTP / 1.0现在很少或使用，因此您可以放心地忽略此设置，除非你使用双绞线&lt;11.1，如果你真的想使用HTTP / 1.0，并覆盖 <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS_BASE</span></code></a> 了 <code class="docutils literal notranslate"><span class="pre">http(s)</span></code> 相应的方案，即
<code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.handlers.http.HTTP10DownloadHandler'</span></code>.</p>
</div>
</div>
<div class="section" id="downloader-clientcontextfactory">
<span id="std:setting-DOWNLOADER_CLIENTCONTEXTFACTORY"></span><h3>DOWNLOADER_CLIENTCONTEXTFACTORY<a class="headerlink" href="#downloader-clientcontextfactory" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.contextfactory.ScrapyClientContextFactory'</span></code></p>
<p>表示要使用的ContextFactory的类路径。</p>
<p>这里，“ContextFactory”是SSL / TLS上下文的Twisted术语，定义了要使用的TLS / SSL协议版本，是否进行证书验证，甚至启用客户端身份验证（以及其他各种事情）。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Scrapy默认上下文管理 <strong>不执行远程服务器证书验证</strong>. 这通常适用于网页抓取。</p>
<p>如果确实需要启用远程服务器证书验证，Scrapy还有另一个可以设置的上下文管理类,
<code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.contextfactory.BrowserLikeContextFactory'</span></code>,
它使用平台的证书来验证远程端点。
<strong>仅当您使用Twisted&gt; = 14.0时才可用</strong></p>
</div>
<p>如果您确实使用自定义ContextFactory，请确保它 <code class="docutils literal notranslate"><span class="pre">method</span></code>
在init 接受参数（这是 <code class="docutils literal notranslate"><span class="pre">OpenSSL.SSL</span></code> 方法映射
<a class="reference internal" href="#std:setting-DOWNLOADER_CLIENT_TLS_METHOD"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOADER_CLIENT_TLS_METHOD</span></code></a>).</p>
</div>
<div class="section" id="downloader-client-tls-method">
<span id="std:setting-DOWNLOADER_CLIENT_TLS_METHOD"></span><h3>DOWNLOADER_CLIENT_TLS_METHOD<a class="headerlink" href="#downloader-client-tls-method" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'TLS'</span></code></p>
<p>使用此设置可自定义默认HTTP / 1.1下载程序使用的TLS / SSL方法。</p>
<p>此设置必须是以下字符串值之一：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'TLS'</span></code>: 映射到OpenSSL  <code class="docutils literal notranslate"><span class="pre">TLS_method()</span></code> (又名 <code class="docutils literal notranslate"><span class="pre">SSLv23_method()</span></code>),
允许协议协商，从平台支持的最高点开始;  <strong>默认，推荐</strong></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'TLSv1.0'</span></code>: 此值强制HTTPS连接使用TLS 1.0版; 如果你想要Scrapy的行为&lt;1.1，请设置此项</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'TLSv1.1'</span></code>: 强制TLS版本1.1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'TLSv1.2'</span></code>: 强制TLS版本1.2</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'SSLv3'</span></code>: 强制SSL版本3 (<strong>不推荐</strong>)</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>我们建议您使用PyOpenSSL&gt; = 0.13和Twisted&gt; = 0.13或更高（如果可以，Twisted&gt; = 14.0）。</p>
</div>
</div>
<div class="section" id="downloader-middlewares">
<span id="std:setting-DOWNLOADER_MIDDLEWARES"></span><h3>DOWNLOADER_MIDDLEWARES<a class="headerlink" href="#downloader-middlewares" title="Permalink to this headline">¶</a></h3>
<p>默认:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含项目中启用的下载器中间件及其订单的dict。有关更多信息，请参阅 <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-middlewares-base">
<span id="std:setting-DOWNLOADER_MIDDLEWARES_BASE"></span><h3>DOWNLOADER_MIDDLEWARES_BASE<a class="headerlink" href="#downloader-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;</span><span class="p">:</span> <span class="mi">350</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;</span><span class="p">:</span> <span class="mi">550</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware&#39;</span><span class="p">:</span> <span class="mi">560</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;</span><span class="p">:</span> <span class="mi">580</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;</span><span class="p">:</span> <span class="mi">590</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;</span><span class="p">:</span> <span class="mi">850</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware&#39;</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>包含Scrapy中默认启用的下载器中间件的dict。低订单更接近引擎，高订单更接近下载。您永远不应该在项目中修改此设置,
<a class="reference internal" href="#std:setting-DOWNLOADER_MIDDLEWARES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOADER_MIDDLEWARES</span></code></a> instead. 而是修改 。有关更多信息，请参阅
<a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-stats">
<span id="std:setting-DOWNLOADER_STATS"></span><h3>DOWNLOADER_STATS<a class="headerlink" href="#downloader-stats" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>是否启用下载程序统计信息收集。</p>
</div>
<div class="section" id="download-delay">
<span id="std:setting-DOWNLOAD_DELAY"></span><h3>DOWNLOAD_DELAY<a class="headerlink" href="#download-delay" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>在从同一网站下载连续页面之前，下载程序应等待的时间（以秒为单位）。这可用于限制爬行速度，以避免过于严重地击中服务器。支持十进制数。例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mf">0.25</span>    <span class="c1"># 250 ms of delay</span>
</pre></div>
</div>
<p>此设置也受e <a class="reference internal" href="#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a>
设置（默认情况下启用）的影响。默认情况下，Scrapy不会在请求之间等待一段固定的时间，而是使用0.5* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> 和1.5* 之间的随机间隔:setting:<cite>DOWNLOAD_DELAY</cite>.</p>
<p>当 <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a> 非零时，每个IP地址而不是每个域强制执行延迟。</p>
<p>Y您还可以通过设置 <code class="docutils literal notranslate"><span class="pre">download_delay</span></code>
spider属性来更改每个爬虫的此设置。</p>
</div>
<div class="section" id="download-handlers">
<span id="std:setting-DOWNLOAD_HANDLERS"></span><h3>DOWNLOAD_HANDLERS<a class="headerlink" href="#download-handlers" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含项目中启用的请求下载程序处理程序的dict。
请参阅 <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS_BASE</span></code></a> 格式。</p>
</div>
<div class="section" id="download-handlers-base">
<span id="std:setting-DOWNLOAD_HANDLERS_BASE"></span><h3>DOWNLOAD_HANDLERS_BASE<a class="headerlink" href="#download-handlers-base" title="Permalink to this headline">¶</a></h3>
<p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;file&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.core.downloader.handlers.file.FileDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;http&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;https&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;s3&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.core.downloader.handlers.s3.S3DownloadHandler&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ftp&#39;</span><span class="p">:</span> <span class="s1">&#39;scrapy.core.downloader.handlers.ftp.FTPDownloadHandler&#39;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>包含Scrapy中默认启用的请求下载处理程序的dict。您永远不应该在项目中修改此设置，
<a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> 而是修改。</p>
<p>您可以通过分配 <code class="docutils literal notranslate"><span class="pre">None</span></code> 其URI方案来禁用任何这些下载处理程序 <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code></a>. 例如，要禁用内置的FTP处理程序（无需替换），请将其放在 <code class="docutils literal notranslate"><span class="pre">settings.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_HANDLERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;ftp&#39;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="download-timeout">
<span id="std:setting-DOWNLOAD_TIMEOUT"></span><h3>DOWNLOAD_TIMEOUT<a class="headerlink" href="#download-timeout" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">180</span></code></p>
<p>下载程序在超时之前等待的时间（以秒为单位）。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>可以使用 <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_timeout</span></code>
pider属性为每个spider设置此超时，使用 <a class="reference internal" href="request-response.html#std:reqmeta-download_timeout"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_timeout</span></code></a>
Request.meta键为每个请求设置此超时。</p>
</div>
</div>
<div class="section" id="download-maxsize">
<span id="std:setting-DOWNLOAD_MAXSIZE"></span><h3>DOWNLOAD_MAXSIZE<a class="headerlink" href="#download-maxsize" title="Permalink to this headline">¶</a></h3>
<p>默认: <cite>1073741824</cite> (1024MB)</p>
<p>下载程序将下载的最大响应大小（以字节为单位）。</p>
<p>如果要禁用它，请将其设置为0。</p>
<div class="admonition note" id="std:reqmeta-download_maxsize">
<p class="admonition-title">Note</p>
<p>可以使用 <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_maxsize</span></code>
spider属性为每个蜘蛛设置此大小，使用 <a class="reference internal" href="#std:reqmeta-download_maxsize"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_maxsize</span></code></a>
Request.meta键为每个请求设置此大小。</p>
<p>此功能需要Twisted&gt; = 11.1。</p>
</div>
</div>
<div class="section" id="download-warnsize">
<span id="std:setting-DOWNLOAD_WARNSIZE"></span><h3>DOWNLOAD_WARNSIZE<a class="headerlink" href="#download-warnsize" title="Permalink to this headline">¶</a></h3>
<p>默认: <cite>33554432</cite> (32MB)</p>
<p>下载程序将开始警告的响应大小（以字节为单位）。</p>
<p>如果要禁用它，请将其设置为0。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>T可以使用 <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_warnsize</span></code>
spider属性为每个蜘蛛设置此大小，使用 <code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_warnsize</span></code>
Request.meta键为每个请求设置此大小。</p>
<p>此功能需要Twisted&gt; = 11.1。</p>
</div>
</div>
<div class="section" id="download-fail-on-dataloss">
<span id="std:setting-DOWNLOAD_FAIL_ON_DATALOSS"></span><h3>DOWNLOAD_FAIL_ON_DATALOSS<a class="headerlink" href="#download-fail-on-dataloss" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>是否在响应中断时失败，即声明
<code class="docutils literal notranslate"><span class="pre">Content-Length</span></code> 与服务器发送的内容不匹配或者分块响应未正确完成。如果 <code class="docutils literal notranslate"><span class="pre">True</span></code>, 这些响应会引发
<code class="docutils literal notranslate"><span class="pre">ResponseFailed([_DataLoss])</span></code> 错误。如果 <code class="docutils literal notranslate"><span class="pre">False</span></code>, 这些响应被传递并且标志 <code class="docutils literal notranslate"><span class="pre">dataloss</span></code> 被添加到响应中，即：
<code class="docutils literal notranslate"><span class="pre">'dataloss'</span> <span class="pre">in</span> <span class="pre">response.flags</span></code> 是 <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>（可选）可以使用
<a class="reference internal" href="request-response.html#std:reqmeta-download_fail_on_dataloss"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_fail_on_dataloss</span></code></a> Request.meta键为每个请求设置 <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>在从服务器配置错误到网络错误再到数据损坏的几种情况下，可能会发生损坏的响应或数据丢失错误。由用户决定处理损坏的响应是否有意义，因为它们可能包含部分或不完整的内容。如果 <a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_ENABLED</span></code></a> 是 <code class="docutils literal notranslate"><span class="pre">True</span></code> 并且此设置设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code>,
<code class="docutils literal notranslate"><span class="pre">ResponseFailed([_DataLoss])</span></code> 则将像往常一样重试。</p>
</div>
</div>
<div class="section" id="dupefilter-class">
<span id="std:setting-DUPEFILTER_CLASS"></span><h3>DUPEFILTER_CLASS<a class="headerlink" href="#dupefilter-class" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.dupefilters.RFPDupeFilter'</span></code></p>
<p>用于检测和过滤重复请求的类。</p>
<p>默认 (<code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code>) 过滤器使用该 <code class="docutils literal notranslate"><span class="pre">scrapy.utils.request.request_fingerprint</span></code> 功能基于请求指纹。为了更改检查重复项的方式，您可以子类化 <code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code> 并覆盖其 <code class="docutils literal notranslate"><span class="pre">request_fingerprint</span></code> 方法。此方法应接受scrapy <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a> o对象并返回其指纹（字符串）。</p>
<p>您可以通过设置
<a class="reference internal" href="#std:setting-DUPEFILTER_CLASS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_CLASS</span></code></a> 为禁用对重复请求的过滤 <code class="docutils literal notranslate"><span class="pre">'scrapy.dupefilters.BaseDupeFilter'</span></code>.
但是要非常小心，因为你可以进入爬行循环。通常最好将 <code class="docutils literal notranslate"><span class="pre">dont_filter</span></code> 参数设置为不应过滤
<code class="docutils literal notranslate"><span class="pre">True</span></code> 的特定参数  <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a> 。</p>
</div>
<div class="section" id="dupefilter-debug">
<span id="std:setting-DUPEFILTER_DEBUG"></span><h3>DUPEFILTER_DEBUG<a class="headerlink" href="#dupefilter-debug" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>默认情况下， <code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code> 仅记录第一个重复请求。设置 <a class="reference internal" href="#std:setting-DUPEFILTER_DEBUG"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_DEBUG</span></code></a> 为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 将使其记录所有重复的请求。</p>
</div>
<div class="section" id="std:setting-EDITOR">
<span id="id11"></span><h3>编辑<a class="headerlink" href="#std:setting-EDITOR" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">vi</span></code> (在 Unix 系统) 或IDLE编辑器（在Windows上）</p>
<p>T用于使用 <a class="reference internal" href="commands.html#std:command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a> 命令编辑蜘蛛的编辑器。此外，如果 <code class="docutils literal notranslate"><span class="pre">EDITOR</span></code> 设置了环境变量，则 <a class="reference internal" href="commands.html#std:command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a>
命令将优先于默认设置。</p>
</div>
<div class="section" id="extensions">
<span id="std:setting-EXTENSIONS"></span><h3>EXTENSIONS<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h3>
<p>默认:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含项目中启用的扩展名及其订单的dict。</p>
</div>
<div class="section" id="extensions-base">
<span id="std:setting-EXTENSIONS_BASE"></span><h3>EXTENSIONS_BASE<a class="headerlink" href="#extensions-base" title="Permalink to this headline">¶</a></h3>
<p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;scrapy.extensions.corestats.CoreStats&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.telnet.TelnetConsole&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.memusage.MemoryUsage&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.memdebug.MemoryDebugger&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.closespider.CloseSpider&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.feedexport.FeedExporter&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.logstats.LogStats&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.spiderstate.SpiderState&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.extensions.throttle.AutoThrottle&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>包含Scrapy中默认可用扩展名的dict及其顺序。此设置包含所有稳定的内置扩展。请记住，其中一些需要通过设置启用。</p>
<p>有关详细信息，请参阅 <a class="reference internal" href="extensions.html#topics-extensions"><span class="std std-ref">extensions user guide</span></a>
和 <a class="reference internal" href="extensions.html#topics-extensions-ref"><span class="std std-ref">list of available extensions</span></a>.</p>
</div>
<div class="section" id="feed-tempdir">
<span id="std:setting-FEED_TEMPDIR"></span><h3>FEED_TEMPDIR<a class="headerlink" href="#feed-tempdir" title="Permalink to this headline">¶</a></h3>
<p>Feed Temp dir允许您在使用 <a class="reference internal" href="feed-exports.html#topics-feed-storage-ftp"><span class="std std-ref">FTP feed storage</span></a> 和
<a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">Amazon S3</span></a> 上载之前设置自定义文件夹以保存搜寻器临时文件。</p>
</div>
<div class="section" id="ftp-passive-mode">
<span id="std:setting-FTP_PASSIVE_MODE"></span><h3>FTP_PASSIVE_MODE<a class="headerlink" href="#ftp-passive-mode" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>在启动FTP传输时是否使用被动模式。</p>
</div>
<div class="section" id="ftp-password">
<span id="std:setting-FTP_PASSWORD"></span><h3>FTP_PASSWORD<a class="headerlink" href="#ftp-password" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">&quot;guest&quot;</span></code></p>
<p>该密码才能使用FTP连接时，有没有 <code class="docutils literal notranslate"><span class="pre">&quot;ftp_password&quot;</span></code>
在 <code class="docutils literal notranslate"><span class="pre">Request</span></code> meta.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>解释 <a class="reference external" href="https://tools.ietf.org/html/rfc1635">RFC 1635</a>, 虽然通常使用密码“guest”或匿名FTP的一个电子邮件地址，但某些FTP服务器明确要求用户的电子邮件地址，并且不允许使用“访客”密码登录。</p>
</div>
</div>
<div class="section" id="ftp-user">
<span id="std:setting-FTP_USER"></span><h3>FTP_USER<a class="headerlink" href="#ftp-user" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">&quot;anonymous&quot;</span></code></p>
<p>用户名使用的FTP连接时，有没有 <code class="docutils literal notranslate"><span class="pre">&quot;ftp_user&quot;</span></code>
在 <code class="docutils literal notranslate"><span class="pre">Request</span></code> meta.</p>
</div>
<div class="section" id="item-pipelines">
<span id="std:setting-ITEM_PIPELINES"></span><h3>ITEM_PIPELINES<a class="headerlink" href="#item-pipelines" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含要使用的项目管道的dict及其命令。订单值是任意的，但通常在0-1000范围内定义它们。在更高订单之前降低订单处理。</p>
<p>例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;mybot.pipelines.validate.ValidateMyItem&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">&#39;mybot.pipelines.validate.StoreMyItem&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="item-pipelines-base">
<span id="std:setting-ITEM_PIPELINES_BASE"></span><h3>ITEM_PIPELINES_BASE<a class="headerlink" href="#item-pipelines-base" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含Scrapy中默认启用的管道的dict。您永远不应该在项目中修改此设置， <a class="reference internal" href="#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">ITEM_PIPELINES</span></code></a> 而是修改。</p>
</div>
<div class="section" id="log-enabled">
<span id="std:setting-LOG_ENABLED"></span><h3>LOG_ENABLED<a class="headerlink" href="#log-enabled" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>是否启用日志记录。</p>
</div>
<div class="section" id="log-encoding">
<span id="std:setting-LOG_ENCODING"></span><h3>LOG_ENCODING<a class="headerlink" href="#log-encoding" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'utf-8'</span></code></p>
<p>用于记录的编码。</p>
</div>
<div class="section" id="log-file">
<span id="std:setting-LOG_FILE"></span><h3>LOG_FILE<a class="headerlink" href="#log-file" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>用于记录输出的文件名。如果``None``, 用于记录输出的文件名。如果</p>
</div>
<div class="section" id="log-format">
<span id="std:setting-LOG_FORMAT"></span><h3>LOG_FORMAT<a class="headerlink" href="#log-format" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'%(asctime)s</span> <span class="pre">[%(name)s]</span> <span class="pre">%(levelname)s:</span> <span class="pre">%(message)s'</span></code></p>
<p>S用于格式化日志消息的字符串。有关可用占位符的完整列表，请参阅 <a class="reference external" href="https://docs.python.org/2/library/logging.html#logrecord-attributes">Python logging documentation</a></p>
</div>
<div class="section" id="log-dateformat">
<span id="std:setting-LOG_DATEFORMAT"></span><h3>LOG_DATEFORMAT<a class="headerlink" href="#log-dateformat" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'%Y-%m-%d</span> <span class="pre">%H:%M:%S'</span></code></p>
<p>用于格式化日期/时间的字符串，用于扩展 <code class="docutils literal notranslate"><span class="pre">%(asctime)s</span></code> 占位符 <a class="reference internal" href="#std:setting-LOG_FORMAT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">LOG_FORMAT</span></code></a>. 有关可用指令的完整列表，请参阅 <a class="reference external" href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior">Python datetime documentation</a></p>
</div>
<div class="section" id="log-level">
<span id="std:setting-LOG_LEVEL"></span><h3>LOG_LEVEL<a class="headerlink" href="#log-level" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'DEBUG'</span></code></p>
<p>记录的最低级别。可用级别包括：CRITICAL，ERROR，WARNING，INFO，DEBUG。有关更多信息，请参阅 <a class="reference internal" href="logging.html#topics-logging"><span class="std std-ref">Logging</span></a>.</p>
</div>
<div class="section" id="log-stdout">
<span id="std:setting-LOG_STDOUT"></span><h3>LOG_STDOUT<a class="headerlink" href="#log-stdout" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>如果 <code class="docutils literal notranslate"><span class="pre">True</span></code>, 记录的最低级别。可用级别包括：CRITICAL，ERROR，WARNING，INFO，DEBUG。有关更多信息，请参阅 <code class="docutils literal notranslate"><span class="pre">print('hello')</span></code> 它将出现在Scrapy日志中。</p>
</div>
<div class="section" id="log-short-names">
<span id="std:setting-LOG_SHORT_NAMES"></span><h3>LOG_SHORT_NAMES<a class="headerlink" href="#log-short-names" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>如果 <code class="docutils literal notranslate"><span class="pre">True</span></code>, 日志将只包含根路径。如果设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code>
日志将只包含根路径。如果设置为</p>
</div>
<div class="section" id="memdebug-enabled">
<span id="std:setting-MEMDEBUG_ENABLED"></span><h3>MEMDEBUG_ENABLED<a class="headerlink" href="#memdebug-enabled" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>是否启用内存调试。</p>
</div>
<div class="section" id="memdebug-notify">
<span id="std:setting-MEMDEBUG_NOTIFY"></span><h3>MEMDEBUG_NOTIFY<a class="headerlink" href="#memdebug-notify" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">[]</span></code></p>
<p>启用内存调试时，如果此设置不为空，则会将内存报告发送到指定的地址，否则报告将写入日志。</p>
<p>例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MEMDEBUG_NOTIFY</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;user@example.com&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="memusage-enabled">
<span id="std:setting-MEMUSAGE_ENABLED"></span><h3>MEMUSAGE_ENABLED<a class="headerlink" href="#memusage-enabled" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>是否启用内存使用扩展。此扩展程序跟踪进程使用的峰值内存（将其写入统计信息）。它还可以选择在超出内存限制时关闭Scrapy进程（请参阅参考资料 <a class="reference internal" href="#std:setting-MEMUSAGE_LIMIT_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_LIMIT_MB</span></code></a>), 并在发生时通过电子邮件通知（请参阅参考资料 <a class="reference internal" href="#std:setting-MEMUSAGE_NOTIFY_MAIL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_NOTIFY_MAIL</span></code></a>).</p>
<p>请参阅 <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展</span></a>.</p>
</div>
<div class="section" id="memusage-limit-mb">
<span id="std:setting-MEMUSAGE_LIMIT_MB"></span><h3>MEMUSAGE_LIMIT_MB<a class="headerlink" href="#memusage-limit-mb" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>关闭Scrapy之前允许的最大内存量（以兆字节为单位）（如果MEMUSAGE_ENABLED为True）。如果为零，则不执行检查。</p>
<p>请参阅 <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展</span></a>.</p>
</div>
<div class="section" id="memusage-check-interval-seconds">
<span id="std:setting-MEMUSAGE_CHECK_INTERVAL_SECONDS"></span><h3>MEMUSAGE_CHECK_INTERVAL_SECONDS<a class="headerlink" href="#memusage-check-interval-seconds" title="Permalink to this headline">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.</span></p>
</div>
<p>默认: <code class="docutils literal notranslate"><span class="pre">60.0</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p><a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>
会检查当前存储器使用，相对于限制由设置
<a class="reference internal" href="#std:setting-MEMUSAGE_LIMIT_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_LIMIT_MB</span></code></a> 和 <a class="reference internal" href="#std:setting-MEMUSAGE_WARNING_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_WARNING_MB</span></code></a>,
会检查当前存储器使用，相对于限制由设置</p>
<p>这将设置这些间隔的长度，以秒为单位。</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展</span></a>.</p>
</div>
<div class="section" id="memusage-notify-mail">
<span id="std:setting-MEMUSAGE_NOTIFY_MAIL"></span><h3>MEMUSAGE_NOTIFY_MAIL<a class="headerlink" href="#memusage-notify-mail" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>如果已达到内存限制，则通知的电子邮件列表。</p>
<p>例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MEMUSAGE_NOTIFY_MAIL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;user@example.com&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>请参阅 <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展</span></a>.</p>
</div>
<div class="section" id="memusage-warning-mb">
<span id="std:setting-MEMUSAGE_WARNING_MB"></span><h3>MEMUSAGE_WARNING_MB<a class="headerlink" href="#memusage-warning-mb" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>发送警告电子邮件通知之前允许的最大内存量（以兆字节为单位）。如果为零，则不会产生警告。</p>
</div>
<div class="section" id="newspider-module">
<span id="std:setting-NEWSPIDER_MODULE"></span><h3>NEWSPIDER_MODULE<a class="headerlink" href="#newspider-module" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">''</span></code></p>
<p>使用该 <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a> 命令模块在哪里创建新的爬虫。</p>
<p>例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s1">&#39;mybot.spiders_dev&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="randomize-download-delay">
<span id="std:setting-RANDOMIZE_DOWNLOAD_DELAY"></span><h3>RANDOMIZE_DOWNLOAD_DELAY<a class="headerlink" href="#randomize-download-delay" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>如果启用，Scrapy将在从同一网站获取请求时等待一段随机时间（介于0.5* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> 和1.5* 之间 <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a>)</p>
<p>这种随机化降低了爬行程序被分析请求的站点检测（并随后被阻止）的机会，这些站点在其请求之间的时间内寻找统计上显着的相似性。</p>
<p>随机化策略与 by <a class="reference external" href="https://www.gnu.org/software/wget/manual/wget.html">wget</a> <code class="docutils literal notranslate"><span class="pre">--random-wait</span></code> 选项使用的相同。</p>
<p>如果 <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> 为零（默认），则此选项无效。</p>
</div>
<div class="section" id="reactor-threadpool-maxsize">
<span id="std:setting-REACTOR_THREADPOOL_MAXSIZE"></span><h3>REACTOR_THREADPOOL_MAXSIZE<a class="headerlink" href="#reactor-threadpool-maxsize" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">10</span></code></p>
<p>Twisted Reactor线程池大小的最大限制。这是各种Scrapy组件使用的常见多用途线程池。螺纹DNS解析器，BlockingFeedStorage，S3FilesStore仅举几例。如果遇到阻塞IO不足的问题，请增加此值。</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h3>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">20</span></code></p>
<p>定义可以重定向请求的最大次数。在此最大值之后，请求的响应将按原样返回。我们使用Firefox默认值来执行相同的任务。</p>
</div>
<div class="section" id="redirect-priority-adjust">
<span id="std:setting-REDIRECT_PRIORITY_ADJUST"></span><h3>REDIRECT_PRIORITY_ADJUST<a class="headerlink" href="#redirect-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">+2</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.redirect.RedirectMiddleware</span></code></p>
<p>相对于原始请求调整重定向请求优先级：</p>
<ul class="simple">
<li><p><strong>正优先级调整（默认）意味着更高的优先级</strong></p></li>
<li><p>负优先级调整意味着较低的优先级。</p></li>
</ul>
</div>
<div class="section" id="retry-priority-adjust">
<span id="std:setting-RETRY_PRIORITY_ADJUST"></span><h3>RETRY_PRIORITY_ADJUST<a class="headerlink" href="#retry-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">-1</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.retry.RetryMiddleware</span></code></p>
<p>相对于原始请求调整重试请求优先级：</p>
<ul class="simple">
<li><p>正优先级调整意味着更高的优先级。</p></li>
<li><p><strong>负优先级调整（默认）表示优先级较低。</strong></p></li>
</ul>
</div>
<div class="section" id="robotstxt-obey">
<span id="std:setting-ROBOTSTXT_OBEY"></span><h3>ROBOTSTXT_OBEY<a class="headerlink" href="#robotstxt-obey" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.robotstxt</span></code></p>
<p>如果启用，Scrapy将尊重robots.txt政策。有关更多信息，请参阅
<a class="reference internal" href="downloader-middleware.html#topics-dlmw-robots"><span class="std std-ref">RobotsTxtMiddleware</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>虽然默认值是 <code class="docutils literal notranslate"><span class="pre">False</span></code> 于历史原因，但默认情况下会在命令生成的settings.py文件中启用此选项。 <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span></code> 命令。</p>
</div>
</div>
<div class="section" id="scheduler">
<span id="std:setting-SCHEDULER"></span><h3>SCHEDULER<a class="headerlink" href="#scheduler" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.scheduler.Scheduler'</span></code></p>
<p>用于爬网的调度程序。</p>
</div>
<div class="section" id="scheduler-debug">
<span id="std:setting-SCHEDULER_DEBUG"></span><h3>SCHEDULER_DEBUG<a class="headerlink" href="#scheduler-debug" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 将记录有关请求调度程序的调试信息。如果请求无法序列化到磁盘，则此当前日志（仅一次）。Stats counter (<code class="docutils literal notranslate"><span class="pre">scheduler/unserializable</span></code>) 跟踪发生这种情况的次数。</p>
<p>日志中的示例条目:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mi">1956</span><span class="o">-</span><span class="mo">01</span><span class="o">-</span><span class="mi">31</span> <span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="o">+</span><span class="mi">0800</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scheduler</span><span class="p">]</span> <span class="n">ERROR</span><span class="p">:</span> <span class="n">Unable</span> <span class="n">to</span> <span class="n">serialize</span> <span class="n">request</span><span class="p">:</span>
<span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">example</span><span class="o">.</span><span class="n">com</span><span class="o">&gt;</span> <span class="o">-</span> <span class="n">reason</span><span class="p">:</span> <span class="n">cannot</span> <span class="n">serialize</span> <span class="o">&lt;</span><span class="n">Request</span> <span class="n">at</span> <span class="mh">0x9a7c7ec</span><span class="o">&gt;</span>
<span class="p">(</span><span class="nb">type</span> <span class="n">Request</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">-</span> <span class="n">no</span> <span class="n">more</span> <span class="n">unserializable</span> <span class="n">requests</span> <span class="n">will</span> <span class="n">be</span> <span class="n">logged</span>
<span class="p">(</span><span class="n">see</span> <span class="s1">&#39;scheduler/unserializable&#39;</span> <span class="n">stats</span> <span class="n">counter</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="scheduler-disk-queue">
<span id="std:setting-SCHEDULER_DISK_QUEUE"></span><h3>SCHEDULER_DISK_QUEUE<a class="headerlink" href="#scheduler-disk-queue" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.squeues.PickleLifoDiskQueue'</span></code></p>
<p>调度程序将使用的磁盘队列类型。其他可用的类型有
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.PickleFifoDiskQueue</span></code>, <code class="docutils literal notranslate"><span class="pre">scrapy.squeues.MarshalFifoDiskQueue</span></code>,
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.MarshalLifoDiskQueue</span></code>.</p>
</div>
<div class="section" id="scheduler-memory-queue">
<span id="std:setting-SCHEDULER_MEMORY_QUEUE"></span><h3>SCHEDULER_MEMORY_QUEUE<a class="headerlink" href="#scheduler-memory-queue" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.squeues.LifoMemoryQueue'</span></code></p>
<p>调度程序使用的内存中队列的类型。其他可用的类型是:
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.FifoMemoryQueue</span></code>.</p>
</div>
<div class="section" id="scheduler-priority-queue">
<span id="std:setting-SCHEDULER_PRIORITY_QUEUE"></span><h3>SCHEDULER_PRIORITY_QUEUE<a class="headerlink" href="#scheduler-priority-queue" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">'queuelib.PriorityQueue'</span></code></p>
<p>调度程序使用的优先级队列的类型。</p>
</div>
<div class="section" id="spider-contracts">
<span id="std:setting-SPIDER_CONTRACTS"></span><h3>SPIDER_CONTRACTS<a class="headerlink" href="#spider-contracts" title="Permalink to this headline">¶</a></h3>
<p>默认:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>包含项目中启用的蜘蛛合同的dict，用于测试蜘蛛。有关更多信息，请参阅 <a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>.</p>
</div>
<div class="section" id="spider-contracts-base">
<span id="std:setting-SPIDER_CONTRACTS_BASE"></span><h3>SPIDER_CONTRACTS_BASE<a class="headerlink" href="#spider-contracts-base" title="Permalink to this headline">¶</a></h3>
<p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;scrapy.contracts.default.UrlContract&#39;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.contracts.default.ReturnsContract&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.contracts.default.ScrapesContract&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>包含scrapy默认情况下启用的scrapy合约的dict。您永远不应该在项目中修改此设置 <a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_CONTRACTS</span></code></a>
而是修改。有关更多信息，请参阅 <a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>.</p>
<p>您可以通过分配 <code class="docutils literal notranslate"><span class="pre">None</span></code> 其类路径来禁用任何这些合同 <a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_CONTRACTS</span></code></a>. 例如，要禁用内置功能
<code class="docutils literal notranslate"><span class="pre">ScrapesContract</span></code>, 请将其放入 <code class="docutils literal notranslate"><span class="pre">settings.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_CONTRACTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;scrapy.contracts.default.ScrapesContract&#39;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="spider-loader-class">
<span id="std:setting-SPIDER_LOADER_CLASS"></span><h3>SPIDER_LOADER_CLASS<a class="headerlink" href="#spider-loader-class" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.spiderloader.SpiderLoader'</span></code></p>
</div></blockquote>
<p>将用于加载蜘蛛的类，必须实现
<a class="reference internal" href="api.html#topics-api-spiderloader"><span class="std std-ref">SpiderLoader API</span></a>.</p>
</div>
<div class="section" id="spider-loader-warn-only">
<span id="std:setting-SPIDER_LOADER_WARN_ONLY"></span><h3>SPIDER_LOADER_WARN_ONLY<a class="headerlink" href="#spider-loader-warn-only" title="Permalink to this headline">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.3.</span></p>
</div>
<p>默认: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>默认情况下，当scrapy尝试从中导入蜘蛛类时 <a class="reference internal" href="#std:setting-SPIDER_MODULES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MODULES</span></code></a>,
如果有任何 <code class="docutils literal notranslate"><span class="pre">ImportError</span></code> 异常，它将大声失败。但您可以选择将此异常静音并通过设置将其转换为简单警告。 <code class="docutils literal notranslate"><span class="pre">SPIDER_LOADER_WARN_ONLY</span> <span class="pre">=</span> <span class="pre">True</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>有些 <a class="reference internal" href="commands.html#topics-commands"><span class="std std-ref">scrapy commands</span></a> 命令已经使用此设置运行为true（即它们只发出警告，不会失败），因为它们实际上不需要加载spider类来工作：</p>
<p><a class="reference internal" href="commands.html#std:command-runspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">runspider</span></code></a>,
<a class="reference internal" href="commands.html#std:command-settings"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">settings</span></code></a>,
<a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span></code></a>,
<a class="reference internal" href="commands.html#std:command-version"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span></code></a>.</p>
</div>
</div>
<div class="section" id="spider-middlewares">
<span id="std:setting-SPIDER_MIDDLEWARES"></span><h3>SPIDER_MIDDLEWARES<a class="headerlink" href="#spider-middlewares" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>默认:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
</div></blockquote>
<p>包含项目中启用的蜘蛛中间件及其命令的dict。有关更多信息，请参阅 <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-middlewares-base">
<span id="std:setting-SPIDER_MIDDLEWARES_BASE"></span><h3>SPIDER_MIDDLEWARES_BASE<a class="headerlink" href="#spider-middlewares-base" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>默认:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>包含Scrapy中默认启用的蜘蛛中间件及其命令的dict。低订单更接近引擎，高订单更接近蜘蛛。有关更多信息，请参阅 <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-modules">
<span id="std:setting-SPIDER_MODULES"></span><h3>SPIDER_MODULES<a class="headerlink" href="#spider-modules" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>默认: <code class="docutils literal notranslate"><span class="pre">[]</span></code></p>
</div></blockquote>
<p>Scrapy将寻找蜘蛛的模块列表。</p>
<p>例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mybot.spiders_prod&#39;</span><span class="p">,</span> <span class="s1">&#39;mybot.spiders_dev&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="stats-class">
<span id="std:setting-STATS_CLASS"></span><h3>STATS_CLASS<a class="headerlink" href="#stats-class" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>默认: <code class="docutils literal notranslate"><span class="pre">'scrapy.statscollectors.MemoryStatsCollector'</span></code></p>
</div></blockquote>
<p>用于收集统计信息的类，必须实现
<a class="reference internal" href="api.html#topics-api-stats"><span class="std std-ref">Stats Collector API</span></a>.</p>
</div>
<div class="section" id="stats-dump">
<span id="std:setting-STATS_DUMP"></span><h3>STATS_DUMP<a class="headerlink" href="#stats-dump" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>蜘蛛完成后，将 <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">Scrapy stats</span></a> （转到Scrapy日志）转储。</p>
<p>有关详细信息，请参阅: <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">统计收集</span></a>.</p>
</div>
<div class="section" id="statsmailer-rcpts">
<span id="std:setting-STATSMAILER_RCPTS"></span><h3>STATSMAILER_RCPTS<a class="headerlink" href="#statsmailer-rcpts" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">[]</span></code> (空列表)</p>
<p>在蜘蛛完成爬取后发送Scrapy统计数据。有关详情请参阅
<code class="xref py py-class docutils literal notranslate"><span class="pre">StatsMailer</span></code></p>
</div>
<div class="section" id="telnetconsole-enabled">
<span id="std:setting-TELNETCONSOLE_ENABLED"></span><h3>TELNETCONSOLE_ENABLED<a class="headerlink" href="#telnetconsole-enabled" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>一个布尔值，指定是否 启用 <a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">telnet console</span></a>
（如果其扩展名也已启用）</p>
</div>
<div class="section" id="telnetconsole-port">
<span id="std:setting-TELNETCONSOLE_PORT"></span><h3>TELNETCONSOLE_PORT<a class="headerlink" href="#telnetconsole-port" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">[6023,</span> <span class="pre">6073]</span></code></p>
<p>用于telnet控制台的端口范围。如果设置为 <code class="docutils literal notranslate"><span class="pre">None</span></code> or <code class="docutils literal notranslate"><span class="pre">0</span></code>, 则使用动态分配的端口。有关详细信息，请参阅
<a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet 控制台</span></a>.</p>
</div>
<div class="section" id="templates-dir">
<span id="std:setting-TEMPLATES_DIR"></span><h3>TEMPLATES_DIR<a class="headerlink" href="#templates-dir" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">templates</span></code> dir inside scrapy module</p>
<p>使用
<a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a> 命令创建新项目时使用命令查找模板的目录以及使用命令创建新爬虫的目录 <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a>
的命令。</p>
<p>项目名称不得与 <code class="docutils literal notranslate"><span class="pre">project</span></code> 子目录中的自定义文件或目录的名称冲突。</p>
</div>
<div class="section" id="urllength-limit">
<span id="std:setting-URLLENGTH_LIMIT"></span><h3>URLLENGTH_LIMIT<a class="headerlink" href="#urllength-limit" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">2083</span></code></p>
<p>范围: <code class="docutils literal notranslate"><span class="pre">spidermiddlewares.urllength</span></code></p>
<p>允许抓取的网址的最大网址长度。有关此设置的默认值的详细信息，请参阅: <a class="reference external" href="https://boutell.com/newfaq/misc/urllength.html">https://boutell.com/newfaq/misc/urllength.html</a></p>
</div>
<div class="section" id="user-agent">
<span id="std:setting-USER_AGENT"></span><h3>USER_AGENT<a class="headerlink" href="#user-agent" title="Permalink to this headline">¶</a></h3>
<p>默认: <code class="docutils literal notranslate"><span class="pre">&quot;Scrapy/VERSION</span> <span class="pre">(+https://scrapy.org)&quot;</span></code></p>
<p>爬网时使用的默认User-Agent，除非被覆盖。</p>
</div>
<div class="section" id="id12">
<h3>其他地方记录的设置:<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>以下设置记录在别处，请检查每个特定情况以了解如何启用和使用它们。</p>
<ul class="simple">
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-AJAXCRAWL_ENABLED">AJAXCRAWL_ENABLED</a></p></li>
<li><p><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_DEBUG">AUTOTHROTTLE_DEBUG</a></p></li>
<li><p><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED">AUTOTHROTTLE_ENABLED</a></p></li>
<li><p><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_MAX_DELAY">AUTOTHROTTLE_MAX_DELAY</a></p></li>
<li><p><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_START_DELAY">AUTOTHROTTLE_START_DELAY</a></p></li>
<li><p><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY">AUTOTHROTTLE_TARGET_CONCURRENCY</a></p></li>
<li><p><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT">CLOSESPIDER_ERRORCOUNT</a></p></li>
<li><p><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT">CLOSESPIDER_ITEMCOUNT</a></p></li>
<li><p><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_PAGECOUNT">CLOSESPIDER_PAGECOUNT</a></p></li>
<li><p><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_TIMEOUT">CLOSESPIDER_TIMEOUT</a></p></li>
<li><p><a class="reference internal" href="commands.html#std:setting-COMMANDS_MODULE">COMMANDS_MODULE</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-COMPRESSION_ENABLED">COMPRESSION_ENABLED</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-COOKIES_DEBUG">COOKIES_DEBUG</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-COOKIES_ENABLED">COOKIES_ENABLED</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORTERS">FEED_EXPORTERS</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORTERS_BASE">FEED_EXPORTERS_BASE</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_ENCODING">FEED_EXPORT_ENCODING</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_FIELDS">FEED_EXPORT_FIELDS</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_INDENT">FEED_EXPORT_INDENT</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_FORMAT">FEED_FORMAT</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORAGES">FEED_STORAGES</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORAGES_BASE">FEED_STORAGES_BASE</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORE_EMPTY">FEED_STORE_EMPTY</a></p></li>
<li><p><a class="reference internal" href="feed-exports.html#std:setting-FEED_URI">FEED_URI</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_EXPIRES">FILES_EXPIRES</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_RESULT_FIELD">FILES_RESULT_FIELD</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE">FILES_STORE</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE_GCS_ACL">FILES_STORE_GCS_ACL</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE_S3_ACL">FILES_STORE_S3_ACL</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-FILES_URLS_FIELD">FILES_URLS_FIELD</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-GCS_PROJECT_ID">GCS_PROJECT_ID</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_ALWAYS_STORE">HTTPCACHE_ALWAYS_STORE</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_DBM_MODULE">HTTPCACHE_DBM_MODULE</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_DIR">HTTPCACHE_DIR</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_ENABLED">HTTPCACHE_ENABLED</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_EXPIRATION_SECS">HTTPCACHE_EXPIRATION_SECS</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_GZIP">HTTPCACHE_GZIP</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_HTTP_CODES">HTTPCACHE_IGNORE_HTTP_CODES</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_MISSING">HTTPCACHE_IGNORE_MISSING</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS">HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_SCHEMES">HTTPCACHE_IGNORE_SCHEMES</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_POLICY">HTTPCACHE_POLICY</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_STORAGE">HTTPCACHE_STORAGE</a></p></li>
<li><p><a class="reference internal" href="spider-middleware.html#std:setting-HTTPERROR_ALLOWED_CODES">HTTPERROR_ALLOWED_CODES</a></p></li>
<li><p><a class="reference internal" href="spider-middleware.html#std:setting-HTTPERROR_ALLOW_ALL">HTTPERROR_ALLOW_ALL</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPPROXY_AUTH_ENCODING">HTTPPROXY_AUTH_ENCODING</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPPROXY_ENABLED">HTTPPROXY_ENABLED</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_EXPIRES">IMAGES_EXPIRES</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_MIN_HEIGHT">IMAGES_MIN_HEIGHT</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_MIN_WIDTH">IMAGES_MIN_WIDTH</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_RESULT_FIELD">IMAGES_RESULT_FIELD</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE">IMAGES_STORE</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE_GCS_ACL">IMAGES_STORE_GCS_ACL</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE_S3_ACL">IMAGES_STORE_S3_ACL</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_THUMBS">IMAGES_THUMBS</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_URLS_FIELD">IMAGES_URLS_FIELD</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_FROM">MAIL_FROM</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_HOST">MAIL_HOST</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_PASS">MAIL_PASS</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_PORT">MAIL_PORT</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_SSL">MAIL_SSL</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_TLS">MAIL_TLS</a></p></li>
<li><p><a class="reference internal" href="email.html#std:setting-MAIL_USER">MAIL_USER</a></p></li>
<li><p><a class="reference internal" href="media-pipeline.html#std:setting-MEDIA_ALLOW_REDIRECTS">MEDIA_ALLOW_REDIRECTS</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-METAREFRESH_ENABLED">METAREFRESH_ENABLED</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-METAREFRESH_MAXDELAY">METAREFRESH_MAXDELAY</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-REDIRECT_ENABLED">REDIRECT_ENABLED</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-REDIRECT_MAX_TIMES">REDIRECT_MAX_TIMES</a></p></li>
<li><p><a class="reference internal" href="spider-middleware.html#std:setting-REFERER_ENABLED">REFERER_ENABLED</a></p></li>
<li><p><a class="reference internal" href="spider-middleware.html#std:setting-REFERRER_POLICY">REFERRER_POLICY</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_ENABLED">RETRY_ENABLED</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_HTTP_CODES">RETRY_HTTP_CODES</a></p></li>
<li><p><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_TIMES">RETRY_TIMES</a></p></li>
<li><p><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_HOST">TELNETCONSOLE_HOST</a></p></li>
<li><p><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_PASSWORD">TELNETCONSOLE_PASSWORD</a></p></li>
<li><p><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_PORT">TELNETCONSOLE_PORT</a></p></li>
<li><p><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_USERNAME">TELNETCONSOLE_USERNAME</a></p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="exceptions.html" class="btn btn-neutral float-right" title="例外" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="link-extractors.html" class="btn btn-neutral float-left" title="链接提取器" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008–2018, Scrapy developers
      <span class="lastupdated">
        Last updated on Feb 27, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>


</body>
</html>