

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spider Middleware &mdash; Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="扩展" href="extensions.html" />
    <link rel="prev" title="Downloader Middleware" href="downloader-middleware.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
              <div class="version">
                1.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy 一目了然</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">示例</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">命令行工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">爬虫（Spiders）</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item 装载器</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline（项目管道）</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed 导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">请求与响应</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">链接提取器</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">设置</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">例外</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">统计收集</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">发送电子邮件</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet 控制台</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web 服务</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="media-pipeline.html">下载和处理文件与图像</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle 扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spider Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#activating-a-spider-middleware">Activating a spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#writing-your-own-spider-middleware">Writing your own spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-spider-middleware-reference">Built-in spider middleware reference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-scrapy.spidermiddlewares.depth">DepthMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-scrapy.spidermiddlewares.httperror">HttpErrorMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#httperrormiddleware-settings">HttpErrorMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-scrapy.spidermiddlewares.offsite">OffsiteMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-scrapy.spidermiddlewares.referer">RefererMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#referermiddleware-settings">RefererMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-scrapy.spidermiddlewares.urllength">UrlLengthMiddleware</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">信号(Signals)</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Spider Middleware</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/topics/spider-middleware.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spider-middleware">
<span id="topics-spider-middleware"></span><h1>Spider Middleware<a class="headerlink" href="#spider-middleware" title="Permalink to this headline">¶</a></h1>
<p>The spider middleware is a framework of hooks into Scrapy’s spider processing
mechanism where you can plug custom functionality to process the responses that
are sent to <a class="reference internal" href="spiders.html#topics-spiders"><span class="std std-ref">爬虫（Spiders）</span></a> for processing and to process the requests
and items that are generated from spiders.</p>
<div class="section" id="activating-a-spider-middleware">
<span id="topics-spider-middleware-setting"></span><h2>Activating a spider middleware<a class="headerlink" href="#activating-a-spider-middleware" title="Permalink to this headline">¶</a></h2>
<p>To activate a spider middleware component, add it to the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES</span></code></a> setting, which is a dict whose keys are the
middleware class path and their values are the middleware orders.</p>
<p>Here’s an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;myproject.middlewares.CustomSpiderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES</span></code></a> setting is merged with the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></code></a> setting defined in Scrapy (and not meant to
be overridden) and then sorted by order to get the final sorted list of enabled
middlewares: the first middleware is the one closer to the engine and the last
is the one closer to the spider. In other words,
the <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_input()</span></code></a>
method of each middleware will be invoked in increasing
middleware order (100, 200, 300, …), and the
<a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_output()</span></code></a> method
of each middleware will be invoked in decreasing order.</p>
<p>To decide which order to assign to your middleware see the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></code></a> setting and pick a value according to where
you want to insert the middleware. The order does matter because each
middleware performs a different action and your middleware could depend on some
previous (or subsequent) middleware being applied.</p>
<p>If you want to disable a builtin middleware (the ones defined in
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></code></a>, and enabled by default) you must define it
in your project <a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES</span></code></a> setting and assign <cite>None</cite> as its
value.  For example, if you want to disable the off-site middleware:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;myproject.middlewares.CustomSpiderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
    <span class="s1">&#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, keep in mind that some middlewares may need to be enabled through a
particular setting. See each middleware documentation for more info.</p>
</div>
<div class="section" id="writing-your-own-spider-middleware">
<h2>Writing your own spider middleware<a class="headerlink" href="#writing-your-own-spider-middleware" title="Permalink to this headline">¶</a></h2>
<p>Each middleware component is a Python class that defines one or more of the
following methods:</p>
<span class="target" id="module-scrapy.spidermiddlewares"></span><dl class="class">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.</code><code class="sig-name descname">SpiderMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input">
<code class="sig-name descname">process_spider_input</code><span class="sig-paren">(</span><em class="sig-param">response</em>, <em class="sig-param">spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called for each response that goes through the spider
middleware and into the spider, for processing.</p>
<p><a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_input()</span></code></a> should return <code class="docutils literal notranslate"><span class="pre">None</span></code> or raise an
exception.</p>
<p>If it returns <code class="docutils literal notranslate"><span class="pre">None</span></code>, Scrapy will continue processing this response,
executing all other middlewares until, finally, the response is handed
to the spider for processing.</p>
<p>If it raises an exception, Scrapy won’t bother calling any other spider
middleware <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_input()</span></code></a> and will call the request
errback.  The output of the errback is chained back in the other
direction for <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_output()</span></code></a> to process it, or
<a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_exception()</span></code></a> if it raised an exception.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code></a> object) – the response being processed</p></li>
<li><p><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">Spider</span></code></a> object) – the spider for which this response is intended</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output">
<code class="sig-name descname">process_spider_output</code><span class="sig-paren">(</span><em class="sig-param">response</em>, <em class="sig-param">result</em>, <em class="sig-param">spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called with the results returned from the Spider, after
it has processed the response.</p>
<p><a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_output()</span></code></a> must return an iterable of
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>, dict or <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code></a>
objects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code></a> object) – the response which generated this output from the
spider</p></li>
<li><p><strong>result</strong> (an iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>, dict
or <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code></a> objects) – the result returned by the spider</p></li>
<li><p><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">Spider</span></code></a> object) – the spider whose result is being processed</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception">
<code class="sig-name descname">process_spider_exception</code><span class="sig-paren">(</span><em class="sig-param">response</em>, <em class="sig-param">exception</em>, <em class="sig-param">spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is called when a spider or <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_input()</span></code></a>
method (from other spider middleware) raises an exception.</p>
<p><a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_exception()</span></code></a> should return either <code class="docutils literal notranslate"><span class="pre">None</span></code> or an
iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>, dict or
<a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal notranslate"><span class="pre">Item</span></code></a> objects.</p>
<p>If it returns <code class="docutils literal notranslate"><span class="pre">None</span></code>, Scrapy will continue processing this exception,
executing any other <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_exception()</span></code></a> in the following
middleware components, until no middleware components are left and the
exception reaches the engine (where it’s logged and discarded).</p>
<p>If it returns an iterable the <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_output()</span></code></a> pipeline
kicks in, and no other <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_exception"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_exception()</span></code></a> will be called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code></a> object) – the response being processed when the exception was
raised</p></li>
<li><p><strong>exception</strong> (<a class="reference external" href="https://docs.python.org/2/library/exceptions.html#exceptions.Exception">Exception</a> object) – the exception raised</p></li>
<li><p><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">Spider</span></code></a> object) – the spider which raised the exception</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware.process_start_requests">
<code class="sig-name descname">process_start_requests</code><span class="sig-paren">(</span><em class="sig-param">start_requests</em>, <em class="sig-param">spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_start_requests" title="Permalink to this definition">¶</a></dt>
<dd><div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<p>This method is called with the start requests of the spider, and works
similarly to the <a class="reference internal" href="#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output" title="scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">process_spider_output()</span></code></a> method, except that it
doesn’t have a response associated and must return only requests (not
items).</p>
<p>It receives an iterable (in the <code class="docutils literal notranslate"><span class="pre">start_requests</span></code> parameter) and must
return another iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a> objects.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When implementing this method in your spider middleware, you
should always return an iterable (that follows the input one) and
not consume all <code class="docutils literal notranslate"><span class="pre">start_requests</span></code> iterator because it can be very
large (or even unbounded) and cause a memory overflow. The Scrapy
engine is designed to pull start requests while it has capacity to
process them, so the start requests iterator can be effectively
endless where there is some other condition for stopping the spider
(like a time limit or item/page count).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start_requests</strong> (an iterable of <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>) – the start requests</p></li>
<li><p><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">Spider</span></code></a> object) – the spider to whom the start requests belong</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermiddlewares.SpiderMiddleware.from_crawler">
<code class="sig-name descname">from_crawler</code><span class="sig-paren">(</span><em class="sig-param">cls</em>, <em class="sig-param">crawler</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermiddlewares.SpiderMiddleware.from_crawler" title="Permalink to this definition">¶</a></dt>
<dd><p>If present, this classmethod is called to create a middleware instance
from a <a class="reference internal" href="api.html#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal notranslate"><span class="pre">Crawler</span></code></a>. It must return a new instance
of the middleware. Crawler object provides access to all Scrapy core
components like settings and signals; it is a way for middleware to
access them and hook its functionality into Scrapy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>crawler</strong> (<a class="reference internal" href="api.html#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal notranslate"><span class="pre">Crawler</span></code></a> object) – crawler that uses this middleware</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="built-in-spider-middleware-reference">
<span id="topics-spider-middleware-ref"></span><h2>Built-in spider middleware reference<a class="headerlink" href="#built-in-spider-middleware-reference" title="Permalink to this headline">¶</a></h2>
<p>This page describes all spider middleware components that come with Scrapy. For
information on how to use them and how to write your own spider middleware, see
the <a class="reference internal" href="#topics-spider-middleware"><span class="std std-ref">spider middleware usage guide</span></a>.</p>
<p>For a list of the components enabled by default (and their orders) see the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MIDDLEWARES_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MIDDLEWARES_BASE</span></code></a> setting.</p>
<div class="section" id="module-scrapy.spidermiddlewares.depth">
<span id="depthmiddleware"></span><h3>DepthMiddleware<a class="headerlink" href="#module-scrapy.spidermiddlewares.depth" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spidermiddlewares.depth.DepthMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.depth.</code><code class="sig-name descname">DepthMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.depth.DepthMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>DepthMiddleware is used for tracking the depth of each Request inside the
site being scraped. It works by setting <cite>request.meta[‘depth’] = 0</cite> whenever
there is no value previously set (usually just the first Request) and
incrementing it by 1 otherwise.</p>
<p>It can be used to limit the maximum depth to scrape, control Request
priority based on their depth, and things like that.</p>
<p>The <a class="reference internal" href="#scrapy.spidermiddlewares.depth.DepthMiddleware" title="scrapy.spidermiddlewares.depth.DepthMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">DepthMiddleware</span></code></a> can be configured through the following
settings (see the settings documentation for more info):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="settings.html#std:setting-DEPTH_LIMIT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DEPTH_LIMIT</span></code></a> - The maximum depth that will be allowed to
crawl for any site. If zero, no limit will be imposed.</p></li>
<li><p><a class="reference internal" href="settings.html#std:setting-DEPTH_STATS_VERBOSE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DEPTH_STATS_VERBOSE</span></code></a> - Whether to collect the number of
requests for each depth.</p></li>
<li><p><a class="reference internal" href="settings.html#std:setting-DEPTH_PRIORITY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DEPTH_PRIORITY</span></code></a> - Whether to prioritize the requests based on
their depth.</p></li>
</ul>
</div></blockquote>
</dd></dl>

</div>
<div class="section" id="module-scrapy.spidermiddlewares.httperror">
<span id="httperrormiddleware"></span><h3>HttpErrorMiddleware<a class="headerlink" href="#module-scrapy.spidermiddlewares.httperror" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spidermiddlewares.httperror.HttpErrorMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.httperror.</code><code class="sig-name descname">HttpErrorMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.httperror.HttpErrorMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter out unsuccessful (erroneous) HTTP responses so that spiders don’t
have to deal with them, which (most of the time) imposes an overhead,
consumes more resources, and makes the spider logic more complex.</p>
</dd></dl>

<p>According to the <a class="reference external" href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP standard</a>, successful responses are those whose
status codes are in the 200-300 range.</p>
<p>If you still want to process response codes outside that range, you can
specify which response codes the spider is able to handle using the
<code class="docutils literal notranslate"><span class="pre">handle_httpstatus_list</span></code> spider attribute or
<a class="reference internal" href="#std:setting-HTTPERROR_ALLOWED_CODES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">HTTPERROR_ALLOWED_CODES</span></code></a> setting.</p>
<p>For example, if you want your spider to handle 404 responses you can do
this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">handle_httpstatus_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">404</span><span class="p">]</span>
</pre></div>
</div>
<span class="target" id="std:reqmeta-handle_httpstatus_list"></span><p id="std:reqmeta-handle_httpstatus_all">The <code class="docutils literal notranslate"><span class="pre">handle_httpstatus_list</span></code> key of <a class="reference internal" href="request-response.html#scrapy.http.Request.meta" title="scrapy.http.Request.meta"><code class="xref py py-attr docutils literal notranslate"><span class="pre">Request.meta</span></code></a> can also be used to specify which response codes to
allow on a per-request basis. You can also set the meta key <code class="docutils literal notranslate"><span class="pre">handle_httpstatus_all</span></code>
to <code class="docutils literal notranslate"><span class="pre">True</span></code> if you want to allow any response code for a request.</p>
<p>Keep in mind, however, that it’s usually a bad idea to handle non-200
responses, unless you really know what you’re doing.</p>
<p>For more information see: <a class="reference external" href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP Status Code Definitions</a>.</p>
<div class="section" id="httperrormiddleware-settings">
<h4>HttpErrorMiddleware settings<a class="headerlink" href="#httperrormiddleware-settings" title="Permalink to this headline">¶</a></h4>
<div class="section" id="httperror-allowed-codes">
<span id="std:setting-HTTPERROR_ALLOWED_CODES"></span><h5>HTTPERROR_ALLOWED_CODES<a class="headerlink" href="#httperror-allowed-codes" title="Permalink to this headline">¶</a></h5>
<p>Default: <code class="docutils literal notranslate"><span class="pre">[]</span></code></p>
<p>Pass all responses with non-200 status codes contained in this list.</p>
</div>
<div class="section" id="httperror-allow-all">
<span id="std:setting-HTTPERROR_ALLOW_ALL"></span><h5>HTTPERROR_ALLOW_ALL<a class="headerlink" href="#httperror-allow-all" title="Permalink to this headline">¶</a></h5>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Pass all responses, regardless of its status code.</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.spidermiddlewares.offsite">
<span id="offsitemiddleware"></span><h3>OffsiteMiddleware<a class="headerlink" href="#module-scrapy.spidermiddlewares.offsite" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spidermiddlewares.offsite.OffsiteMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.offsite.</code><code class="sig-name descname">OffsiteMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.offsite.OffsiteMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters out Requests for URLs outside the domains covered by the spider.</p>
<p>This middleware filters out every request whose host names aren’t in the
spider’s <a class="reference internal" href="spiders.html#scrapy.spiders.Spider.allowed_domains" title="scrapy.spiders.Spider.allowed_domains"><code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_domains</span></code></a> attribute.
All subdomains of any domain in the list are also allowed.
E.g. the rule <code class="docutils literal notranslate"><span class="pre">www.example.org</span></code> will also allow <code class="docutils literal notranslate"><span class="pre">bob.www.example.org</span></code>
but not <code class="docutils literal notranslate"><span class="pre">www2.example.com</span></code> nor <code class="docutils literal notranslate"><span class="pre">example.com</span></code>.</p>
<p>When your spider returns a request for a domain not belonging to those
covered by the spider, this middleware will log a debug message similar to
this one:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DEBUG</span><span class="p">:</span> <span class="n">Filtered</span> <span class="n">offsite</span> <span class="n">request</span> <span class="n">to</span> <span class="s1">&#39;www.othersite.com&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">othersite</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">some</span><span class="o">/</span><span class="n">page</span><span class="o">.</span><span class="n">html</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>To avoid filling the log with too much noise, it will only print one of
these messages for each new domain filtered. So, for example, if another
request for <code class="docutils literal notranslate"><span class="pre">www.othersite.com</span></code> is filtered, no log message will be
printed. But if a request for <code class="docutils literal notranslate"><span class="pre">someothersite.com</span></code> is filtered, a message
will be printed (but only for the first request filtered).</p>
<p>If the spider doesn’t define an
<a class="reference internal" href="spiders.html#scrapy.spiders.Spider.allowed_domains" title="scrapy.spiders.Spider.allowed_domains"><code class="xref py py-attr docutils literal notranslate"><span class="pre">allowed_domains</span></code></a> attribute, or the
attribute is empty, the offsite middleware will allow all requests.</p>
<p>If the request has the <code class="xref py py-attr docutils literal notranslate"><span class="pre">dont_filter</span></code> attribute
set, the offsite middleware will allow the request even if its domain is not
listed in allowed domains.</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.spidermiddlewares.referer">
<span id="referermiddleware"></span><h3>RefererMiddleware<a class="headerlink" href="#module-scrapy.spidermiddlewares.referer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.RefererMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">RefererMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.RefererMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Populates Request <code class="docutils literal notranslate"><span class="pre">Referer</span></code> header, based on the URL of the Response which
generated it.</p>
</dd></dl>

<div class="section" id="referermiddleware-settings">
<h4>RefererMiddleware settings<a class="headerlink" href="#referermiddleware-settings" title="Permalink to this headline">¶</a></h4>
<div class="section" id="referer-enabled">
<span id="std:setting-REFERER_ENABLED"></span><h5>REFERER_ENABLED<a class="headerlink" href="#referer-enabled" title="Permalink to this headline">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether to enable referer middleware.</p>
</div>
<div class="section" id="referrer-policy">
<span id="std:setting-REFERRER_POLICY"></span><h5>REFERRER_POLICY<a class="headerlink" href="#referrer-policy" title="Permalink to this headline">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.</span></p>
</div>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.spidermiddlewares.referer.DefaultReferrerPolicy'</span></code></p>
<p id="std:reqmeta-referrer_policy"><a class="reference external" href="https://www.w3.org/TR/referrer-policy">Referrer Policy</a> to apply when populating Request “Referer” header.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also set the Referrer Policy per request,
using the special <code class="docutils literal notranslate"><span class="pre">&quot;referrer_policy&quot;</span></code> <a class="reference internal" href="request-response.html#topics-request-meta"><span class="std std-ref">Request.meta</span></a> key,
with the same acceptable values as for the <code class="docutils literal notranslate"><span class="pre">REFERRER_POLICY</span></code> setting.</p>
</div>
<div class="section" id="acceptable-values-for-referrer-policy">
<h6>Acceptable values for REFERRER_POLICY<a class="headerlink" href="#acceptable-values-for-referrer-policy" title="Permalink to this headline">¶</a></h6>
<ul class="simple">
<li><p>either a path to a <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.ReferrerPolicy</span></code>
subclass — a custom policy or one of the built-in ones (see classes below),</p></li>
<li><p>or one of the standard W3C-defined string values,</p></li>
<li><p>or the special <code class="docutils literal notranslate"><span class="pre">&quot;scrapy-default&quot;</span></code>.</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 34%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>String value</p></th>
<th class="head"><p>Class name (as a string)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">&quot;scrapy-default&quot;</span></code> (default)</p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.DefaultReferrerPolicy" title="scrapy.spidermiddlewares.referer.DefaultReferrerPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.DefaultReferrerPolicy</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer">“no-referrer”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.NoReferrerPolicy" title="scrapy.spidermiddlewares.referer.NoReferrerPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.NoReferrerPolicy</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade">“no-referrer-when-downgrade”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.NoReferrerWhenDowngradePolicy" title="scrapy.spidermiddlewares.referer.NoReferrerWhenDowngradePolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.NoReferrerWhenDowngradePolicy</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-same-origin">“same-origin”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.SameOriginPolicy" title="scrapy.spidermiddlewares.referer.SameOriginPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.SameOriginPolicy</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-origin">“origin”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.OriginPolicy" title="scrapy.spidermiddlewares.referer.OriginPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.OriginPolicy</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin">“strict-origin”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.StrictOriginPolicy" title="scrapy.spidermiddlewares.referer.StrictOriginPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.StrictOriginPolicy</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-origin-when-cross-origin">“origin-when-cross-origin”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.OriginWhenCrossOriginPolicy" title="scrapy.spidermiddlewares.referer.OriginWhenCrossOriginPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.OriginWhenCrossOriginPolicy</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin-when-cross-origin">“strict-origin-when-cross-origin”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.StrictOriginWhenCrossOriginPolicy" title="scrapy.spidermiddlewares.referer.StrictOriginWhenCrossOriginPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.StrictOriginWhenCrossOriginPolicy</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-unsafe-url">“unsafe-url”</a></p></td>
<td><p><a class="reference internal" href="#scrapy.spidermiddlewares.referer.UnsafeUrlPolicy" title="scrapy.spidermiddlewares.referer.UnsafeUrlPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.referer.UnsafeUrlPolicy</span></code></a></p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.DefaultReferrerPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">DefaultReferrerPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.DefaultReferrerPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>A variant of “no-referrer-when-downgrade”,
with the addition that “Referer” is not sent if the parent request was
using <code class="docutils literal notranslate"><span class="pre">file://</span></code> or <code class="docutils literal notranslate"><span class="pre">s3://</span></code> scheme.</p>
</dd></dl>

<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Scrapy’s default referrer policy — just like <a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade">“no-referrer-when-downgrade”</a>,
the W3C-recommended value for browsers — will send a non-empty
“Referer” header from any <code class="docutils literal notranslate"><span class="pre">http(s)://</span></code> to any <code class="docutils literal notranslate"><span class="pre">https://</span></code> URL,
even if the domain is different.</p>
<p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-same-origin">“same-origin”</a> may be a better choice if you want to remove referrer
information for cross-domain requests.</p>
</div>
<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.NoReferrerPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">NoReferrerPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.NoReferrerPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer">https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer</a></p>
<p>The simplest policy is “no-referrer”, which specifies that no referrer information
is to be sent along with requests made from a particular request client to any origin.
The header will be omitted entirely.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.NoReferrerWhenDowngradePolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">NoReferrerWhenDowngradePolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.NoReferrerWhenDowngradePolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade">https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade</a></p>
<p>The “no-referrer-when-downgrade” policy sends a full URL along with requests
from a TLS-protected environment settings object to a potentially trustworthy URL,
and requests from clients which are not TLS-protected to any origin.</p>
<p>Requests from TLS-protected clients to non-potentially trustworthy URLs,
on the other hand, will contain no referrer information.
A Referer HTTP header will not be sent.</p>
<p>This is a user agent’s default behavior, if no policy is otherwise specified.</p>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“no-referrer-when-downgrade” policy is the W3C-recommended default,
and is used by major web browsers.</p>
<p>However, it is NOT Scrapy’s default referrer policy (see <a class="reference internal" href="#scrapy.spidermiddlewares.referer.DefaultReferrerPolicy" title="scrapy.spidermiddlewares.referer.DefaultReferrerPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">DefaultReferrerPolicy</span></code></a>).</p>
</div>
<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.SameOriginPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">SameOriginPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.SameOriginPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-same-origin">https://www.w3.org/TR/referrer-policy/#referrer-policy-same-origin</a></p>
<p>The “same-origin” policy specifies that a full URL, stripped for use as a referrer,
is sent as referrer information when making same-origin requests from a particular request client.</p>
<p>Cross-origin requests, on the other hand, will contain no referrer information.
A Referer HTTP header will not be sent.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.OriginPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">OriginPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.OriginPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-origin">https://www.w3.org/TR/referrer-policy/#referrer-policy-origin</a></p>
<p>The “origin” policy specifies that only the ASCII serialization
of the origin of the request client is sent as referrer information
when making both same-origin requests and cross-origin requests
from a particular request client.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.StrictOriginPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">StrictOriginPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.StrictOriginPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin">https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin</a></p>
<p>The “strict-origin” policy sends the ASCII serialization
of the origin of the request client when making requests:
- from a TLS-protected environment settings object to a potentially trustworthy URL, and
- from non-TLS-protected environment settings objects to any origin.</p>
<p>Requests from TLS-protected request clients to non- potentially trustworthy URLs,
on the other hand, will contain no referrer information.
A Referer HTTP header will not be sent.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.OriginWhenCrossOriginPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">OriginWhenCrossOriginPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.OriginWhenCrossOriginPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-origin-when-cross-origin">https://www.w3.org/TR/referrer-policy/#referrer-policy-origin-when-cross-origin</a></p>
<p>The “origin-when-cross-origin” policy specifies that a full URL,
stripped for use as a referrer, is sent as referrer information
when making same-origin requests from a particular request client,
and only the ASCII serialization of the origin of the request client
is sent as referrer information when making cross-origin requests
from a particular request client.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.StrictOriginWhenCrossOriginPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">StrictOriginWhenCrossOriginPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.StrictOriginWhenCrossOriginPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin-when-cross-origin">https://www.w3.org/TR/referrer-policy/#referrer-policy-strict-origin-when-cross-origin</a></p>
<p>The “strict-origin-when-cross-origin” policy specifies that a full URL,
stripped for use as a referrer, is sent as referrer information
when making same-origin requests from a particular request client,
and only the ASCII serialization of the origin of the request client
when making cross-origin requests:</p>
<ul class="simple">
<li><p>from a TLS-protected environment settings object to a potentially trustworthy URL, and</p></li>
<li><p>from non-TLS-protected environment settings objects to any origin.</p></li>
</ul>
<p>Requests from TLS-protected clients to non- potentially trustworthy URLs,
on the other hand, will contain no referrer information.
A Referer HTTP header will not be sent.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.spidermiddlewares.referer.UnsafeUrlPolicy">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.referer.</code><code class="sig-name descname">UnsafeUrlPolicy</code><a class="headerlink" href="#scrapy.spidermiddlewares.referer.UnsafeUrlPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.w3.org/TR/referrer-policy/#referrer-policy-unsafe-url">https://www.w3.org/TR/referrer-policy/#referrer-policy-unsafe-url</a></p>
<p>The “unsafe-url” policy specifies that a full URL, stripped for use as a referrer,
is sent along with both cross-origin requests
and same-origin requests made from a particular request client.</p>
<p>Note: The policy’s name doesn’t lie; it is unsafe.
This policy will leak origins and paths from TLS-protected resources
to insecure origins.
Carefully consider the impact of setting such a policy for potentially sensitive documents.</p>
</dd></dl>

<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>“unsafe-url” policy is NOT recommended.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="module-scrapy.spidermiddlewares.urllength">
<span id="urllengthmiddleware"></span><h3>UrlLengthMiddleware<a class="headerlink" href="#module-scrapy.spidermiddlewares.urllength" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="scrapy.spidermiddlewares.urllength.UrlLengthMiddleware">
<em class="property">class </em><code class="sig-prename descclassname">scrapy.spidermiddlewares.urllength.</code><code class="sig-name descname">UrlLengthMiddleware</code><a class="headerlink" href="#scrapy.spidermiddlewares.urllength.UrlLengthMiddleware" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters out requests with URLs longer than URLLENGTH_LIMIT</p>
<p>The <a class="reference internal" href="#scrapy.spidermiddlewares.urllength.UrlLengthMiddleware" title="scrapy.spidermiddlewares.urllength.UrlLengthMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">UrlLengthMiddleware</span></code></a> can be configured through the following
settings (see the settings documentation for more info):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="settings.html#std:setting-URLLENGTH_LIMIT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">URLLENGTH_LIMIT</span></code></a> - The maximum URL length to allow for crawled URLs.</p></li>
</ul>
</div></blockquote>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="extensions.html" class="btn btn-neutral float-right" title="扩展" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="downloader-middleware.html" class="btn btn-neutral float-left" title="Downloader Middleware" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008–2018, Scrapy developers
      <span class="lastupdated">
        Last updated on Feb 27, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>


</body>
</html>